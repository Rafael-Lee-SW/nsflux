# SQL_NS.py

import os
import subprocess
from utils.tracking import time_tracker
import json
from utils.utils import load_model
import re

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['ORACLE_HOME'] = '/workspace/oracle/instantclient_23_7'
os.environ['LD_LIBRARY_PATH'] = os.environ['ORACLE_HOME'] + ':' + os.environ.get('LD_LIBRARY_PATH', '')
os.environ['PATH'] = os.environ['ORACLE_HOME'] + ':' + os.environ.get('PATH', '')

import yaml
from box import Box

# Config ë¶ˆëŸ¬ì˜¤ê¸°
with open("./config.yaml", "r") as f:
    config_yaml = yaml.load(f, Loader=yaml.FullLoader)
    config = Box(config_yaml)

# ê¸°ë³¸ SQL ì ‘ì†ì½”ë“œ
sqlplus_command = [
            'sqlplus', '-S', 'LLM/L9SD2TT9XJ0H@//210.113.16.230:1521/ORA11GDR'
        ]

'''
### ORACLE DB ì •ë³´ ###
TABLE : ai_dg_check
    COLUMNS : CLS (ìœ„í—˜ë¬¼ í´ë˜ìŠ¤)
              UNNO (ìœ„í—˜ë¬¼ UN ë²ˆí˜¸)
              PORT (í¬íŠ¸ ë²ˆí˜¸)
              ALLOW_YN (ì·¨ê¸‰ ê°€ëŠ¥ ì—¬ë¶€)
'''

SQL_UNNO_PROMPT = \
"""
<bos>
<system>
ë„ˆëŠ” ë‚¨ì„±í•´ìš´ì˜ ë‚´ë¶€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë°ì´í„° ë¶„ì„ê°€ì•¼.
- ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ë‹µë³€ì„ í•œë‹¤.
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë‚´ë¶€ ìë£Œì— í•´ë‹¹ ìë£Œ ì—†ìŒ"ì´ë¼ê³  ëª…ì‹œí•œë‹¤.
- í‘œ ë°ì´í„°ë¥¼ ë§ë¡œ í’€ì–´ í•´ì„í•œ ë’¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•œë‹¤.
- ì¶œì²˜ í‘œê¸°ëŠ” í•„ìˆ˜ë‹¤.
</system>

<user>
ë‚´ë¶€ ìë£Œ: {docs}
ì§ˆë¬¸: {query}
</user>

<assistant>
ë‹µë³€:
</assistant>
"""

# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì´ˆê¸°ì„¤ì •
def initialze(config):
    

    model, tokenizer, _, _ = load_model(config)
    return model, tokenizer

# sqlplus ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
def check_sqlplus():
    try:
        # sqlplus ë²„ì „ í™•ì¸
        result = subprocess.run(['sqlplus', '-version'], capture_output=True, text=True, check=True)
        print(" SQL*Plus is working!")
        print("Version info:\n", result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"Error: {e.stderr}")

# DB ì—°ê²°ìƒíƒœ í™•ì¸
def check_db_connection():
    try:
        # SQL*Plus ì‹¤í–‰ ëª…ë ¹
        
        # SQL ëª…ë ¹ì„ í‘œì¤€ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        sql_query = "SELECT 1 FROM dual;\nEXIT;\n"
        result = subprocess.run(
            sqlplus_command,
            input=sql_query,  # SQL ëª…ë ¹ì„ í‘œì¤€ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            capture_output=True,
            text=True
        )
        
        # SQL*Plus ê²°ê³¼ ë¶„ì„
        if "1" in result.stdout:
            print("  Successfully connected to the Namsung database!")
        else:
            print(" Connection to the database failed!")

    except subprocess.CalledProcessError as e:
        print(f" Error: {e.stderr}")

# ìŠ¤í‚¤ë§ˆ ë³„ í…Œì´ë¸” ëª©ë¡ ì¶œë ¥
@time_tracker
def get_all_schema_tables():
    try:
        # SQL*Plus ì‹¤í–‰ ëª…ë ¹
        sqlplus_command = [
            'sqlplus', '-S', 'LLM/L9SD2TT9XJ0H@//210.113.16.230:1521/ORA11GDR'
        ]

        # SQL ì‹¤í–‰ (ìŠ¤í‚¤ë§ˆë³„ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ)
        sql_query = """SET PAGESIZE 0 FEEDBACK OFF VERIFY OFF HEADING OFF ECHO OFF;
        SELECT OWNER, TABLE_NAME FROM ALL_TABLES ORDER BY OWNER, TABLE_NAME;
        EXIT;"""

        # SQL*Plus ì‹¤í–‰
        result = subprocess.run(
            sqlplus_command,
            input=sql_query,
            capture_output=True,
            text=True
        )

        # ê²°ê³¼ ë¶„ì„
        schema_tables = {}
        for line in result.stdout.splitlines():
            line = line.strip()
            if line:
                parts = line.split()  # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ OWNERì™€ TABLE_NAME ë¶„ë¦¬
                if len(parts) >= 2:
                    schema, table = parts[0], parts[1]
                    if schema not in schema_tables:
                        schema_tables[schema] = []
                    schema_tables[schema].append(table)

        # ê²°ê³¼ ì¶œë ¥
        if schema_tables:
            print("  ìŠ¤í‚¤ë§ˆë³„ í…Œì´ë¸” ëª©ë¡:")
            for schema, tables in schema_tables.items():
                print(f"\nğŸ”¹ ìŠ¤í‚¤ë§ˆ: {schema}")
                for table in tables:
                    print(f"  - {table}")
        else:
            print(" í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        return schema_tables

    except subprocess.CalledProcessError as e:
        print(f" Error: {e.stderr}")
        return {}

# OPRAIMDGì—ì„œ ë©”íƒ€ë°ì´í„° ë§Œë“¤ê¸°.
def make_metadata_from_table(schema_name="ICON", table_name="OPRAIMDG"):
    
    # LINESIZE : ì»¬ëŸ¼ì´ ê¸¸ë•Œ ë‹¤ìŒì¤„ë¡œ ì¶œë ¥í•˜ëŠ” ê²ƒ ë°©ì§€
    # PAGESIZE : 0ì¼ ê²½ìš° í—¤ë” ë¬´ì‹œ
    # TRIMSPOOL : ì˜ë¯¸ì—†ëŠ” ê³µë°± ë¬´ì‹œ
    # IMDCOM FORMAT A200 : IMDCOM ì»¬ëŸ¼ì˜ ì¶œë ¥ ê¸¸ì´ ëŠ˜ë¦¬ê¸°
    sql_query = f"""
    SET LINESIZE 2000;
    SET PAGESIZE 0;
    SET TRIMSPOOL ON;
    COL IMDCOM FORMAT A200;
    -- ê°œí–‰ë¬¸ì ì—†ì• ê¸°
    SELECT IMDUNM, IMDCLS, REPLACE(REPLACE(IMDCOM, CHR(10), ' '), CHR(13), ' ') AS IMDCOM 
    FROM {schema_name}.{table_name};
    EXIT;
    """
    
    try:
        # SQL*Plus ì‹¤í–‰ ë° ê²°ê³¼ ìº¡ì²˜
        result = subprocess.run(sqlplus_command, input=sql_query, capture_output=True, text=True)
        print(f"  RESULT: \n{str(result)[:1000]}")
        output = result.stdout
        print(f"  OUTPUT: \n{str(output)[:1000]}")
        
        # ê²°ê³¼ íŒŒì‹±
        lines = output.strip().split("\n")
        print(f"  LINE: \n{str(lines)[:1000]}")
        metadata = []
        
        for line in lines[:-1]:
            # print(line)
            values = line.split(None, 2)  # ì²« ë‘ ê°œëŠ” ê·¸ëŒ€ë¡œ, ì„¸ ë²ˆì§¸ëŠ” ë‚˜ë¨¸ì§€ ì „ì²´ë¥¼ í¬í•¨
            if len(values) == 3:
                imdunm = values[0].strip()
                imdcls = values[1].strip()
                imdcom = values[2].strip()  # ì„¤ëª…ì€ ì „ì²´ ìœ ì§€
                metadata.append({
                    "UNNO": imdunm,
                    "Class": imdcls,
                    "Description": imdcom
                })
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        json_filename = "/workspace/data/METADATA_OPRAIMDG.json"
        with open(json_filename, "w", encoding="utf-8") as json_file:
            json.dump(metadata, json_file, indent=4, ensure_ascii=False)
        
        print(f"  Metadata saved to {json_filename}")
    
    except subprocess.CalledProcessError as e:
        print(f" SQL Execution Error: {e.stderr}")

# # Oracle sqlplus ëª…ë ¹ì–´ ì‹¤í–‰ ì˜ˆì‹œ
@time_tracker
def run_sql_unno(cls=None, unno=None, pol_port='KR%', pod_port='JP%'):
    # ê°’ì´ "NULL"ì´ ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ì·¨ê¸‰í•˜ì—¬ ì‘ì€ë”°ì˜´í‘œë¡œ ê°ìŒˆ.
    cls_val = "NULL" if (cls is None or cls == "NULL") else f"'{cls}'"
    unno_val = "NULL" if (unno is None or unno == "NULL") else f"'{unno}'"

    # SQL*Plus ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•  ê¸°ë³¸ ëª…ë ¹ì–´
    sql_query = \
    f"""
    SET LINESIZE 150;
    SET PAGESIZE 1000;
    SET TRIMSPOOL ON;

    SELECT 
        p.cls  AS CLS,
        p.unno AS UNNO,
        p.port AS POL_PORT,
        d.port AS POD_PORT,
        DECODE(p.allow_yn,'Y','OK','N','Forbidden','Need to contact PIC of POL') AS Landing_STATUS,
        DECODE(d.allow_yn,'Y','OK','N','Forbidden','Need to contact PIC of POL') AS Departure_STATUS
    FROM icon.ai_dg_check p
    JOIN icon.ai_dg_check d 
        ON p.unno = d.unno 
        AND p.cls = d.cls
    WHERE (p.cls={cls_val} OR {cls_val} IS NULL) AND (p.unno={unno_val} OR {unno_val} IS NULL) AND p.port LIKE '{pol_port}'
      AND (p.cls={cls_val} OR {cls_val} IS NULL) AND (d.unno={unno_val} OR {unno_val} IS NULL) AND d.port LIKE '{pod_port}';
    EXIT;
    """
    
    # subprocessë¥¼ ì‚¬ìš©í•˜ì—¬ SQL*Plus ëª…ë ¹ì–´ ì‹¤í–‰
    try:
        result = subprocess.run(sqlplus_command, input=sql_query, capture_output=True, text=True)
        # SQL*Plusì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤
        print("  SQL Query Results:\n", result.stdout)
    except subprocess.CalledProcessError as e:
        # ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
        print(f" Error: {e.stderr}")
    # import code
    # code.interact(local=locals())  # í˜„ì¬ ë³€ìˆ˜ë“¤ì„ ìœ ì§€í•œ ìƒíƒœì—ì„œ Python ì¸í„°ë™í‹°ë¸Œ ì…¸ ì‹¤í–‰
    return sql_query, result.stdout

def get_metadata(config):
    """
    - port_path JSON: ë”•ì…”ë„ˆë¦¬ í˜•íƒœì´ë©°, 'location_code' í‚¤ì˜ ê°’ì„ ì¶”ì¶œ.
    - unno_path JSON: ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë©°, ëª¨ë“  í•­ëª©ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜.
    """
    print("[SOOWAN] get_metadata ì§„ì…")
    print("[SOOWAN] get_metadata ì§„ì…")
    if not config or not hasattr(config, "metadata_unno"):
        raise ValueError("Config ê°ì²´ì— 'metadata_unno' ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. config: {}".format(config))
    unno_path = config.metadata_unno
    port_path = config.metadata_path

    # port_path JSON íŒŒì¼ ë¡œë“œ (ë”•ì…”ë„ˆë¦¬)
    with open(port_path, "r", encoding="utf-8") as f:
        port_data = json.load(f)
    
    # location_code ê°’ ì¶”ì¶œ (í‚¤ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
    location_codes = json.dumps(port_data.get("location_code"), ensure_ascii=False)

    # unno_path JSON íŒŒì¼ ë¡œë“œ (ë¦¬ìŠ¤íŠ¸)
    with open(unno_path, "r", encoding="utf-8") as f:
        unno_data = json.load(f)
    
    # ë¦¬ìŠ¤íŠ¸ ë‚´ ëª¨ë“  ìš”ì†Œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    unno_list_as_string = json.dumps(unno_data, ensure_ascii=False)

    return location_codes, unno_list_as_string


@time_tracker
async def generate_sql(user_query, model, tokenizer, config):
    
    # Parse Metadata
    metadata_location, metadata_unno = get_metadata(config)
    # metadata_location = get_metadata(config)

    PROMPT =\
f'''
<bos>
<system>
"YourRole": "ì§ˆë¬¸ìœ¼ë¡œ ë¶€í„° ì¡°ê±´ì„ ì¶”ì¶œí•˜ëŠ” ì—­í• ",
"YourJob": "ì•„ë˜ ìš”êµ¬ ì‚¬í•­ì— ë§ì¶”ì–´ 'unno', 'class', 'pol_port', 'pod_port' ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬, ì˜ˆì‹œì²˜ëŸ¼ ë‹µë³€ì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.",
"Requirements": [
    unno: UNNO NumberëŠ” 4ê°œì˜ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ìœ„í—˜ë¬¼ ë²ˆí˜¸ ì½”ë“œì•¼. 
    class : UN ClassëŠ” 2.1, 6.0,,, ì˜ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ì½”ë“œì•¼.
    pol_port, pod_port: í•­êµ¬ ì½”ë“œëŠ” 5ê°œì˜ ì•ŒíŒŒë²³ ë˜ëŠ” ë‚˜ë¼ì˜ ê²½ìš° 2ê°œì˜ ì•ŒíŒŒë²³ê³¼ %ë¡œ ì´ë£¨ì–´ì ¸ ìˆì–´. ë‹¤ìŒì€ í•­êµ¬ ì½”ë“œì— ëŒ€í•œ ë©”íƒ€ë°ì´í„°ì•¼ {metadata_location}. ì—¬ê¸°ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì½”ë“œë§Œì„ ì‚¬ìš©í•´ì•¼ í•´. í•­êµ¬ëŠ” í•­êµ¬ì½”ë“œ, ë‚˜ë¼ëŠ” 2ê°œì˜ ë‚˜ë¼ì½”ë“œì™€ %ë¥¼ ì‚¬ìš©í•´.
    unknown : ì§ˆë¬¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” NULLì„ ì¶œë ¥í•´ì¤˜.
]

"Examples": [
    "ì§ˆë¬¸": "UN ë²ˆí˜¸ 1689 í™”ë¬¼ì˜ ë¶€ì‚°ì—ì„œ ë¯¸ì¦ˆì‹œë§ˆë¡œì˜ ì„ ì  ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.",
    "ë‹µë³€": "<unno/>1689<unno>\\n<class/>NULL<class>\\n<pol_port/>KRPUS<pol_port>\\n<pod_port/>JPMIZ<pod_port>"

    "ì§ˆë¬¸": "UN í´ë˜ìŠ¤ 2.1 í™”ë¬¼ì˜ í•œêµ­ì—ì„œ ì¼ë³¸ìœ¼ë¡œì˜ ì„ ì  ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.",
    "ë‹µë³€": "<unno/>NULL<unno>\\n<class/>2.1<class>\\n<pol_port/>KR%<pol_port>\\n<pod_port/>JP%<pod_port>"
]
- ìµœì¢… ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
    <unno/>...<unno>
    <class/>...<class>
    <pol_port/>...<pol_port>
    <pod_port/>...<pod_port>
</system>

<user>
ì§ˆë¬¸: "{user_query}"
</user>

<assistant>
ë‹µë³€:
</assistant>
'''

    # --- í† í° ìˆ˜ ê³„ì‚° ë‹¨ê³„ ì¶”ê°€ ---
    tokenized_prompt = tokenizer(PROMPT, return_tensors="pt", truncation=True)
    token_count = tokenized_prompt["input_ids"].shape[1]
    print(f"[DEBUG] í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜: {token_count}")

    # Get Answer
    ## From Vllm Inference
    from vllm import SamplingParams
    import uuid
    from core.RAG import collect_vllm_text
    sampling_params = SamplingParams(
        max_tokens=config.model.max_new_tokens,
        temperature=config.model.temperature,
        top_k=config.model.top_k,
        top_p=config.model.top_p,
        repetition_penalty=config.model.repetition_penalty,
    )
    # ì„±ê³µí•  ë•Œê¹Œì§€ ìµœëŒ€ 3íšŒ ë°˜ë³µ
    max_attempts = 3
    attempt = 0
    UN_number = UN_class = POL = POD = "NULL"
    unno_pattern = r'<unno.*?>(.*?)<unno.*?>'
    class_pattern = r'<class.*?>(.*?)<class.*?>'
    pol_port_pattern = r'<pol_port.*?>(.*?)<pol_port.*?>'
    pod_port_pattern = r'<pod_port.*?>(.*?)<pod_port.*?>'

    while attempt < max_attempts:
        accepted_request_id = str(uuid.uuid4())
        outputs_result = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
        print(f"[GENERATE_SQL] Attempt {attempt+1}, SQL Model Outputs: {outputs_result}")

        match_unno = re.search(unno_pattern, outputs_result, re.DOTALL)
        UN_number = match_unno.group(1).strip() if match_unno is not None else "NULL"

        match_class = re.search(class_pattern, outputs_result, re.DOTALL)
        UN_class = match_class.group(1).strip() if match_class is not None else "NULL"

        match_pol = re.search(pol_port_pattern, outputs_result, re.DOTALL)
        POL = match_pol.group(1).strip() if match_pol is not None else "NULL"

        match_pod = re.search(pod_port_pattern, outputs_result, re.DOTALL)
        POD = match_pod.group(1).strip() if match_pod is not None else "NULL"

        print(f"[GENERATE_SQL] ì¶”ì¶œ ê²°ê³¼ - UN_number: {UN_number}, UN_class: {UN_class}, POL: {POL}, POD: {POD}")

        # ì¡°ê±´: UN_numberì™€ UN_class ì¤‘ í•˜ë‚˜ë¼ë„ NULLì´ ì•„ë‹ˆê³ , POLê³¼ PODëŠ” ëª¨ë‘ NULLì´ ì•„ë‹ˆì–´ì•¼ í•¨.
        if ((UN_number != "NULL" or UN_class != "NULL") and POL != "NULL" and POD != "NULL"):
            break
        attempt += 1

    print(f"[GENERATE_SQL] ìµœì¢… ì¶”ì¶œ ê°’ - UN_number: {UN_number}, UN_class: {UN_class}, POL: {POL}, POD: {POD}")
    final_sql_query, result = run_sql_unno(UN_class, UN_number, POL, POD)
    # Temporary: title, explain, table_json, chart_jsonì€ Noneìœ¼ë¡œ ì²˜ë¦¬
    title, explain, table_json, chart_json = (None,) * 4
    return final_sql_query, title, explain, result, chart_json

if __name__ == "__main__":
    # check_sqlplus()             # sqlplusê°€ ì˜ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
    # check_db_connection()       # ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ì—¬ë¶€ í™•ì¸
    # get_all_schema_tables()    # ICON Table Name ë°˜í™˜
    # run_sql_unno(cls=4.1, pol_port="KR%", pod_port="JPUKB")         # ì‹¤ì œ SQL ì¿¼ë¦¬ ì‹¤í–‰
    # make_metadata_from_table()

    query = "UNë²ˆí˜¸ 1033, UN í´ë˜ìŠ¤ 2.1ì¸ í™”ë¬¼ì˜ ë¶€ì‚°í•­ì—ì„œ ê³ ë² í•­ìœ¼ë¡œì˜ ì„ ì ì´ ê°€ëŠ¥í•œì§€ ì•Œì•„ë´ì¤˜."
    model,tokenizer = initialze(config)
    # print(f"  METADATA: {metadata_location}")
    final_sql_query, title, explain, table_json, chart_json = generate_sql(query, model, tokenizer, config)
    print(f"  Final Sql Query: {final_sql_query}\n  Result: {table_json}")