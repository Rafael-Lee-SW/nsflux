# Project Tree of RAG for company

```
├─ app.py
├─ config.yaml
├─ core/RAG.py
├─ core/SQL_NS.py
├─ ray_deploy/langchain.py
├─ ray_deploy/ray_setup.py
├─ ray_deploy/ray_utils.py
├─ utils/utils_format.py
├─ utils/utils_load.py
└─ utils/utils_vector.py
```

--- config.yaml

```yaml

# config.yaml
# Server : 2x H100 (80 GB SXM5), 52 CPU cores, 483.2 GB RAM, 6 TB SSD
### Model
model_id : 'google/gemma-3-27b-it'
response_url : "http://202.20.84.16:8083/responseToUI"
# response_url : "https://eo5smhcazmp1bqe.m.pipedream.net"

ray:
  actor_count: 1                  # 총 Actor 개수(same as num_replicas)
  num_gpus: 1                     # 각 Actor(Node)가 점유하고 있는 GPU 갯수
  num_cpus: 24                    # 각 Actor(Node)가 점유하고 있는 CPU 갯수 (1 actor 시에 gpu 48개, 2 actor 시에 gpu 24개 할당)
  max_batch_size: 5               # max_concurrency(actor 최대 동시 처리량, default 1000)로 대체해도 됨
  batch_wait_timeout: 0.05        
  max_ongoing_requests: 100       # ray.serve에서 deployment setting으로 동시 요청 처리 갯수를 의미함(Batch랑 다름)

use_vllm: True # vLLM 사용 여부
vllm:
  enable_prefix_caching: True
  scheduler_delay_factor: 0.1
  enable_chunked_prefill: True
  tensor_parallel_size: 1         # vLLM의 GPU 사용 갯수 (!!!! num_gpus 보다 작아야 함 !!!!)
  max_num_seqs: 128               # v1에 따른 상향
  max_num_batched_tokens: 34000   # v1에 따른 상향
  block_size: 128                 # 미적용
  gpu_memory_utilization: 0.99    # v0: 0.95 / v1: 0.99로 상향
  # v1에 따른 새로운 인자값
  disable_custom_all_reduce: true
  enable_memory_defrag: True      
  disable_sliding_window: True    # sliding window 비활성화 - cascade attention과 충돌이 나서 이를 비활성화
  # 모델 변경에 따른 추가된 설정
  max_model_len: 24000            # For the new model (Gemma2 : 8192)

model:
  quantization_4bit : False # Quantize 4-bit
  quantization_8bit : False # Quantize 8-bit
  max_new_tokens : 2048      # 생성할 최대 토큰 수

  do_sample : False # True 일때만 아래가 적용
  temperature : 1.0          # 텍스트 다양성 조정: 높을수록 창의력 향상 (1.0)
  top_k : 30                 # top-k 샘플링: 상위 k개의 후보 토큰 중 하나를 선택 (50)
  top_p : 1.0                # top-p 샘플링: 누적 확률을 기준으로 후보 토큰을 선택 (1.0 보다 낮을수록 창의력 증가)
  repetition_penalty : 1.0   # 같은 단어를 반복해서 출력하지 않도록 패널티를 부여 (1.0 보다 클수록 페널티 증가)
embed_model_id : 'BM-K/KoSimCSE-roberta-multitask'
# cache_dir : "D:/huggingface" # Windows Local
# cache_dir : "/media/user/7340afbb-e4ce-4a38-8210-c6362e85eae7/RAG/RAG_application/huggingface" # Local
cache_dir : "/workspace/huggingface"  # Docker

### Data
data_path : '/workspace/data/0228_DB_.json'     # VectorDB Path - New one (계약서 데이터 포함)
# data_path : 'data/1104_NS_DB_old.json' # VectorDB Path - Old one
metadata_path : '/workspace/data/Metadata.json' # Metadata.json Path
metadata_unno : '/workspace/data/METADATA_OPRAIMDG.json'
sql_data_path : '/workspace/data/poc.db'        # SQLite 데이터베이스 Path

### Retrieve
N : 5 # Retrieve top N chunks

### Others
beep : '-------------------------------------------------------------------------------------------------------------------------------------------------------------------------'
seed : 4734                     # Radom Seed
k : 15                        # SQL Max Rows (None=MAX)

```


--- app.py

```python

# app.py
import os
# Setting environment variable
# os.environ["TRANSFORMERS_CACHE"] = "/workspace/huggingface"
os.environ["HF_HOME"] = "/workspace/huggingface"
# os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
# For the Huggingface Token setting
os.environ["HF_TOKEN_PATH"] = "/root/.cache/huggingface/token"
# Change to GNU to using OpenMP. Because this is more friendly with CUDA(NVIDIA),
# and Some library(Pytorch, Numpy, vLLM etc) use the OpenMP so that set the GNU is better.
# OpenMP: Open-Multi-Processing API
os.environ["MKL_THREADING_LAYER"] = "GNU"
# Increase download timeout (in seconds)
os.environ["HF_HUB_DOWNLOAD_TIMEOUT"] = "60"
# Use the vLLM as v1 version
os.environ["VLLM_USE_V1"] = "1"
os.environ["VLLM_STANDBY_MEM"] = "0"
os.environ["VLLM_METRICS_LEVEL"] = "1"
os.environ["VLLM_PROFILE_MEMORY"]= "1"
# GPU 단독 사용(박상제 연구원님이랑 분기점 - 연구원님 0번 GPU, 수완 1번 GPU)
os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # GPU1 사용

# 토크나이저 병렬 처리 명시적 비활성화
os.environ["TOKENIZERS_PARALLELISM"] = "false"

print("[[TEST]]")

from flask import (
    Flask,
    request,
    Response,
    render_template,
    jsonify,
    g,
    stream_with_context,
)
import json
import yaml
from box import Box
from utils import random_seed, error_format, send_data_to_server, process_format_to_response
from datetime import datetime

# Import the Ray modules
from ray_deploy import init_ray
from ray_deploy import InferenceActor
from ray_deploy import InferenceService, SSEQueueManager

# ------ checking process of the thread level
import logging
import threading

# 로깅 설정: 요청 처리 시간과 현재 스레드 이름을 기록
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s %(levelname)s [%(threadName)s] %(message)s'
)

import ray
from ray import serve
import uuid
import asyncio
import time

# Configuration
with open("./config.yaml", "r") as f:
    config_yaml = yaml.load(f, Loader=yaml.FullLoader)
    config = Box(config_yaml)
random_seed(config.seed)

########## Ray Dashboard 8265 port ##########
init_ray()  # Initialize the Ray
sse_manager = SSEQueueManager.options(name="SSEQueueManager").remote()
serve.start(detached=True)

#### Ray-Actor 다중 ####
inference_service = InferenceService.options(num_replicas=config.ray.actor_count).bind(config)
serve.run(inference_service)
inference_handle = serve.get_deployment_handle("inference", app_name="default")

#### Ray-Actor 단독 ####
# inference_actor = InferenceActor.options(num_cpus=config.ray.num_cpus, num_gpus=config.ray.num_gpus).remote(config)

########## FLASK APP setting ##########
app = Flask(__name__)
content_type = "application/json; charset=utf-8"

# 기본 페이지를 불러오는 라우트
@app.route("/")
def index():
    return render_template("index.html")  # index.html을 렌더링

# Test 페이지를 불러오는 라우트
@app.route("/test")
def test_page():
    return render_template("index_test.html")

# chatroomPage 페이지를 불러오는 라우트
@app.route("/chat")
def chat_page():
    return render_template("chatroom.html")

# data 관리
from data_control.data_control import data_control_bp
app.register_blueprint(data_control_bp, url_prefix="/data")

# Query Endpoint (Non-streaming)
@app.route("/query", methods=["POST"])
async def query():
    try:
        # Log when the query is received
        receive_time = datetime.now().isoformat()
        print(f"[APP] Received /query request at {receive_time}")
        
        # Optionally, attach the client time if desired:
        http_query = request.json  # 클라이언트로부터 JSON 요청 수신
        
        http_query["server_receive_time"] = receive_time
        
        # Ray Serve 배포된 서비스를 통해 추론 요청 (자동으로 로드밸런싱됨)
        # result = await inference_actor.process_query.remote(http_query) # 단일
        result = await inference_handle.query.remote(http_query) # 다중
        if isinstance(result, dict):
            result = json.dumps(result, ensure_ascii=False)
        print("APP.py - 결과: ", result)
        return Response(result, content_type=content_type)
    except Exception as e:
        error_resp = error_format(f"서버 처리 중 오류 발생: {str(e)}", 500)
        return Response(error_resp, content_type=content_type)

# --------------------- Streaming part ----------------------------

# # Streaming Endpoint (POST 방식 SSE) → 동기식 뷰 함수로 변경
# @app.route("/query_stream", methods=["POST"])
# def query_stream():
#     """
#     POST 방식 SSE 스트리밍 엔드포인트.
#     클라이언트가 {"input": "..."} 형태의 JSON을 보내면, SSE 스타일의 청크를 반환합니다.
#     """
#     body = request.json or {}
#     user_input = body.get("input", "")
#     # request_id 파트 추가
#     client_request_id = body.get("request_id")
#     print(f"[DEBUG] /query_stream (POST) called with user_input='{user_input}', request_id='{client_request_id}'")
    
#     http_query = {"qry_contents": user_input}
#     # request_id 파트 추가
#     if client_request_id:
#         http_query["request_id"] = client_request_id
#     print(f"[DEBUG] Built http_query={http_query}")

#     response = inference_handle.process_query_stream.remote(http_query)
#     obj_ref = response._to_object_ref_sync()
#     request_id = ray.get(obj_ref)
    
#     print(f"[DEBUG] streaming request_id={request_id}")
    
#     def sse_generator():
#         try:
#             while True:
#                 # Retrieve token from SSEQueueManager
#                 token = ray.get(sse_manager.get_token.remote(request_id, 120))
#                 if token is None or token == "[[STREAM_DONE]]":
#                     break
#                 yield f"data: {token}\n\n"
#         except Exception as e:
#             error_token = json.dumps({"type": "error", "message": str(e)})
#             yield f"data: {error_token}\n\n"
#         finally:
#             # Cleanup: close the SSE queue after streaming is done
#             try:
#                 obj_ref = inference_handle.close_sse_queue.remote(request_id)._to_object_ref_sync()
#                 ray.get(obj_ref)
#             except Exception as ex:
#                 print(f"[DEBUG] Error closing SSE queue for {request_id}: {str(ex)}")
#             print("[DEBUG] SSE closed.")

#     return Response(sse_generator(), mimetype="text/event-stream")

# --------------------- Streaming part TEST for API format matching ----------------------------

@app.route("/query_stream", methods=["POST"])
def query_stream():
    """
    POST 방식 SSE 스트리밍 엔드포인트.
    클라이언트가 아래 필드들을 포함한 JSON을 보내면:
      - qry_id, user_id, page_id, auth_class, qry_contents, qry_time
    auth_class는 내부적으로 'admin'으로 통일합니다.
    """
    body = request.json or {}
    # 새로운 필드 추출
    qry_id = body.get("qry_id")
    user_id = body.get("user_id")
    page_id = body.get("page_id")
    auth_class = "admin"  # 어떤 값이 와도 'admin'으로 통일
    qry_contents = body.get("qry_contents", "")
    qry_time = body.get("qry_time")  # 클라이언트 측 타임스탬프

    print(f"[DEBUG] /query_stream called with qry_id='{qry_id}', user_id='{user_id}', page_id='{page_id}', qry_contents='{qry_contents}', qry_time='{qry_time}'")
    
    # 새로운 http_query 생성 – 내부 로직에서는 page_id를 채팅방 id로 사용
    http_query = {
        "qry_id": qry_id,
        "user_id": user_id,
        "page_id": page_id if page_id else str(uuid.uuid4()),
        "auth_class": auth_class,
        "qry_contents": qry_contents,
        "qry_time": qry_time
    }
    
    # 기존 request_id 대신 page_id를 SSE queue key로 사용
    print(f"[DEBUG] Built http_query: {http_query}")
    
    # Ray Serve를 통한 streaming 호출 (변경 없음, 내부 인자는 수정된 http_query)
    response = inference_handle.process_query_stream.remote(http_query)
    obj_ref = response._to_object_ref_sync()
    chat_id = ray.get(obj_ref)  # chat_id는 page_id
    print(f"[DEBUG] streaming chat_id={chat_id}")
    
    def sse_generator():
        try:
            while True:
                # SSEQueueManager에서 토큰을 가져옴 (chat_id 사용)
                token = ray.get(sse_manager.get_token.remote(chat_id, 120))
                if token is None or token == "[[STREAM_DONE]]":
                    break
                yield f"data: {token}\n\n"
        except Exception as e:
            error_token = json.dumps({"type": "error", "message": str(e)})
            yield f"data: {error_token}\n\n"
        finally:
            try:
                obj_ref = inference_handle.close_sse_queue.remote(chat_id)._to_object_ref_sync()
                ray.get(obj_ref)
            except Exception as ex:
                print(f"[DEBUG] Error closing SSE queue for {chat_id}: {str(ex)}")
            print("[DEBUG] SSE closed.")

    return Response(sse_generator(), mimetype="text/event-stream")

# --------------------- CLT Streaming part ----------------------------

# --------------------- CLT Streaming part ----------------------------
@app.route("/queryToSLLM", methods=["POST"])
def query_stream_to_clt():
    """
    POST 방식 SSE 스트리밍 엔드포인트.
    클라이언트가 {"qry_id": "...", "user_id": "...", "page_id": "...", "qry_contents": "...", "qry_time": "..." }
    형태의 JSON을 보내면, 내부 Ray Serve SSE 스트림을 통해 처리한 후 지정된 response_url로 SSE 청크를 전송합니다.
    """
    # POST 요청 파라미터 파싱
    body = request.json or {}
    qry_id = body.get("qry_id", "")
    user_id = body.get("user_id", "")
    page_id = body.get("page_id", "")
    auth_class = "admin"  # 모든 요청을 'admin'으로 처리
    user_input = body.get("qry_contents", "")
    qry_time = body.get("qry_time", "")
    
    response_url = config.response_url


    print(f"[DEBUG] /queryToSLLM called with qry_id='{qry_id}', user_id='{user_id}', "
          f"page_id='{page_id}', qry_contents='{user_input}', qry_time='{qry_time}', url={response_url}")
    
    # 내부 로직에서는 page_id를 채팅방 ID(또는 request_id)로 사용합니다.
    http_query = {
        "qry_id": qry_id,
        "user_id": user_id,
        "page_id": page_id if page_id else str(uuid.uuid4()),
        "auth_class": auth_class,
        "qry_contents": user_input,
        "qry_time": qry_time,
        "response_url": response_url
    }
    print(f"[DEBUG] Built http_query={http_query}")

    # Ray Serve에 SSE 스트리밍 요청 보내기
    response = inference_handle.process_query_stream.remote(http_query)
    obj_ref = response._to_object_ref_sync()
    request_id = ray.get(obj_ref)
    print(f"[DEBUG] streaming request_id={request_id}")
    
    def sse_generator(request_id, response_url):
        token_buffer = []  # To collect tokens (for answer tokens only)
        last_sent_time = time.time()  # To track the last time data was sent
        answer_counter = 1  # 답변 업데이트 순번
        try:
            while True:
                token = ray.get(sse_manager.get_token.remote(request_id, 120))
                if token is None:
                    print("[DEBUG] 토큰이 None 반환됨. 종료합니다.")
                    break

                if isinstance(token, str):
                    token = token.strip()
                if token == "[[STREAM_DONE]]":
                    print("[DEBUG] 종료 토큰([[STREAM_DONE]]) 수신됨. 스트림 종료.")
                    break

                try:
                    token_dict = json.loads(token) if isinstance(token, str) else token
                except Exception as e:
                    print(f"[ERROR] JSON 파싱 실패: {e}. 원시 토큰: '{token}'")
                    continue

                # If token is a reference token, send it immediately
                if token_dict.get("type") == "reference":
                    print(f"[DEBUG] Reference token details: {token_dict}")
                    ref_format = process_format_to_response([token_dict], qry_id, continue_="C", update_index=answer_counter)
                    print(f"[DEBUG] Sending reference data: {json.dumps(ref_format, ensure_ascii=False, indent=2)}")
                    send_data_to_server(ref_format, response_url)
                    continue

                # Otherwise, accumulate answer tokens
                token_buffer.append(token_dict)
                current_time = time.time()
                # If 1 second has passed, flush the accumulated answer tokens
                if current_time - last_sent_time >= 1:
                    if len(token_buffer) > 0:
                        # Check if any token in the buffer signals termination.
                        final_continue = "E" if any(t.get("continue") == "E" for t in token_buffer) else "C"
                        print(f"[DEBUG] Flushing {len(token_buffer)} tokens with continue flag: {final_continue}")
                        buffer_format = process_format_to_response(token_buffer, qry_id, continue_=final_continue, update_index=answer_counter)
                        send_data_to_server(buffer_format, response_url)
                        token_buffer = []  # Reset the buffer
                        last_sent_time = current_time  # Update the last sent time
                        answer_counter += 1
                if token_dict.get("continue") == "E":
                    # Immediately flush the buffer with termination flag if needed
                    if len(token_buffer) > 0:
                        print(f"[DEBUG] Immediate flush due to termination flag in buffer (size {len(token_buffer)}).")
                        buffer_format = process_format_to_response(token_buffer, qry_id, continue_="E", update_index=answer_counter)
                        send_data_to_server(buffer_format, response_url)
                        token_buffer = []
                    break
            # After loop: if tokens remain, flush them with termination flag
            if len(token_buffer) > 0:
                print(f"[DEBUG] Final flush of remaining {len(token_buffer)} tokens with end flag.")
                buffer_format = process_format_to_response(token_buffer, qry_id, continue_="E", update_index=answer_counter)
                send_data_to_server(buffer_format, response_url)
        except Exception as e:
            print(f"[ERROR] sse_generator encountered an error: {e}")
        finally:
            try:
                obj_ref = inference_handle.close_sse_queue.remote(request_id)._to_object_ref_sync()
                ray.get(obj_ref)
            except Exception as ex:
                print(f"[DEBUG] Error closing SSE queue for {request_id}: {str(ex)}")
            print("[DEBUG] SSE closed.")

    
    # 별도의 스레드에서 SSE generator 실행
    job = threading.Thread(target=sse_generator, args=(request_id, response_url), daemon=False)
    job.start()

    # 클라이언트에는 즉시 "수신양호" 메시지를 JSON 형식으로 응답
    return Response(error_format("수신양호", 200, qry_id), content_type="application/json")

# ------------------------------------------------

# 새로 추가1: request_id로 대화 기록을 조회하는 API 엔드포인트
@app.route("/history", methods=["GET"])
def conversation_history():
    request_id = request.args.get("request_id", "")
    last_index = request.args.get("last_index")
    if not request_id:
        error_resp = error_format("request_id 파라미터가 필요합니다.", 400)
        return Response(error_resp, content_type="application/json; charset=utf-8")
    
    try:
        last_index = int(last_index) if last_index is not None else None
        response = inference_handle.get_history.remote(request_id, last_index=last_index)
        # DeploymentResponse를 ObjectRef로 변환
        obj_ref = response._to_object_ref_sync()
        history_data = ray.get(obj_ref)
        return jsonify(history_data)
    except Exception as e:
        print(f"[ERROR /history] {e}")
        error_resp = error_format(f"대화 기록 조회 오류: {str(e)}", 500)
        return Response(error_resp, content_type="application/json; charset=utf-8")


# 새로 추가2: request_id로 해당 답변의 참고자료를 볼 수 있는 API
@app.route("/reference", methods=["GET"])
def get_reference():
    request_id = request.args.get("request_id", "")
    msg_index_str = request.args.get("msg_index", "")
    if not request_id or not msg_index_str:
        error_resp = error_format("request_id와 msg_index 파라미터가 필요합니다.", 400)
        return Response(error_resp, content_type="application/json; charset=utf-8")
    
    try:
        msg_index = int(msg_index_str)
        # 먼저 history를 가져옴
        response = inference_handle.get_history.remote(request_id)
        obj_ref = response._to_object_ref_sync()
        history_data = ray.get(obj_ref)
        
        history_list = history_data.get("history", [])
        if msg_index < 0 or msg_index >= len(history_list):
            return jsonify({"error": "유효하지 않은 메시지 인덱스"}), 400
        
        message = history_list[msg_index]
        if message.get("role") != "ai":
            return jsonify({"error": "해당 메시지는 AI 응답이 아닙니다."}), 400
        
        chunk_ids = message.get("references", [])
        if not chunk_ids:
            return jsonify({"references": []})
        
        # chunk_ids에 해당하는 실제 참조 데이터 조회
        ref_response = inference_handle.get_reference_data.remote(chunk_ids)
        ref_obj_ref = ref_response._to_object_ref_sync()
        references = ray.get(ref_obj_ref)
        return jsonify({"references": references})
    except Exception as e:
        print(f"[ERROR /reference] {e}")
        error_resp = error_format(f"참조 조회 오류: {str(e)}", 500)
        return Response(error_resp, content_type="application/json; charset=utf-8")


# Flask app 실행
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)

```


--- ray_deploy/ray_setup.py

```python

# ray_deploy/ray_setup.py
import ray
from ray import serve

########## Starting Banner ############
from colorama import init, Fore, Style
init(autoreset=True)

BANNER = Fore.GREEN + r"""
'########:'##:::::::'##::::'##:'##::::'##::::::::::'##::: ##::'######::
 ##.....:: ##::::::: ##:::: ##:. ##::'##::::::::::: ###:: ##:'##... ##:
 ##::::::: ##::::::: ##:::: ##::. ##'##:::::::::::: ####: ##: ##:::..::
 ######::: ##::::::: ##:::: ##:::. ###::::::::::::: ## ## ##:. ######::
 ##...:::: ##::::::: ##:::: ##::: ## ##:::::::::::: ##. ####::..... ##:
 ##::::::: ##::::::: ##:::: ##:: ##:. ##::::::::::: ##:. ###:'##::: ##:
 ##::::::: ########:. #######:: ##:::. ##:'#######: ##::. ##:. ######::
..::::::::........:::.......:::..:::::..::.......::..::::..:::......:::
"""

def init_ray():
    print(BANNER)
    # Ray-Dashboard - GPU 상태, 사용 통계 등을 제공하는 모니터링 툴, host 0.0.0.0로 외부 접속을 허용하고, Default 포트인 8265으로 설정
    ray.init(
        include_dashboard=True,
        dashboard_host="0.0.0.0" # External IP accessable
        # dashboard_port=8265
    )
    print("Ray initialized. DashBoard running at http://192.222.54.254:8265") # New Server(2xH100)

```


--- ray_deploy/ray_utils.py

```python

# ray_deploy/ray_utils.py
import ray  # Ray library
from ray import serve
import json
import asyncio  # async I/O process module
from concurrent.futures import ProcessPoolExecutor  # 스레드 컨트롤
import uuid  # --- NEW OR MODIFIED ---
import time
from typing import Dict, Optional  # --- NEW OR MODIFIED ---
import threading  # To find out the usage of thread
import datetime

from core.RAG import (
    query_sort,
    specific_question,
    execute_rag,
    generate_answer,
    generate_answer_stream,
)  # hypothetically
from utils import (
    load_model,
    load_data,
    process_format_to_response,
    process_to_format,
    error_format,
)
# from summarizer import summarize_conversation
from utils.summarizer import summarize_conversation
from utils.debug_tracking import log_batch_info, log_system_info

from ray_deploy.langchain import CustomConversationBufferMemory

@ray.remote  # From Decorator, Each Actor is allocated 1 GPU
class InferenceActor:
    async def __init__(self, config):
        self.config = config
        # 액터 내부에서 모델 및 토크나이저를 새로 로드 (GPU에 한 번만 로드)
        self.model, self.tokenizer, self.embed_model, self.embed_tokenizer = load_model(
            config
        )
        # 데이터는 캐시 파일을 통해 로드
        self.data = load_data(config.data_path)
        # 비동기 큐와 배치 처리 설정 (마이크로 배칭)
        self.request_queue = asyncio.Queue()
        self.max_batch_size = config.ray.max_batch_size  # 최대 배치 수
        self.batch_wait_timeout = config.ray.batch_wait_timeout  # 배치당 처리 시간

        # Actor 내부에서 ProcessPoolExecutor 생성 (직렬화 문제 회피)
        max_workers = int(min(config.ray.num_cpus * 0.8, (26*config.ray.actor_count)-4))
        self.process_pool = ProcessPoolExecutor(max_workers)

        # --- SSE Queue Manager ---
        # A dictionary to store SSE queues for streaming requests
        # Key = request_id, Value = an asyncio.Queue of partial token strings
        self.queue_manager = ray.get_actor("SSEQueueManager")
        self.active_sse_queues: Dict[str, asyncio.Queue] = {}

        self.batch_counter = 0  # New counter to track batches

        
        self.memory_map = {}

        # Micro-batching로 바꾸기(아래 주석 해체)
        # asyncio.create_task(self._batch_processor())
        
        # In-flight batching까지 추가 적용(Micro 사용할 경우 주석)
        asyncio.create_task(self._in_flight_batch_processor())


    def get_memory_for_session(self, request_id: str) -> CustomConversationBufferMemory:
        """
        세션별 Memory를 안전하게 가져오는 헬퍼 메서드.
        만약 memory_map에 request_id가 없으면 새로 생성해 저장 후 반환.
        """
        if request_id not in self.memory_map:
            print(f"[DEBUG] Creating new CustomConversationBufferMemory for session={request_id}")
            self.memory_map[request_id] = CustomConversationBufferMemory(return_messages=True)
        return self.memory_map[request_id]

    # -------------------------------------------------------------------------
    # Micro_batch_processor - OLD METHOD
    # -------------------------------------------------------------------------
    async def _batch_processor(self):
        """
        Continuously processes queued requests in batches (micro-batching).
        We add new logic for streaming partial tokens if a request has an SSE queue.
        """
        while True:
            batch = []
            batch_start_time = time.time()
            # 1) get first request from the queue
            print("=== _batch_processor waiting for request_queue item... ===")
            item = await self.request_queue.get()
            print(
                f"[DEBUG] 첫 요청 도착: {time.strftime('%H:%M:%S')} (현재 배치 크기: 1)"
            )
            batch.append(item)

            print(f"[DEBUG] Received first request at {time.strftime('%H:%M:%S')}")

            # 2) try to fill the batch up to batch_size or until timeout
            try:
                while len(batch) < self.max_batch_size:
                    print("현재 배치 사이즈 : ", len(batch))
                    print("최대 배치 사이즈 : ", self.max_batch_size)
                    item = await asyncio.wait_for(
                        self.request_queue.get(), timeout=self.batch_wait_timeout
                    )

                    batch.append(item)
                    print(
                        f"[DEBUG] 추가 요청 도착: {time.strftime('%H:%M:%S')} (현재 배치 크기: {len(batch)})"
                    )
            except asyncio.TimeoutError:
                elapsed = time.time() - batch_start_time
                print(
                    f"[DEBUG] 타임아웃 도달: {elapsed:.2f}초 후 (최종 배치 크기: {len(batch)})"
                )
                pass

            print(
                f"=== _batch_processor: 배치 사이즈 {len(batch)} 처리 시작 ({time.strftime('%H:%M:%S')}) ==="
            )

            # 각 요청 처리 전후에 로그 추가
            start_proc = time.time()
            await asyncio.gather(
                *(
                    self._process_single_query(req, fut, sse_queue)
                    for (req, fut, sse_queue) in batch
                )
            )
            proc_time = time.time() - start_proc
            print(f"[DEBUG] 해당 배치 처리 완료 (처리시간: {proc_time:.2f}초)")
            
    # -------------------------------------------------------------------------
    # In-flight BATCH PROCESSOR
    # -------------------------------------------------------------------------
    async def _in_flight_batch_processor(self):
        while True:
            # Wait for the first item (blocking until at least one is available)
            print(
                "=== [In-Flight Batching] Waiting for first item in request_queue... ==="
            )
            first_item = await self.request_queue.get()
            batch = [first_item]
            batch_start_time = time.time()

            print(
                "[In-Flight Batching] Got the first request. Attempting to fill a batch..."
            )

            # Attempt to fill up the batch until we hit max_batch_size or batch_wait_timeout
            while len(batch) < self.max_batch_size:
                try:
                    remain_time = self.batch_wait_timeout - (
                        time.time() - batch_start_time
                    )
                    if remain_time <= 0:
                        print(
                            "[In-Flight Batching] Timed out waiting for more requests; proceeding with current batch."
                        )
                        break
                    item = await asyncio.wait_for(
                        self.request_queue.get(), timeout=remain_time
                    )
                    batch.append(item)
                    print(
                        f"[In-Flight Batching] +1 request => batch size now {len(batch)} <<< {self.max_batch_size}"
                    )
                except asyncio.TimeoutError:
                    print(
                        "[In-Flight Batching] Timeout reached => proceeding with the batch."
                    )
                    break
            self.batch_counter += 1
            
            # 현재 배치 정보 로깅
            log_batch_info(batch)
            log_system_info("배치 처리 전 상태")

            # We have a batch of items: each item is ( http_query_or_stream_dict, future, sse_queue )
            # We'll process them concurrently.
            tasks = []
            for request_tuple in batch:
                request_obj, fut, sse_queue = request_tuple
                tasks.append(self._process_single_query(request_obj, fut, sse_queue))

            # Actually run them all concurrently
            await asyncio.gather(*tasks)
            log_system_info("배치 처리 후 상태")

    async def _process_single_query(self, http_query_or_stream_dict, future, sse_queue):
        """
        Process a single query from the micro-batch. If 'sse_queue' is given,
        we do partial-token streaming. Otherwise, normal final result.
        """
        # 스트리밍 요청인 경우 request_id를 미리 초기화
        request_id = None
        print(
            f"[DEBUG] _process_single_query 시작: {time.strftime('%H:%M:%S')}, 요청 내용: {http_query_or_stream_dict}, 현재 스레드: {threading.current_thread().name}"
        )
        try:
            # 1) 스트리밍 구분
            if (isinstance(http_query_or_stream_dict, dict)
                and "request_id" in http_query_or_stream_dict):
                # 스트리밍
                request_id = http_query_or_stream_dict["request_id"]
                http_query = http_query_or_stream_dict["http_query"]
                is_streaming = True
                print(f"[STREAM] _process_single_query: request_id={request_id}")
            else:
                # Non-스트리밍
                request_id = None
                http_query = http_query_or_stream_dict
                is_streaming = False
                print("[NORMAL] _process_single_query started...")
                
            # 2) Memory 객체 정보 가져오기 (없으면 새로 생성)
            page_id = http_query.get("page_id", request_id)
            memory = self.get_memory_for_session(page_id)

            # 3) 유저가 현재 입력한 쿼리 가져오기
            user_input = http_query.get("qry_contents", "")
            
            # 4) LangChain Memory에서 이전 대화 이력(history) 추출
            past_context = memory.load_memory_variables({}).get("history", [])
            # history가 리스트 형식인 경우 (각 메시지가 별도 항목으로 저장되어 있다면)
            if isinstance(past_context, list):
                recent_messages = [msg if isinstance(msg, str) else msg.content for msg in past_context[-5:]]
                past_context = "\n\n".join(recent_messages)
            else:
                # 문자열인 경우, 메시지 구분자를 "\n\n"으로 가정하여 분리
                messages = str(past_context).split("\n\n")
                recent_messages = messages[-5:]
                past_context = "\n\n".join(recent_messages)
            
            # # 2) 추가: 전체 토큰 수가 4000개를 초과하면 마지막 4000 토큰만 유지
            # past_tokens = self.tokenizer.tokenize(str(past_context))
            # if len(past_tokens) > 4000:
            #     past_tokens = past_tokens[-4000:]
            #     past_context = self.tokenizer.convert_tokens_to_string(past_tokens)
            
            # ★ 토큰 수 계산 코드 추가 ★
            # retrieval 자료는 dict나 리스트일 수 있으므로 문자열로 변환하여 토큰화합니다.
            # 각 입력값을 명시적으로 str()로 변환합니다.
            past_tokens = self.tokenizer.tokenize(str(past_context))
            query_tokens = self.tokenizer.tokenize(str(user_input))
            total_tokens = len(past_tokens) + len(query_tokens)
            print(f"[DEBUG] Token counts - 이전 대화: {len(past_tokens)}, 사용자 입력 질문: {len(query_tokens)}, 총합: {total_tokens}")
            
            # # To Calculate the token
            # tokens = self.tokenizer(user_input, add_special_tokens=True)["input_ids"]
            # print(f"[DEBUG] Processing query: '{user_input}' with {len(tokens)} tokens")

            # 5) 필요하다면 RAG 데이터를 다시 로드(1.16version 유지)
            self.data = load_data(
                self.config.data_path
            )  # if you want always-latest, else skip

            # 6) 현재 사용중인 Thread 확인
            print("   ... calling query_sort() ...")
            # print(
            #     f"[DEBUG] query_sort 시작 (offload) - 스레드: {threading.current_thread().name}"
            # )
            # 7) “대화 이력 + 현재 사용자 질문”을 Prompt에 합쳐서 RAG 수행
            #    방법 1) query_sort() 전에 past_context를 참조해 query를 확장
            #    방법 2) generate_answer()에서 Prompt 앞부분에 붙임
            # 여기서는 예시로 “query_sort”에 past_context를 넘겨
            # 호출부 수정 "user_input": f"{past_context}\n사용자 질문: {user_input}",
            params = {
                "user_input": f"사용자 질문: {user_input}",
                "model": self.model,
                "tokenizer": self.tokenizer,
                "embed_model": self.embed_model,
                "embed_tokenizer": self.embed_tokenizer,
                "data": self.data,
                "config": self.config,
            }
            QU, KE, TA, TI = await query_sort(params)
            print(f"   ... query_sort => QU={QU}, KE={KE}, TA={TA}, TI={TI}")

            # 4) RAG
            if TA == "yes":
                try:
                    print("[SOOWAN] config 설정 : ", self.config)
                    docs, docs_list = await execute_rag(
                        QU,
                        KE,
                        TA,
                        TI,
                        model=self.model,
                        tokenizer=self.tokenizer,
                        embed_model=self.embed_model,
                        embed_tokenizer=self.embed_tokenizer,
                        data=self.data,
                        config=self.config,
                    )
                    try:
                                                # 기존 방식
                        retrieval, chart = process_to_format(docs_list, type="SQL")
                        # 수정된 방식 - Talbe,Chart 없이 Answer Part에 SQL 결과 전송.
                        # retrieval_sql = process_to_format(docs, type="Answer")
                        # await self.queue_manager.put_token.remote(request_id, retrieval_sql)
                    except Exception as e:
                        print("[ERROR] process_to_format (SQL) failed:", str(e))
                        retrieval, chart = [], None

                    # If streaming => partial tokens
                    if is_streaming:
                        print(
                            f"[STREAM] Starting partial generation for request_id={request_id}"
                        )
                        await self._stream_partial_answer(
                            QU, docs, retrieval, chart, request_id, future, user_input
                        )
                    else:
                        # normal final result
                        output = await generate_answer(
                            QU,
                            docs,
                            model=self.model,
                            tokenizer=self.tokenizer,
                            config=self.config,
                        )
                        answer = process_to_format([output, chart], type="Answer")
                        final_data = [retrieval, answer]
                        outputs = process_format_to_response(final_data, qry_id=None, continue_="C")
                        
                        # >>> Record used chunk IDs
                        # 변경 후: retrieval 결과에서 추출
                        chunk_ids_used = []
                        print("---------------- chunk_id 찾기 : ", retrieval.get("rsp_data", []))
                        for doc in retrieval.get("rsp_data", []):
                            if "chunk_id" in doc:
                                chunk_ids_used.append(doc["chunk_id"])
                                                        
                        # >>> CHANGED: summarize the conversation
                        # loop = asyncio.get_event_loop()
                        # prev_summary = memory.load_memory_variables({}).get("summary", "")
                        # new_entry = f"User: {user_input}\nAssistant: {output}\nUsed Chunks: {chunk_ids_used}\n"
                        # updated_conversation = prev_summary + "\n" + new_entry
                        # # Summarized CPU 사용
                        # # import concurrent.futures

                        # # Create a dedicated pool with more workers (e.g., 4)
                        # # summary_pool = concurrent.futures.ProcessPoolExecutor(max_workers=4)

                        # # Later, when calling the summarization function:
                        # summarized = loop.run_in_executor(None, summarize_conversation, updated_conversation)
                        # # # After obtaining 'summarized' in _process_single_query:
                        # # if not summarized:
                        # #     print("[ERROR] Summarization returned an empty string.")
                        # # else:
                        # #     print(f"[CHECK] Summarized conversation: {summarized}")
                        # memory.save_context({"input": user_input}, {"output": output, "chunk_ids": chunk_ids_used})
                                            # 메모리에 저장
                        try:
                            memory.save_context(
                                {
                                    "qry_contents": user_input,
                                    "qry_id": http_query.get("qry_id"),
                                    "user_id": http_query.get("user_id"),
                                    "auth_class": http_query.get("auth_class"),
                                    "qry_time": http_query.get("qry_time")
                                },
                                {
                                    "output": output,
                                    "chunk_ids": chunk_ids_used
                                }
                            )
                        except Exception as e:
                            print(f"[ERROR memory.save_context] {e}")
                        # >>> CHANGED -----------------------------------------------------
                        future.set_result(outputs)

                except Exception as e:
                    outputs = error_format("내부 Excel 에 해당 자료가 없습니다.", 551)
                    future.set_result(outputs)

            else:
                try:
                    print("[SOOWAN] TA is No, before make a retrieval")
                    QU, KE, TA, TI = await specific_question(params) # TA == no, so that have to remake the question based on history
                    
                    docs, docs_list = await execute_rag(
                        QU,
                        KE,
                        TA,
                        TI,
                        model=self.model,
                        tokenizer=self.tokenizer,
                        embed_model=self.embed_model,
                        embed_tokenizer=self.embed_tokenizer,
                        data=self.data,
                        config=self.config,
                    )
                    retrieval = process_to_format(docs_list, type="Retrieval")
                    print("[SOOWAN] TA is No, and make a retrieval is successed")
                    if is_streaming:
                        print(
                            f"[STREAM] Starting partial generation for request_id={request_id}"
                        )
                        await self._stream_partial_answer(
                            QU, docs, retrieval, None, request_id, future, user_input
                        )
                    else:
                        output = await generate_answer(
                            QU,
                            docs,
                            model=self.model,
                            tokenizer=self.tokenizer,
                            config=self.config,
                        )
                        print("process_to_format 이후에 OUTPUT 생성 완료")
                        answer = process_to_format([output], type="Answer")
                        print("process_to_format 이후에 ANSWER까지 생성 완료")
                        final_data = [retrieval, answer]
                        outputs = process_format_to_response(final_data, qry_id=None, continue_="C")
                        
                        # >>> CHANGED: Record used chunk ID
                        chunk_ids_used = []
                        print("---------------- chunk_id 찾기 : ", retrieval.get("rsp_data", []))
                        for doc in retrieval.get("rsp_data", []):
                            if "chunk_id" in doc:
                                chunk_ids_used.append(doc["chunk_id"])
                                
                        
                        # loop = asyncio.get_event_loop()
                        # prev_summary = memory.load_memory_variables({}).get("summary", "")
                        # new_entry = f"User: {user_input}\nAssistant: {output}\nUsed Chunks: {chunk_ids_used}\n"
                        # updated_conversation = prev_summary + "\n" + new_entry
                        # # # Summarized CPU 사용
                        # # import concurrent.futures
                        
                        # # # Create a dedicated pool with more workers (e.g., 4)
                        # # summary_pool = concurrent.futures.ProcessPoolExecutor(max_workers=4)
                        
                        # # Later, when calling the summarization function:
                        # summarized = loop.run_in_executor(None, summarize_conversation, updated_conversation)
                        
                        # memory.save_context({"input": user_input}, {"output": output, "chunk_ids": chunk_ids_used})
                                            # 메모리 저장
                        try:
                            memory.save_context(
                                {
                                    "qry_contents": user_input,
                                    "qry_id": http_query.get("qry_id"),
                                    "user_id": http_query.get("user_id"),
                                    "auth_class": http_query.get("auth_class"),
                                    "qry_time": http_query.get("qry_time")
                                },
                                {
                                    "output": output,
                                    "chunk_ids": chunk_ids_used
                                }
                            )
                        except Exception as e:
                            print(f"[ERROR memory.save_context] {e}")
                        # --------------------------------------------------------------------
                        
                        future.set_result(outputs)

                except Exception as e:
                    # ====== 이 부분에서 SSE를 즉시 닫고 스트리밍 종료 ======
                    err_msg = f"[ERROR] 처리 중 오류 발생: {str(e)}"
                    print(err_msg)

                    # SSE 전송 (error 이벤트)
                    if request_id:
                        try:
                            error_token = json.dumps({"type": "error", "message": err_msg}, ensure_ascii=False)
                            await self.queue_manager.put_token.remote(request_id, error_token)
                            # 스트리밍 종료
                            await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")
                        except Exception as e2:
                            print(f"[ERROR] SSE 전송 중 추가 예외 발생: {str(e2)}")
                        finally:
                            # SSEQueue 정리
                            await self.close_sse_queue(request_id)

                    # Future 응답도 에러로
                    future.set_result(error_format(str(e), 500))
                    return
                
        except Exception as e:
            err_msg = f"[ERROR] 처리 중 오류 발생: {str(e)}"
            print("[ERROR]", err_msg)
            # SSE 스트리밍인 경우 error 토큰과 종료 토큰 전송
            if request_id:
                try:
                    error_token = json.dumps({"type": "error", "message": err_msg}, ensure_ascii=False)
                    await self.queue_manager.put_token.remote(request_id, error_token)
                except Exception as e2:
                    print(f"[ERROR] SSE 전송 중 추가 예외 발생: {str(e2)}")
            future.set_result(error_format(err_msg, 500))
        finally:
            # 스트리밍 요청인 경우 반드시 SSE 큐에 종료 토큰을 넣고 큐를 정리한다.
            if request_id:
                try:
                    await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")
                except Exception as ex:
                    print(f"[DEBUG] Error putting STREAM_DONE: {str(ex)}")
                await self.close_sse_queue(request_id)

    # ------------------------------------------------------------
    # HELPER FOR STREAMING PARTIAL ANSWERS (Modified to send reference)
    # ------------------------------------------------------------
    async def _stream_partial_answer(
        self, QU, docs, retrieval, chart, request_id, future, user_input
    ):
        """
        Instead of returning a final string, we generate partial tokens
        and push them to the SSE queue in real time.
        We'll do a "delta" approach so each chunk is only what's newly added.
        """
        print(
            f"[STREAM] _stream_partial_answer => request_id={request_id}, chart={chart}"
        )

        # 단일
        # queue = self.active_sse_queues.get(request_id)
        # if not queue:
        #     print(f"[STREAM] SSE queue not found => fallback to normal final (request_id={request_id})")
        #     # fallback...
        #     return

        # This will hold the entire text so far. We'll yield only new pieces.
        
        # 먼저, 참조 데이터 전송: type을 "reference"로 명시
        reference_json = json.dumps({
            "type": "reference",
            "status_code": 200,
            "result": "OK",
            "detail": "Reference data",
            "evt_time": datetime.datetime.now().isoformat(),
            "data_list": [retrieval]
        }, ensure_ascii=False)
        # Debug: print the reference JSON before sending
        print(f"[DEBUG] Prepared reference data: {reference_json}")
        await self.queue_manager.put_token.remote(request_id, reference_json)
        
        print(f"[STREAM] Sent reference data for request_id={request_id}")
        
        # 1) 메모리 가져오기 (없으면 생성)
        try:
            memory = self.get_memory_for_session(request_id)
        except Exception as e:
            msg = f"[STREAM] Error retrieving memory for {request_id}: {str(e)}"
            print(msg)
            # 에러 응답을 SSE로 전송하고 종료
            error_token = json.dumps({"type":"error","message":msg}, ensure_ascii=False)
            await self.queue_manager.put_token.remote(request_id, error_token)
            await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")
            future.set_result(error_format(msg, 500))
            return
        
        # 2) 과거 대화 이력 로드
        try:
            past_context = memory.load_memory_variables({})["history"]
            # history가 리스트 형식인 경우 (각 메시지가 별도 항목으로 저장되어 있다면)
            if isinstance(past_context, list):
                recent_messages = [msg if isinstance(msg, str) else msg.content for msg in past_context[-5:]]
                past_context = "\n\n".join(recent_messages)
            else:
                # 문자열인 경우, 메시지 구분자를 "\n\n"으로 가정하여 분리
                messages = str(past_context).split("\n\n")
                recent_messages = messages[-5:]
                past_context = "\n\n".join(recent_messages)
            
            # # 2) 추가: 전체 토큰 수가 4000개를 초과하면 마지막 4000 토큰만 유지
            # past_tokens = self.tokenizer.tokenize(str(past_context))
            # if len(past_tokens) > 4000:
            #     past_tokens = past_tokens[-4000:]
            #     past_context = self.tokenizer.convert_tokens_to_string(past_tokens)
        except KeyError:
            # 만약 "history" 키가 없으면 빈 문자열로 처리
            print(f"[STREAM] No 'history' in memory for {request_id}, using empty.")
            past_context = ""
        except Exception as e:
            msg = f"[STREAM] load_memory_variables error for {request_id}: {str(e)}"
            print(msg)
            error_token = json.dumps({"type":"error","message":msg}, ensure_ascii=False)
            await self.queue_manager.put_token.remote(request_id, error_token)
            await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")
            future.set_result(error_format(msg, 500))
            return

        # 3) 최종 프롬프트 구성
        final_query = f"{past_context}\n\n[사용자 질문]\n{QU}"
        print(f"[STREAM] final_query = \n{final_query}")
        
        # ★ 토큰 수 계산 코드 추가 ★
        # retrieval 자료는 dict나 리스트일 수 있으므로 문자열로 변환하여 토큰화합니다.
        retrieval_str = str(retrieval)
        # 각 입력값을 명시적으로 str()로 변환합니다.
        past_tokens = self.tokenizer.tokenize(str(past_context))
        query_tokens = self.tokenizer.tokenize(str(QU))
        retrieval_tokens = self.tokenizer.tokenize(retrieval_str)
        total_tokens = len(self.tokenizer.tokenize(str(final_query))) + len(retrieval_tokens)
        print(f"[DEBUG] Token counts - 이전 대화: {len(past_tokens)}, RAG 검색 자료: {len(retrieval_tokens)}, 사용자 구체화 질문: {len(query_tokens)}, 총합: {total_tokens}")
        
        partial_accumulator = ""

        try:
            print(
                f"[STREAM] SSE: calling generate_answer_stream for request_id={request_id}"
            )
            async for partial_text in generate_answer_stream(
                final_query, docs, self.model, self.tokenizer, self.config
            ):
                # print(f"[STREAM] Received partial_text: {partial_text}")
                new_text = partial_text[len(partial_accumulator) :]
                partial_accumulator = partial_text
                # # 원래 코드
                # if not new_text.strip():
                #     continue

                # 수정 예시: new_text가 완전히 빈 문자열("")인 경우에만 건너뛰기
                if new_text == "":
                    continue
                
                # Wrap answer tokens in a JSON object with type "answer"
                answer_json = json.dumps({
                    "type": "answer",
                    "answer": new_text
                }, ensure_ascii=False)
                # Use the central SSEQueueManager to put tokens
                # print(f"[STREAM] Sending token: {answer_json}")
                await self.queue_manager.put_token.remote(request_id, answer_json)
            final_text = partial_accumulator
            # # 이제 memory에 저장 (이미 request_id를 알고 있다고 가정) # 랭체인
            # try:
            #     memory.save_context({"input": user_input}, {"output": final_text})
            # except Exception as e:
            #     msg = f"[STREAM] memory.save_context failed: {str(e)}"
            #     print(msg)
                
                
            # >>> CHANGED: Update conversation summary in streaming branch as well
            chunk_ids_used = []
            print("---------------- chunk_id 찾기 : ", retrieval.get("rsp_data", []))
            for doc in retrieval.get("rsp_data", []):
                if "chunk_id" in doc:
                    chunk_ids_used.append(doc["chunk_id"])
                    
            # memory.save_context({"input": user_input}, {"output": final_text, "chunk_ids": chunk_ids_used})
            
            # 메모리 저장
            try:
                memory.save_context(
                    {
                        "qry_contents": user_input,
                        "qry_id": "",  # 필요한 경우 http_query에 있는 값을 넣음
                    },
                    {
                        "output": final_text,
                        "chunk_ids": chunk_ids_used
                    }
                )
            except Exception as e:
                print(f"[ERROR memory.save_context in stream] {e}")
            
            print("메시지 저장 직후 chunk_id 확인 : ", memory)
            # >>> CHANGED: -------------------------------------------------------
            
            # 최종 응답 구조
            if chart is not None:
                ans = process_to_format([final_text, chart], type="Answer")
                final_res = process_format_to_response(retrieval, ans)
            else:
                ans = process_to_format([final_text], type="Answer")
                final_res = process_format_to_response(retrieval, ans)
                
            # 담아서 보내기
            future.set_result(final_res)
            await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")
            print(
                f"[STREAM] done => placed [[STREAM_DONE]] for request_id={request_id}"
            )
        except Exception as e:
            msg = f"[STREAM] error in partial streaming => {str(e)}"
            print(msg)
            future.set_result(error_format(msg, 500))
            await self.queue_manager.put_token.remote(request_id, "[[STREAM_DONE]]")

    # --------------------------------------------------------
    # EXISTING METHODS FOR NORMAL QUERIES (unchanged)
    # --------------------------------------------------------
    async def process_query(self, http_query):
        """
        Existing synchronous method. Returns final string/dict once done.
        """
        loop = asyncio.get_event_loop()
        future = loop.create_future()
        # There's no SSE queue for normal queries
        sse_queue = None
        await self.request_queue.put((http_query, future, sse_queue))
        # print("self.request_queue : ", self.request_queue)
        return await future
    # ----------------------
    # 1) Streaming Entrypoint
    # ----------------------
    async def process_query_stream(self, http_query: dict) -> str:
        """
        /query_stream 호출 시 page_id(채팅방 id)를 기반으로 SSE queue 생성하고,
        대화 저장에 활용할 수 있도록 합니다.
        """
        # page_id를 채팅방 id로 사용 (없으면 생성)
        chat_id = http_query.get("page_id")
        if not chat_id:
            chat_id = str(uuid.uuid4())
        http_query["page_id"] = chat_id  # 강제 할당
        await self.queue_manager.create_queue.remote(chat_id)
        print(f"[STREAM] process_query_stream => chat_id={chat_id}, http_query={http_query}")

        loop = asyncio.get_event_loop()
        final_future = loop.create_future()

        sse_queue = asyncio.Queue()
        self.active_sse_queues[chat_id] = sse_queue
        print(f"[STREAM] Created SSE queue for chat_id={chat_id}")

        # 기존과 동일하게 micro-batch queue에 푸시 (http_query에 새 필드들이 포함됨)
        queued_item = {
            "request_id": chat_id,   # 내부적으로 page_id를 request_id처럼 사용
            "http_query": http_query,
        }

        print(f"[STREAM] Putting item into request_queue for chat_id={chat_id}")
        await self.request_queue.put((queued_item, final_future, sse_queue))
        print(f"[STREAM] Done putting item in queue => chat_id={chat_id}")

        return chat_id


    # ----------------------
    # 2) SSE token popping
    # ----------------------
    async def pop_sse_token(self, request_id: str) -> Optional[str]:
        """
        The SSE route calls this repeatedly to get partial tokens.
        If no token is available, we block up to 120s, else return None.
        """
        if request_id not in self.active_sse_queues:
            print(
                f"[STREAM] pop_sse_token => no SSE queue found for request_id={request_id}"
            )
            return None

        queue = self.active_sse_queues[request_id]
        try:
            token = await asyncio.wait_for(queue.get(), timeout=120.0)
            # print(f"[STREAM] pop_sse_token => got token from queue: {token}")
            return token
        except asyncio.TimeoutError:
            print(
                f"[STREAM] pop_sse_token => timed out waiting for token, request_id={request_id}"
            )
            return None

    # ----------------------
    # 3) SSE queue cleanup
    # ----------------------
    async def close_sse_queue(self, request_id: str):
        """
        Called by the SSE route after finishing.
        Remove the queue from memory.
        """
        if request_id in self.active_sse_queues:
            print(
                f"[STREAM] close_sse_queue => removing SSE queue for request_id={request_id}"
            )
            del self.active_sse_queues[request_id]
        else:
            print(f"[STREAM] close_sse_queue => no SSE queue found for {request_id}")
    
    # ----------------------
    # /history | 대화 기록 가져오기
    # ----------------------
    async def get_conversation_history(self, request_id: str) -> dict:
        """
        Returns the conversation history for the given request_id.
        The messages are serialized into a JSON-friendly format.
        """
        try:
            if request_id in self.memory_map:
                memory = self.memory_map[request_id]
                history_obj = memory.load_memory_variables({})
                if "history" in history_obj and isinstance(history_obj["history"], list):
                    # 직렬화
                    serialized = [serialize_message(msg) for msg in history_obj["history"]]
                    print("[HISTORY] 대화 기록 반환(직렬화) : ", serialized)
                    return {"history": serialized}
                else:
                    print("[HISTORY] 대화 기록 반환(직렬화X) : ", history_obj)
                    return {"history": []}
            else:
                return {"history": []}
        except Exception as e:
            print(f"[ERROR get_conversation_history] {e}")
            return {"history": []}
        
    # ----------------------
    # /reference | 해당 답변의 출처 가져오기
    # ----------------------
    async def get_reference_data(self, chunk_ids: list):
        try:
            result = []
            data = self.data
            for cid in chunk_ids:
                if cid in data["chunk_ids"]:
                    idx = data["chunk_ids"].index(cid)
                    record = {
                        "file_name": data["file_names"][idx],
                        "title": data["titles"][idx],
                        "text": data["texts_vis"][idx],
                        "date": str(data["times"][idx])
                    }
                    result.append(record)
            return result
        except Exception as e:
            print(f"[ERROR get_reference_data] {e}")
            return []

# Ray Serve를 통한 배포
@serve.deployment(name="inference", max_ongoing_requests=100)
class InferenceService:
    def __init__(self, config):
        self.config = config
        self.actor = InferenceActor.options(
            num_gpus=config.ray.num_gpus, 
            num_cpus=config.ray.num_cpus
        ).remote(config)

    async def query(self, http_query: dict):
        result = await self.actor.process_query.remote(http_query)
        return result

    async def process_query_stream(self, http_query: dict) -> str:
        req_id = await self.actor.process_query_stream.remote(http_query)
        return req_id

    async def pop_sse_token(self, req_id: str) -> str:
        token = await self.actor.pop_sse_token.remote(req_id)
        return token

    async def close_sse_queue(self, req_id: str) -> str:
        await self.actor.close_sse_queue.remote(req_id)
        return "closed"
    
    # /history
    async def get_history(self, request_id: str, last_index: int = None):
        result = await self.actor.get_conversation_history.remote(request_id)
        if last_index is not None and isinstance(result.get("history"), list):
            result["history"] = result["history"][last_index+1:]
        return result

    # /reference
    async def get_reference_data(self, chunk_ids: list):
        result = await self.actor.get_reference_data.remote(chunk_ids)
        return result

# Ray의 요청을 비동기적으로 관리하기 위해 도입하는 큐-매니저
@ray.remote
class SSEQueueManager:
    def __init__(self):
        self.active_queues = {}
        self.lock = asyncio.Lock()

    async def create_queue(self, request_id):
        async with self.lock:
            self.active_queues[request_id] = asyncio.Queue()
            return True

    async def get_queue(self, request_id):
        return self.active_queues.get(request_id)

    async def get_token(self, request_id, timeout: float):
        queue = self.active_queues.get(request_id)
        if queue:
            try:
                token = await asyncio.wait_for(queue.get(), timeout=timeout)
                return token
            except asyncio.TimeoutError:
                return None
        return None

    async def put_token(self, request_id, token):
        async with self.lock:
            if request_id in self.active_queues:
                await self.active_queues[request_id].put(token)
                return True
            return False

    async def delete_queue(self, request_id):
        async with self.lock:
            if request_id in self.active_queues:
                del self.active_queues[request_id]
                return True
            return False

```


--- ray_deploy/langchain.py

```python

# ray_deploy/langchain.py

# 랭체인 도입
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage

# =============================================================================
# Custom Conversation Memory to store extra metadata (e.g., chunk_ids)
# =============================================================================
class CustomConversationBufferMemory(ConversationBufferMemory):
    """대화 저장 시 추가 메타데이터를 함께 기록"""
    def save_context(self, inputs: dict, outputs: dict) -> None:
        """
        inputs, outputs 예시:
            inputs = {
                "qry_contents": "사용자 질문",
                "qry_id": "...",
                "user_id": "...",
                "auth_class": "...",
                "qry_time": "..."
            }
            outputs = {
                "output": "AI의 최종 답변",
                "chunk_ids": [...참조 chunk_id 리스트...]
            }
        """
        try:
            user_content = inputs.get("qry_contents", "")
            human_msg = HumanMessage(
                content=user_content,
                additional_kwargs={
                    "qry_id": inputs.get("qry_id"),
                    "user_id": inputs.get("user_id"),
                    "auth_class": inputs.get("auth_class"),
                    "qry_time": inputs.get("qry_time")
                }
            )
            ai_content = outputs.get("output", "")
            ai_msg = AIMessage(
                content=ai_content,
                additional_kwargs={
                    "chunk_ids": outputs.get("chunk_ids", []),
                    "qry_id": inputs.get("qry_id"),
                    "user_id": inputs.get("user_id"),
                    "auth_class": inputs.get("auth_class"),
                    "qry_time": inputs.get("qry_time")
                }
            )

            self.chat_memory.messages.append(human_msg)
            self.chat_memory.messages.append(ai_msg)
        except Exception as e:
            print(f"[ERROR in save_context] {e}")
        
    def load_memory_variables(self, inputs: dict) -> dict:
        """
        랭체인 규약에 의해 {"history": [메시지 리스트]} 형태 리턴
        """
        try:
            return {"history": self.chat_memory.messages}
        except Exception as e:
            print(f"[ERROR in load_memory_variables] {e}")
            return {"history": []}

# Serialization function for messages
def serialize_message(msg):
    """
    HumanMessage -> {"role": "human", "content": ...}
    AIMessage    -> {"role": "ai", "content": ..., "references": [...]}
    """
    try:
        if isinstance(msg, HumanMessage):
            return {"role": "human", "content": msg.content}
        elif isinstance(msg, AIMessage):
            refs = msg.additional_kwargs.get("chunk_ids", [])
            # 디버그 출력
            print(f"[DEBUG serialize_message] AI refs: {refs}")
            return {"role": "ai", "content": msg.content, "references": refs}
        else:
            return {
                "role": "unknown",
                "content": getattr(msg, "content", str(msg))
            }
    except Exception as e:
        print(f"[ERROR in serialize_message] {e}")
        return {"role": "error", "content": str(e)}
    
# =============================================================================
# =============================================================================

```


--- utils/utils_format.py

```python

# utils/utils_format.py
import json
from datetime import datetime, timedelta

import requests

# Define the minimum valid file size (e.g., 10MB)
MIN_WEIGHT_SIZE = 10 * 1024 * 1024

# For tracking execution time of functions
from utils.tracking import time_tracker

# Logging
import logging
logging.basicConfig(level=logging.DEBUG)

# -------------------------------------------------
# Function: process_to_format
# -------------------------------------------------
@time_tracker
def process_to_format(qry_contents, type):
    # 여기서 RAG 시스템을 호출하거나 답변을 생성하도록 구현하세요.
    # 예제 응답 형식
    ### rsp_type : RA(Retrieval All), RT(Retrieval Text), RB(Retrieval taBle), AT(Answer Text), AB(Answer taBle) ###
    print("[SOOWAN] process_to_format 진입")
    if type == "Retrieval":
        print("[SOOWAN] 타입 : 리트리버")
        tmp_format = {"rsp_type": "R", "rsp_tit": "남성 내부 데이터", "rsp_data": []}
        for i, form in enumerate(qry_contents):
            tmp_format_ = {
                "rsp_tit": f"{i+1}번째 검색데이터: {form['title']} (출처:{form['file_name']})",
                "rsp_data": form["contents"],
                "chunk_id": form.get("chunk_id"),
            }
            tmp_format["rsp_data"].append(tmp_format_)
        return tmp_format

    elif type == "SQL":
        print("[SOOWAN] 타입 : SQL")
        tmp_format = {
            "rsp_type": "R",
            "rsp_tit": "남성 내부 데이터",
            "rsp_data": [{"rsp_tit": "SQL Query 결과표", "rsp_data": []}],
        }
        tmp_format_sql = {
            "rsp_type": "TB",
            "rsp_tit": qry_contents[0]["title"],
            "rsp_data": qry_contents[0]["data"],
        }
        tmp_format_chart = {
            "rsp_type": "CT",
            "rsp_tit": qry_contents[1]["title"],
            "rsp_data": {"chart_tp": "BAR", "chart_data": qry_contents[1]["data"]},
        }
        tmp_format["rsp_data"][0]["rsp_data"].append(tmp_format_sql)
        # tmp_format['rsp_data'].append(tmp_format_chart)
        return tmp_format, tmp_format_chart

    elif type == "Answer":
        print("[SOOWAN] 타입 : 대답")
        tmp_format = {"rsp_type": "A", "rsp_tit": "답변", "rsp_data": []}
        # for i, form in enumerate(qry_contents):
            # if i == 0:
        tmp_format_ = {"rsp_type": "TT", "rsp_data": qry_contents}
        tmp_format["rsp_data"].append(tmp_format_)
            # elif i == 1:
            #     tmp_format["rsp_data"].append(form)
            # else:
            #     None

        return tmp_format

    else:
        print("Error! Type Not supported!")
        return None

# @time_tracker
# def process_format_to_response(formats, qry_id, continue_="C", update_index=1):
#     # Get multiple formats to tuple

#     ans_format = {
#         "status_code": 200,
#         "result": "OK",
#         "detail": "",
#         "continue":continue_,
#         "qry_id": qry_id,
#         "rsp_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f"),
#         "data_list": [],
#     }

#     # 누적된 토큰을 하나의 문자열로 결합합니다.
#     aggregated_answer = "".join(token.get("answer", "") for token in formats)
#     ans_format["data_list"].append({
#         "rsp_type": "A",
#         "rsp_tit": f"답변{update_index}",
#         "rsp_data": [
#             {
#                 "rsp_type": "TT",
#                 "rsp_data": aggregated_answer
#             }
#         ]
#     })
    
#     # Validate JSON before returning
#     try:
#         json.dumps(ans_format, ensure_ascii=False)  # Test JSON validity
#     except Exception as e:
#         print(f"[ERROR] Invalid JSON structure: {str(e)}")
#         ans_format["status_code"] = 500
#         ans_format["result"] = "ERROR"
#         ans_format["detail"] = f"JSON Error: {str(e)}"

#     # for format in formats:
#     #     ans_format["data_list"].append(format)

#     # return json.dumps(ans_format, ensure_ascii=False)
#     return ans_format

@time_tracker
def process_format_to_response(formats, qry_id, continue_="C", update_index=1):
    # If there are any reference tokens, return only them.
    reference_tokens = [token for token in formats if token.get("type") == "reference"]
    if reference_tokens:
        # For this example, we'll use the first reference token.
        ref = reference_tokens[0]
        # Add the extra keys.
        ref["qry_id"] = qry_id
        ref["continue"] = continue_
        ref["rsp_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")
        # Ensure that a "rsp_tit" key exists to satisfy downstream requirements.
        if "rsp_tit" not in ref:
            ref["rsp_tit"] = "Reference"
        return ref

    # Otherwise, aggregate the normal answer tokens.
    normal_tokens = [token.get("answer", "") for token in formats if token.get("type") != "reference"]
    aggregated_answer = "".join(normal_tokens)
    
    ans_format = {
        "status_code": 200,
        "result": "OK",
        "detail": "",
        "continue": continue_,
        "qry_id": qry_id,
        "rsp_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f"),
        "data_list": [{
            "rsp_type": "A",
            "rsp_tit": f"답변{update_index}",
            "rsp_data": [{
                "rsp_type": "TT",
                "rsp_data": aggregated_answer
            }]
        }]
    }
    
    # Validate JSON structure before returning.
    try:
        json.dumps(ans_format, ensure_ascii=False)
    except Exception as e:
        print(f"[ERROR] Invalid JSON structure: {str(e)}")
        ans_format["status_code"] = 500
        ans_format["result"] = "ERROR"
        ans_format["detail"] = f"JSON Error: {str(e)}"
    
    return ans_format



# @time_tracker
# def process_format_to_response(formats, qry_id, continue_="C", update_index=1):
#     # 누적된 토큰들을 하나의 문자열로 결합합니다.
#     aggregated_answer = "".join(token.get("answer", "") for token in formats)
    
#     # retrieval과 동일한 구조를 위해, 답변 데이터는 내부 data_list가 딕셔너리 형태로 구성됩니다.
#     answer = {
#         "rsp_type": "A",                # Answer
#         "rsp_tit": f"답변{update_index}",
#         "rsp_data": [                    # 바로 텍스트 응답 리스트를 구성
#             {
#                 "rsp_tit": f"답변{update_index}",
#                 "rsp_data": [
#                     {
#                         'rsp_type': 'TT',
#                         'rsp_tit': '',
#                         'rsp_data': aggregated_answer,
#                     }
#                 ]
                
#             }
#         ]
#     }
    
#     # 최종 응답 구조: 최상위에 data_list는 리스트이고, 내부에 딕셔너리로 답변 데이터를 포함합니다.
#     ans_format = {
#         "status_code": 200,
#         "result": "OK",
#         "detail": "Answer",
#         "continue": continue_,
#         "qry_id": qry_id,
#         "rsp_time": datetime.now().isoformat(),
#         "data_list": [
#             {
#                 "type": "answer",               # 응답 타입 answer
#                 "status_code": 200,
#                 "result": "OK",
#                 "detail": "Answer",
#                 "evt_time": datetime.now().isoformat(),
#                 "data_list": answer              # retrieval의 data_list와 동일하게 딕셔너리 형태
#             }
#         ]
#     }
#     return ans_format

@time_tracker
def error_format(message, status, qry_id=""):
    ans_format = {
        "status_code": status,
        "result": message,
        "qry_id": qry_id,  # 추가: qry_id 포함
        "detail": "",
        "evt_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f"),
    }
    return json.dumps(ans_format)

# @time_tracker
# def send_data_to_server(data, url):
#     headers = {
#         "Content-Type": "application/json; charset=utf-8"
#     }
#     try:
#         # 다른 서버로 데이터를 전송 (POST 요청)
#         response = requests.post(url, json=data, headers=headers)
#         if response.status_code == 200:
#             print(f"Data sent successfully: {data}")
#         else:
#             print(f"Failed to send data: {response.status_code}")
#             print(f"Failed data: {data}")
#     except requests.exceptions.RequestException as e:
#         print(f"Error sending data: {e}")
@time_tracker     
def send_data_to_server(data, url):
    try:
        if not data or "data_list" not in data:
            print("[ERROR] Empty or Invalid data structure")
            return
        # Log reference data if present
        for item in data["data_list"]:
            if item.get("rsp_type") == "A" and "references" in str(item):
                print(f"[DEBUG] Sending reference data: {json.dumps(data, ensure_ascii=False, indent=2)}")
        response = requests.post(url, json=data, timeout=10)
        
        if response.status_code != 200:
            print(f"[ERROR] Failed to send data: {response.status_code}, {response.text}")
        
        return response

    except Exception as e:
        print(f"[ERROR] send_data_to_server encountered an error: {str(e)}")

```


--- utils/utils_load.py

```python

# utils/utils_load.py
import json
import numpy as np
import torch
import random
import shutil
from datetime import datetime, timedelta
from transformers import (
    AutoModel,
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    AutoConfig,
)

import os

# 전역 캐시 변수 - 데이터의 변화를 감지하기 위한
_cached_data = None
_cached_data_mtime = 0

# Import vLLM utilities
from vllm.engine.arg_utils import AsyncEngineArgs
from vllm.engine.async_llm_engine import AsyncLLMEngine

# Define the minimum valid file size (e.g., 10MB)
MIN_WEIGHT_SIZE = 10 * 1024 * 1024

# For tracking execution time of functions
from utils.tracking import time_tracker

# Logging
import logging
logging.basicConfig(level=logging.DEBUG)
# -------------------------------------------------
# Function: find_weight_directory - 허깅페이스 권한 문제 해결 후에 잘 사용되지 아니함
# -------------------------------------------------
# Recursively searches for weight files (safetensors or pytorch_model.bin) in a given base path.
# This method Find the files searching the whole directory
# Because, vLLM not automatically find out the model files.
# -------------------------------------------------
@time_tracker
def find_weight_directory(base_path):
    # ---- Recursively searches for weight files in a given base path ----
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if ".safetensors" in file or "pytorch_model.bin" in file:
                file_path = os.path.join(root, file)
                try:
                    if os.path.getsize(file_path) >= MIN_WEIGHT_SIZE:
                        return root, "safetensors" if ".safetensors" in file else "pt"
                    else:
                        logging.debug(
                            f"파일 {file_path}의 크기가 너무 작음: {os.path.getsize(file_path)} bytes"
                        )
                except Exception as ex:
                    logging.debug(f"파일 크기 확인 실패: {file_path} - {ex}")
    return None, None

# -------------------------------------------------
# Function: load_model
# -------------------------------------------------
@time_tracker
def load_model(config):
    # Loads the embedding model and the main LLM model (using vLLM if specified in the config).
    
    # Get the HF token from the environment variable.
    logging.info("Starting model loading...")
    token = os.getenv("HF_TOKEN_PATH")
    # Check if token is likely a file path.
    if token is not None and not token.startswith("hf_"):
        if os.path.exists(token) and os.path.isfile(token):
            try:
                with open(token, "r") as f:
                    token = f.read().strip()
            except Exception as e:
                print("DEBUG: Exception while reading token file:", e)
                logging.warning("Failed to read token from file: %s", e)
                token = None
        else:
            logging.warning("The HF_TOKEN path does not exist: %s", token)
            token = None
    else:
        print("DEBUG: HF_TOKEN appears to be a token string; using it directly:")

    if token is None or token == "":
        logging.warning("HF_TOKEN is not set. Access to gated models may fail.")
        token = None

    # -------------------------------
    # Load the embedding model and tokenizer.
    # -------------------------------
    print("Loading embedding model")
    try:
        embed_model = AutoModel.from_pretrained(
            config.embed_model_id,
            cache_dir=config.cache_dir,
            trust_remote_code=True,
            token=token,  # using 'token' parameter
        )
    except Exception as e:
        raise e
    try:
        embed_tokenizer = AutoTokenizer.from_pretrained(
            config.embed_model_id,
            cache_dir=config.cache_dir,
            trust_remote_code=True,
            token=token,
        )
    except Exception as e:
        raise e
    print(":Embedding tokenizer loaded successfully.")
    embed_model.eval()
    embed_tokenizer.model_max_length = 4096

    # -------------------------------
    # Load the main LLM model via vLLM.
    # -------------------------------
    if config.use_vllm:
        print("vLLM mode enabled. Starting to load main LLM model via vLLM.")
        if config.model.quantization_4bit:
            bnb_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.bfloat16,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4",
            )
            print("Using 4-bit quantization.")
        elif config.model.quantization_8bit:
            bnb_config = BitsAndBytesConfig(load_in_8bit=True)
            print("Using 8-bit quantization.")
        else:
            bnb_config = None
            print("Using pure option of Model(No quantization)")

        local_model_path = os.path.join(
            config.cache_dir, "models--" + config.model_id.replace("/", "--")
        )
        local_model_path = os.path.abspath(local_model_path)

        config_file = os.path.join(local_model_path, "config.json")
        need_patch = False

        if not os.path.exists(config_file):
            os.makedirs(local_model_path, exist_ok=True)
            try:
                hf_config = AutoConfig.from_pretrained(
                    config.model_id,
                    cache_dir=config.cache_dir,
                    trust_remote_code=True,
                    token=token,
                )
            except Exception as e:
                raise e
            # 패치: vocab_size 속성이 없으면 embed_tokenizer의 값을 사용하여 추가
            if not hasattr(hf_config, "vocab_size"):
                print("[MODEL-LOADING] 'vocab_size' 속성이 없어서 기본값으로 추가합니다.")
                hf_config.vocab_size = getattr(embed_tokenizer, "vocab_size", 32000)
            config_dict = hf_config.to_dict()
            if not config_dict.get("architectures"):
                print("[MODEL-LOADING] Config file의 architectures 정보 없음, Default Gemma2 아키텍처 설정")
                config_dict["architectures"] = ["Gemma2ForCausalLM"]
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(config_dict, f)
        else:
            # 이미 config_file이 존재하는 경우
            with open(config_file, "r", encoding="utf-8") as f:
                config_dict = json.load(f)

            if "vocab_size" not in config_dict:
                # embed_tokenizer의 vocab_size가 존재하면 사용하고, 없으면 기본값 30522로 설정
                config_dict["vocab_size"] = getattr(embed_tokenizer, "vocab_size", 30522)
                print("[MODEL-LOADING] 'vocab_size' 속성이 없어서 기본값으로 추가합니다:", config_dict["vocab_size"])
                with open(config_file, "w", encoding="utf-8") as f:
                    json.dump(config_dict, f)
            if not config_dict.get("architectures"):
                print("[MODEL-LOADING] Config file의 architectures 정보 없음, Default Gemma2 아키텍처 설정")
                config_dict["architectures"] = ["Gemma2ForCausalLM"]
                with open(config_file, "w", encoding="utf-8") as f:
                    json.dump(config_dict, f)

        weight_dir, weight_format = find_weight_directory(local_model_path)
        if weight_dir is None:
            print("DEBUG: No model weights found. Attempting to download model snapshot.")
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"DEBUG: Snapshot download attempt {attempt+1}...")
                    # Attempt to download the model snapshot using the Hugging Face hub function.
                    from huggingface_hub import snapshot_download
                    snapshot_download(config.model_id, cache_dir=config.cache_dir, token=token)
                    break  # If download succeeds, break out of the loop.
                except Exception as e:
                    print(f"DEBUG: Snapshot download attempt {attempt+1} failed:", e)
                    if attempt < max_retries - 1:
                        print("DEBUG: Retrying snapshot download...")
                    else:
                        raise RuntimeError(f"Snapshot download failed after {max_retries} attempts: {e}")
            # After download, try to find the weights again.
            weight_dir, weight_format = find_weight_directory(local_model_path)
            if weight_dir is None:
                raise RuntimeError(f"Unable to find model weights even after snapshot download in {local_model_path}.")

        snapshot_config = os.path.join(weight_dir, "config.json")
        if not os.path.exists(snapshot_config):
            shutil.copy(config_file, snapshot_config)
        engine_args = AsyncEngineArgs(
            model=weight_dir,
            tokenizer=config.model_id,
            download_dir=config.cache_dir,
            trust_remote_code=True,
            config_format="hf",
            load_format=weight_format,
        )
        
        vllm_conf = config.get("vllm", {})
        
        engine_args.enable_prefix_caching = True
        # engine_args.scheduler_delay_factor = vllm_conf.get("scheduler_delay_factor", 0.1)
        engine_args.enable_chunked_prefill = True
        engine_args.tensor_parallel_size = vllm_conf.get("tensor_parallel_size", 1) # Using Multi-GPU at once.
        engine_args.max_num_seqs = vllm_conf.get("max_num_seqs")
        engine_args.max_num_batched_tokens = vllm_conf.get("max_num_batched_tokens", 8192)
        # engine_args.block_size = vllm_conf.get("block_size", 128)
        engine_args.gpu_memory_utilization = vllm_conf.get("gpu_memory_utilization")
        
        if vllm_conf.get("disable_custom_all_reduce", False):
            engine_args.disable_custom_all_reduce = True # For Fixing the Multi GPU problem
            
        engine_args.max_model_len = vllm_conf.get("max_model_len")
        
        # # 새로 추가: disable_sliding_window 옵션 확인
        # if vllm_conf.get("disable_sliding_window", False):
        #     engine_args.sliding_window = (-1, -1)
        #     print("Sliding window disabled: engine_args.sliding_window set to (-1, -1)")
        
        # engine_args.enable_memory_defrag = True # v1 새로운 기능
        # engine_args.max_model_len = vllm_conf.get("max_model_len") # Context Length
        
        # # ★★ 추가: 슬라이딩 윈도우 비활성화 옵션 적용 ★★
        # if vllm_conf.get("disable_sliding_window", False):
        #     # cascade attention에서는 슬라이딩 윈도우가 (-1, -1)이어야 함
        #     engine_args.sliding_window = (-1, -1)
        #     print("Sliding window disabled: engine_args.sliding_window set to (-1, -1)")
        
        # print("Final EngineArgs:", engine_args)
        
        #         # ── 여기서 unified_attention 호출 추적을 위한 monkey-patch ──
        # try:
        #     if hasattr(torch.ops.vllm, "unified_attention_with_output"):
        #         orig_unified_attention = torch.ops.vllm.unified_attention_with_output
        #         def tracking_unified_attention(*args, **kwargs):
        #             logging.info("Called unified_attention_with_output with args: %s, kwargs: %s", args, kwargs)
        #             return orig_unified_attention(*args, **kwargs)
        #         torch.ops.vllm.unified_attention_with_output = tracking_unified_attention
        #         logging.info("Monkey-patched unified_attention_with_output for tracking.")
        # except Exception as e:
        #     logging.warning("Failed to monkey-patch unified_attention_with_output: %s", e)
        
        # # ── 끝 ──

        print("EngineArgs setting be finished")
        
        try:
            # --- v1 구동 해결책: 현재 스레드가 메인 스레드가 아니면 signal 함수를 임시 패치 ---
            import threading, signal
            if threading.current_thread() is not threading.main_thread():
                original_signal = signal.signal
                signal.signal = lambda s, h: None  # signal 설정 무시
                print("비메인 스레드에서 signal.signal을 monkey-patch 하였습니다.")
            # --- v1 구동 해결책: ------------------------------------------------------ ---
            engine = AsyncLLMEngine.from_engine_args(engine_args) # Original
            # v1 구동 해결책: 엔진 생성 후 원래 signal.signal으로 복원 (필요 시) ----------------- ---
            if threading.current_thread() is not threading.main_thread():
                signal.signal = original_signal
            # --- v1 구동 해결책: ------------------------------------------------------ ---
            print("DEBUG: vLLM engine successfully created.") # Original
            
        except Exception as e:
            print("DEBUG: Exception during engine creation:", e)
            if "HeaderTooSmall" in str(e):
                print("DEBUG: Falling back to PyTorch weights.")
                fallback_dir = None
                for root, dirs, files in os.walk(local_model_path):
                    for file in files:
                        if (
                            "pytorch_model.bin" in file
                            and os.path.getsize(os.path.join(root, file))
                            >= MIN_WEIGHT_SIZE
                        ):
                            fallback_dir = root
                            break
                    if fallback_dir:
                        break
                if fallback_dir is None:
                    logging.error(
                        "DEBUG: No PyTorch weight file found in", local_model_path
                    )
                    raise e
                engine_args.load_format = "pt"
                engine_args.model = fallback_dir
                print("DEBUG: New EngineArgs for fallback:", engine_args)
                engine = AsyncLLMEngine.from_engine_args(engine_args)
                print("DEBUG: vLLM engine created with PyTorch fallback.")
            else:
                logging.error("DEBUG: Engine creation failed:", e)
                raise e

        engine.is_vllm = True

        print("DEBUG: Loading main LLM tokenizer with token authentication.")
        try:
            tokenizer = AutoTokenizer.from_pretrained(
                config.model_id,
                cache_dir=config.cache_dir,
                trust_remote_code=True,
                token=token,
                local_files_only=True  # Force loading from local cache to avoid hub requests
            )
        except Exception as e:
            print("DEBUG: Exception loading main tokenizer:", e)
            raise e
        tokenizer.model_max_length = 4024
        return engine, tokenizer, embed_model, embed_tokenizer

    else:
        print("DEBUG: vLLM is not used. Loading model via standard HF method.")
        try:
            tokenizer = AutoTokenizer.from_pretrained(
                config.model_id,
                cache_dir=config.cache_dir,
                trust_remote_code=True,
                token=token,
            )
        except Exception as e:
            print("DEBUG: Exception loading tokenizer:", e)
            raise e
        tokenizer.model_max_length = 4024
        try:
            model = AutoModelForCausalLM.from_pretrained(
                config.model_id,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                cache_dir=config.cache_dir,
                # quantization_config=bnb_config,
                trust_remote_code=True,
                token=token,
            )
        except Exception as e:
            print("DEBUG: Exception loading model:", e)
            raise e
        model.eval()
        return model, tokenizer, embed_model, embed_tokenizer

# -------------------------------------------------
# Function: load_data
# -------------------------------------------------
@time_tracker
def load_data(data_path):
    global _cached_data, _cached_data_mtime
    try:
        current_mtime = os.path.getmtime(data_path)
    except Exception as e:
        print("파일 수정 시간 확인 실패:", e)
        return None

    # 캐시가 비어있거나 파일 수정 시간이 변경된 경우 데이터 재로드
    if _cached_data is None or current_mtime != _cached_data_mtime:
        with open(data_path, "r", encoding="utf-8") as json_file:
            data = json.load(json_file)

        # --- 디버그 함수: 벡터 포맷 검사 ---
        debug_vector_format(data)

        # 데이터 전처리 (예: 리스트 변환 및 numpy, torch 변환)
        file_names = []
        chunk_ids = []  # >>> CHANGED: Added to record each chunk's ID
        titles = []
        times = []
        vectors = []
        texts = []
        texts_short = []
        texts_vis = []
        missing_time = 0

        for file_obj in data:
            for chunk in file_obj["chunks"]:
                file_names.append(file_obj["file_name"])
                chunk_ids.append(chunk.get("chunk_id", 0))  # >>> CHANGED: Record chunk_id
                try:
                    arr = np.array(chunk["vector"])
                    vectors.append(arr)
                except Exception as e:
                    logging.warning(f"[load_data] 벡터 변환 오류: {e} → 빈 벡터로 대체")
                    vectors.append(np.zeros((1, 768), dtype=np.float32))  # 임의로 1x768 형식
                
                titles.append(chunk["title"])
                
                # 날짜 파싱
                if chunk["date"]:
                    try:
                        times.append(datetime.strptime(chunk["date"], "%Y-%m-%d"))
                    except ValueError:
                        logging.warning(f"잘못된 날짜 형식: {chunk['date']} → 기본 날짜로 대체")
                        times.append(datetime.strptime("2023-10-31", "%Y-%m-%d"))
                        missing_time += 1
                else:
                    missing_time += 1
                    times.append(datetime.strptime("2023-10-31", "%Y-%m-%d"))

                texts.append(chunk["text"])
                texts_short.append(chunk["text_short"])
                texts_vis.append(chunk["text_vis"])

        # 실제 텐서로 변환
        try:
            vectors = np.array(vectors)
            vectors = torch.from_numpy(vectors).to(torch.float32)
        except Exception as e:
            logging.error(f"[load_data] 최종 벡터 텐서 변환 오류: {str(e)}")
            # 필요 시 추가 처리

        _cached_data = {
            "file_names": file_names,
            "chunk_ids": chunk_ids,  # >>> CHANGED: Saved chunk IDs here
            "titles": titles,
            "times": times,
            "vectors": vectors,
            "texts": texts,
            "texts_short": texts_short,
            "texts_vis": texts_vis,
        }
        _cached_data_mtime = current_mtime
        print(f"Data loaded! Length: {len(titles)}, Missing times: {missing_time}")
    else:
        print("Using cached data")

    return _cached_data

# -------------------------------------------------
# Function: debug_vector_format
# -------------------------------------------------
def debug_vector_format(data):
    """
    data(List[Dict]): load_data에서 JSON으로 로드된 객체.
    각 file_obj에 대해 chunks 리스트를 순회하며 vector 형식을 디버깅 출력.
    """
    print("\n[DEBUG] ===== 벡터 형식 검사 시작 =====")
    for f_i, file_obj in enumerate(data):
        file_name = file_obj.get("file_name", f"Unknown_{f_i}")
        chunks = file_obj.get("chunks", [])
        for c_i, chunk in enumerate(chunks):
            vector_data = chunk.get("vector", None)
            if vector_data is None:
                # print(f"[DEBUG] file={file_name}, chunk_index={c_i} → vector 없음(None)")
                continue
            # 자료형, 길이, shape 등 확인
            vector_type = type(vector_data)
            # shape을 안전하게 얻기 위해 np.array 변환 시도
            try:
                arr = np.array(vector_data)
                shape = arr.shape
                # print(f"[DEBUG] file={file_name}, chunk_index={c_i} → vector_type={vector_type}, shape={shape}")
            except Exception as e:
                print(f"[DEBUG] file={file_name}, chunk_index={c_i} → vector 변환 실패: {str(e)}")
    print("[DEBUG] ===== 벡터 형식 검사 종료 =====\n")

# -------------------------------------------------
# Function: random_seed
# -------------------------------------------------
@time_tracker
def random_seed(seed):
    # Set random seed for Python's built-in random module
    random.seed(seed)

    # Set random seed for NumPy
    np.random.seed(seed)

    # Set random seed for PyTorch
    torch.manual_seed(seed)

    # Ensure the same behavior on different devices (CPU vs GPU)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.

    # Enable deterministic algorithms
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

```


--- utils/utils_vector.py

```python

# utils/utils_vector.py
import json
import torch
from transformers import (
    AutoModel,
    AutoTokenizer,
)

# Define the minimum valid file size (e.g., 10MB)
MIN_WEIGHT_SIZE = 10 * 1024 * 1024

# For tracking execution time of functions
from utils.tracking import time_tracker

# Logging
import logging
logging.basicConfig(level=logging.DEBUG)

# ---------------------- 벡터화 -----------------------
import yaml
from box import Box
# Configuration
with open("./config.yaml", "r") as f:
    config_yaml = yaml.load(f, Loader=yaml.FullLoader)
    config = Box(config_yaml)

# 임베딩 모델 및 토크나이저 (청크 벡터화를 위해 별도 로드)
embedding_model = AutoModel.from_pretrained(config.embed_model_id, cache_dir=config.cache_dir)
embedding_tokenizer = AutoTokenizer.from_pretrained(config.embed_model_id, cache_dir=config.cache_dir)
embedding_model.eval()

# -------------------- 벡터화 함수 --------------------
@time_tracker
def vectorize_content(content):
    try:
        inputs = embedding_tokenizer(content, padding=True, truncation=True, return_tensors="pt")
        with torch.no_grad():
            outputs = embedding_model(**inputs, return_dict=False)
        # 첫 토큰의 임베딩을 사용 (1D 벡터)
        vector = outputs[0][:, 0, :].squeeze(0).tolist()
        
        # 벡터 일관성 확인
        expected_dim = 768  # 임베딩 모델 차원에 맞게 조정
        
        # 리스트가 아닌 경우 변환 시도
        if not isinstance(vector, list):
            print(f"경고: 벡터가 리스트가 아님, 타입: {type(vector)}")
            try:
                vector = list(vector)
            except Exception as e:
                print("오류: 벡터를 리스트로 변환 실패:", e)
                vector = [0.0] * expected_dim  # 기본 벡터 제공
        
        # 벡터 차원 확인 및 조정
        if len(vector) != expected_dim:
            print(f"경고: 벡터 차원 불일치. 예상: {expected_dim}, 실제: {len(vector)}")
            if len(vector) < expected_dim:
                # 부족한 차원은 0으로 패딩
                vector.extend([0.0] * (expected_dim - len(vector)))
            else:
                # 초과 차원은 자르기
                vector = vector[:expected_dim]
        
        # 기존 파일 형식과 일치하도록 항상 2차원 배열 형식으로 반환 ([[...] 형태])
        if vector and not isinstance(vector[0], list):
            return [vector]
        return vector
    except Exception as e:
        print(f"vectorize_content 함수 오류: {str(e)}")
        # 오류 시 기본 벡터 반환 (2차원 형식)
        return [[0.0] * 768]

# -------------------- 텍스트 출력 필드 정규화 함수 --------------------
def normalize_text_vis(text_vis):
    """
    text_vis가 이미 올바른 리스트-딕셔너리 구조이면 그대로 반환하고,
    그렇지 않은 경우 기본 구조로 감싸서 반환합니다.
    """
    if isinstance(text_vis, list) and len(text_vis) > 0 and isinstance(text_vis[0], dict):
        # 필요한 키가 존재하는지 확인
        if all(k in text_vis[0] for k in ("rsp_type", "rsp_tit", "rsp_data")):
            return text_vis
    if isinstance(text_vis, str):
        return [{
            "rsp_type": "TT",
            "rsp_tit": "",
            "rsp_data": text_vis
        }]
    return [{
        "rsp_type": "TT",
        "rsp_tit": "",
        "rsp_data": str(text_vis)
    }]

# -------------------- 데이터셋 진단 및 수정 도구 --------------------
# 데이터셋 진단 및 복구 함수 (utils.py 또는 별도 파일에 추가)
def diagnose_and_fix_dataset(data_path, output_path=None):
    """
    데이터셋의 벡터 차원 문제를 진단하고 수정합니다.
    """
    try:
        print(f"데이터셋 진단 중: {data_path}")
        with open(data_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        print(f"데이터셋 내 파일 수: {len(data)}")
        dimensions = {}
        fixed_count = 0
        problem_count = 0
        
        # 1단계: 가장 흔한 차원 찾기
        for file_idx, file in enumerate(data):
            file_name = file.get("file_name", f"Unknown-{file_idx}")
            for chunk_idx, chunk in enumerate(file.get("chunks", [])):
                if "vector" in chunk and chunk["vector"]:
                    vector = chunk["vector"]
                    try:
                        if isinstance(vector, list):
                            dim = len(vector)
                            dimensions[dim] = dimensions.get(dim, 0) + 1
                        else:
                            print(f"벡터가 리스트가 아님: {file_name}, 청크 {chunk_idx}")
                            problem_count += 1
                    except Exception as e:
                        print(f"벡터 길이 확인 실패: {file_name}, 청크 {chunk_idx} - {str(e)}")
                        problem_count += 1
        
        if dimensions:
            # 가장 흔한 차원 찾기
            expected_dim = max(dimensions.items(), key=lambda x: x[1])[0]
            print(f"가장 흔한 벡터 차원: {expected_dim} (총 {dimensions[expected_dim]}개 발견)")
            print(f"발견된 모든 차원: {dimensions}")
        else:
            print("데이터셋에서 유효한 벡터를 찾을 수 없습니다!")
            return False
        
        # 2단계: 잘못된 차원의 벡터 수정
        for file_idx, file in enumerate(data):
            file_name = file.get("file_name", f"Unknown-{file_idx}")
            for chunk_idx, chunk in enumerate(file.get("chunks", [])):
                if "vector" in chunk and chunk["vector"]:
                    vector = chunk["vector"]
                    try:
                        if not isinstance(vector, list):
                            print(f"리스트가 아닌 벡터 수정 시도: {file_name}, 청크 {chunk_idx}")
                            try:
                                vector = list(vector)
                                chunk["vector"] = vector
                                fixed_count += 1
                            except:
                                # 변환 실패 시 빈 벡터 생성
                                chunk["vector"] = [0.0] * expected_dim
                                fixed_count += 1
                                print(f"리스트 변환 실패, 기본 벡터 사용")
                        
                        dim = len(vector)
                        if dim != expected_dim:
                            print(f"벡터 차원 수정: {file_name}, 청크 {chunk_idx} (차원: {dim})")
                            if dim < expected_dim:
                                # 0으로 패딩
                                chunk["vector"] = vector + [0.0] * (expected_dim - dim)
                            else:
                                # 자르기
                                chunk["vector"] = vector[:expected_dim]
                            fixed_count += 1
                    except Exception as e:
                        print(f"벡터 처리 중 오류: {file_name}, 청크 {chunk_idx} - {str(e)}")
                        problem_count += 1
        
        print(f"고정된 벡터 수: {fixed_count}, 문제 벡터 수: {problem_count}")
        
        # 수정된 데이터셋 저장
        if output_path is None:
            output_path = data_path
        
        # 덮어쓰기 전 백업 생성
        if output_path == data_path:
            backup_path = f"{data_path}.bak"
            print(f"백업 생성: {backup_path}")
            with open(backup_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"수정된 데이터셋 저장: {output_path}")
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return True
    
    except Exception as e:
        print(f"데이터셋 진단 중 오류: {str(e)}")
        return False

```


--- core/RAG.py

```python

# RAG.py
import torch
import re
import numpy as np
import rank_bm25
import random
import uuid
import logging
from datetime import datetime, timedelta
# from sql import generate_sql  # (구) 제거된 import
from core.SQL_NS import run_sql_unno, run_sql_bl, get_metadata  # SQL만 담당하는 함수들만 import

# Tracking
from utils.tracking import time_tracker

# Import the vLLM to use the AsyncLLMEngine
from vllm.engine.async_llm_engine import AsyncLLMEngine

# In RAG.py (at the top, add an import for prompts)
from prompt.prompt_rag import QUERY_SORT_PROMPT, GENERATE_PROMPT_TEMPLATE, STREAM_PROMPT_TEMPLATE

global beep
beep = "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------"


@time_tracker
async def execute_rag(QU, KE, TA, TI, **kwargs):
    print("[SOOWAN]: execute_rag : 진입")
    model = kwargs.get("model")
    tokenizer = kwargs.get("tokenizer")
    embed_model = kwargs.get("embed_model")
    embed_tokenizer = kwargs.get("embed_tokenizer")
    data = kwargs.get("data")
    config = kwargs.get("config")

    if TA == "yes":  # Table 이 필요하면
        print("[SOOWAN]: execute_rag : 테이블 필요 (TA == yes). SQL 생성 시작합니다.")
        try:
            # generate_sql 함수를 이 파일(RAG.py) 내부에 새로 정의했으므로, 여기서 직접 호출
            result = await generate_sql(QU, model, tokenizer, config)
        except Exception as e:
            # 1) generate_sql() 자체가 도중에 예외를 던지는 경우
            print("[ERROR] generate_sql() 도중 예외 발생:", e)
            # 멈추지 않고, 에러 형식으로 데이터를 만들어 반환
            docs = (
                "테이블 조회 시도 중 예외가 발생했습니다. "
                "해당 SQL을 실행할 수 없어서 테이블 데이터를 가져오지 못했습니다."
            )
            docs_list = []
            return docs, docs_list

        # 2) 함수가 정상 실행됐지만 결과가 None인 경우(= SQL 쿼리 결과가 없거나 오류)
        if result is None:
            print(
                "[WARNING] generate_sql()에서 None을 반환했습니다. "
                "SQL 수행 결과가 없거나 에러가 발생한 것일 수 있습니다."
            )
            docs = (
                "테이블 조회 결과가 비어 있습니다. "
                "조회할 데이터가 없거나 SQL 오류가 발생했습니다."
            )
            docs_list = []
            return docs, docs_list

        # 기존 generate_sql은 이제 6개의 값을 반환합니다.
        final_sql_query, title, explain, table_json, chart_json, detailed_result = result

        # docs : LLM 입력용 (string)
        PROMPT = (
            f"실제 사용된 SQL문: {final_sql_query}\n\n"
            f"추가 설명: {explain}\n\n"
            f"실제 SQL 추출된 데이터: {str(table_json)}\n\n"
            f"실제 선적된 B/L 데이터: {str(detailed_result)}\n\n"
        )
        # docs_list에 DG B/L 상세 정보를 추가하여 총 3개 항목으로 구성합니다.
        docs_list = [
            {"title": title, "data": table_json},
            {"title": "DG B/L 상세 정보", "data": detailed_result},
        ]
        print("[SOOWAN]: execute_rag : 테이블 부분 정상 처리 완료")

        return PROMPT, docs_list

    else:
        print("[SOOWAN]: execute_rag : 테이블 필요없음")
        # 적응형 시간 필터링으로 RAG 실행
        filtered_data = expand_time_range_if_needed(TI, data, min_docs=50)

        # 디버깅을 위해 문서 수 로깅
        print(f"[RETRIEVE] 검색에 사용되는 문서 수: {len(filtered_data.get('vectors', []))}")

        docs, docs_list = retrieve(KE, filtered_data, config.N, embed_model, embed_tokenizer)
        return docs, docs_list


@time_tracker
async def execute_sql(QU, KE, TA, TI, **kwargs):
    """
    별도의 SQL 실행(UNNO, CLASS, POL, POD 자동 추출) 로직이 필요한 경우 사용되는 함수
    """
    from core.SQL_NS import get_metadata, run_sql_unno

    print("[SANGJE]: execute_sql : 진입")
    model = kwargs.get("model")
    tokenizer = kwargs.get("tokenizer")
    embed_model = kwargs.get("embed_model")
    embed_tokenizer = kwargs.get("embed_tokenizer")
    data = kwargs.get("data")
    config = kwargs.get("config")

    metadata_location, metadata_unno = get_metadata(config)
    print(f"✅ Metadata loaded:{metadata_location[:100]}")
    PROMPT = f'''
<bos>
<system>
"YourRole": "질문으로 부터 조건을 추출하는 역할",
"YourJob": "아래 요구 사항에 맞추어 'unno', 'class', 'pol_port', 'pod_port' 정보를 추출하여, 예시처럼 답변을 구성해야 합니다.",
"Requirements": [
    unno: UNNO Number는 4개의 숫자로 이루어진 위험물 번호 코드야. 
    class : UN Class는 2.1, 6.0,,, 의 숫자로 이루어진 코드야.
    pol_port, pod_port: 항구 코드는 5개의 알파벳 또는 나라의 경우 2개의 알파벳과 %로 이루어져 있어. 다음은 항구 코드에 대한 메타데이터야 {metadata_location}. 여기에서 매칭되는 코드만을 사용해야 해. 항구는 항구코드, 나라는 2개의 나라코드와 %를 사용해.
    unknown : 질문에서 찾을 수 없는 정보는 NULL을 출력해줘.
]

"Examples": [
    "질문": "UN 번호 1689 화물의 부산에서 미즈시마로의 선적 가능 여부를 확인해 주세요.",
    "답변": "<unno/>1689<unno>\\n<class/>NULL<class>\\n<pol_port/>KRPUS<pol_port>\\n<pod_port/>JPMIZ<pod_port>"

    "질문": "UN 클래스 2.1 화물의 한국에서 일본으로의 선적 가능 여부를 확인해 주세요.",
    "답변": "<unno/>NULL<unno>\\n<class/>2.1<class>\\n<pol_port/>KR%<pol_port>\\n<pod_port/>JP%<pod_port>"
]
- 최종 출력은 반드시 다음 4가지 항목을 포함해야 합니다:
    <unno/>...<unno>
    <class/>...<class>
    <pol_port/>...<pol_port>
    <pod_port/>...<pod_port>
</system>

<user>
질문: "{QU}"
</user>

<assistant>
답변:
</assistant>
'''
    try:
        from vllm import SamplingParams
        sampling_params = SamplingParams(
            max_tokens=config.model.max_new_tokens,
            temperature=config.model.temperature,
            top_k=config.model.top_k,
            top_p=config.model.top_p,
            repetition_penalty=config.model.repetition_penalty,
        )
        accepted_request_id = str(uuid.uuid4())
        outputs_result = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
        print(f"✅ SQL Model Outputs:{outputs_result}")

        # Regular expression to extract content between <query/> and <query>
        unno_pattern = r'<unno.*?>(.*?)<unno.*?>'
        class_pattern = r'<class.*?>(.*?)<class.*?>'
        pol_port_pattern = r'<pol_port.*?>(.*?)<pol_port.*?>'
        pod_port_pattern = r'<pod_port.*?>(.*?)<pod_port.*?>'

        UN_number = re.search(unno_pattern, outputs_result, re.DOTALL).group(1)
        UN_class = re.search(class_pattern, outputs_result, re.DOTALL).group(1)
        POL = re.search(pol_port_pattern, outputs_result, re.DOTALL).group(1)
        POD = re.search(pod_port_pattern, outputs_result, re.DOTALL).group(1)

        print(f"✅ UN_number:{UN_number}, UN_class:{UN_class}, POL:{POL}, POD:{POD}")
        final_sql_query, result = run_sql_unno(UN_class, UN_number, POL, POD)

        ### Temporary ###
        title, explain, table_json, chart_json = (None,) * 4

        result = final_sql_query, title, explain, result, chart_json

    except Exception as e:
        # 1) generate_sql() 자체가 도중에 예외를 던지는 경우
        print("[ERROR] generate_sql() 도중 예외 발생:", e)
        # 멈추지 않고, 에러 형식으로 데이터를 만들어 반환
        docs = (
            "테이블 조회 시도 중 예외가 발생했습니다. "
            "해당 SQL을 실행할 수 없어서 테이블 데이터를 가져오지 못했습니다."
        )
        docs_list = []
        return docs, docs_list

    # 2) 함수가 정상 실행됐지만 결과가 None인 경우(= SQL 쿼리 결과가 없거나 오류)
    if result is None:
        print(
            "[WARNING] generate_sql()에서 None을 반환했습니다. "
            "SQL 수행 결과가 없거나 에러가 발생한 것일 수 있습니다."
        )
        docs = (
            "테이블 조회 결과가 비어 있습니다. "
            "조회할 데이터가 없거나 SQL 오류가 발생했습니다."
        )
        docs_list = []
        return docs, docs_list

    # 정상적인 경우(튜플 언패킹)
    final_sql_query, title, explain, table_json, chart_json = result

    # docs : LLM 입력용 (string)
    PROMPT = (
        f"다음은 SQL 추출에 사용된 쿼리문: {final_sql_query}\n\n"
        f"추가 설명: {explain}\n\n"
        f"실제 SQL 추출된 데이터: {str(table_json)}\n\n"
    )

    docs_list = None
    print("[SOOWAN]: execute_rag : 테이블 부분 정상 처리 완료")
    return PROMPT, docs_list


@time_tracker
async def generate_answer(query, docs, **kwargs):
    model = kwargs.get("model")
    tokenizer = kwargs.get("tokenizer")
    config = kwargs.get("config")

    answer = await generate(docs, query, model, tokenizer, config)
    return answer


@time_tracker
async def query_sort(params):
    max_attempts = 3
    attempt = 0
    while attempt < max_attempts:
        # params: 딕셔너리로 전달된 값들
        query = params["user_input"]
        model = params["model"]
        tokenizer = params["tokenizer"]
        embed_model = params["embed_model"]
        embed_tokenizer = params["embed_tokenizer"]
        data = params["data"]
        config = params["config"]

        # 프롬프트 생성
        PROMPT = QUERY_SORT_PROMPT.format(user_query=query)
        print("##### query_sort is starting, attempt:", attempt + 1, "#####")

        # Get Answer from LLM
        if config.use_vllm:  # use_vllm = True case
            from vllm import SamplingParams

            sampling_params = SamplingParams(
                max_tokens=config.model.max_new_tokens,
                temperature=config.model.temperature,
                top_k=config.model.top_k,
                top_p=config.model.top_p,
                repetition_penalty=config.model.repetition_penalty,
            )
            accepted_request_id = str(uuid.uuid4())
            answer = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
        else:
            input_ids = tokenizer(
                PROMPT, return_tensors="pt", truncation=True, max_length=4024
            ).to("cuda")
            token_count = input_ids["input_ids"].shape[1]
            outputs = model.generate(
                **input_ids,
                max_new_tokens=config.model.max_new_tokens,
                do_sample=config.model.do_sample,
                temperature=config.model.temperature,
                top_k=config.model.top_k,
                top_p=config.model.top_p,
                repetition_penalty=config.model.repetition_penalty,
                eos_token_id=tokenizer.eos_token_id,
                pad_token_id=tokenizer.eos_token_id,
            )
            answer = tokenizer.decode(outputs[0][token_count:], skip_special_tokens=True)

        print("[DEBUG query_sort] Generated answer:")
        print(answer)

        # Regular expressions for tags
        query_pattern = r"<query.*?>(.*?)<query.*?>"
        keyword_pattern = r"<keyword.*?>(.*?)<keyword.*?>"
        table_pattern = r"<table.*?>(.*?)<table.*?>"
        time_pattern = r"<time.*?>(.*?)<time.*?>"

        m_query = re.search(query_pattern, answer, re.DOTALL)
        m_keyword = re.search(keyword_pattern, answer, re.DOTALL)
        m_table = re.search(table_pattern, answer, re.DOTALL)
        m_time = re.search(time_pattern, answer, re.DOTALL)

        if m_query and m_keyword and m_table and m_time:
            QU = m_query.group(1).strip()
            KE = m_keyword.group(1).strip()
            TA = m_table.group(1).strip()
            TI = m_time.group(1).strip()
            if TI == "all":
                TI = "1900-01-01:2099-01-01"
            print(beep)
            print(f"구체화 질문: {QU}, 키워드 : {KE}, 테이블 필요 유무: {TA}, 시간: {TI}")
            print(beep)
            return QU, KE, TA, TI
        else:
            print("[ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.")
            attempt += 1

    # 3회 재시도 후에도 실패하면 에러 발생
    raise ValueError("LLM이 올바른 태그 형식의 답변을 생성하지 못했습니다.")


@time_tracker
async def specific_question(params):
    """
    query_sort와 동일한 로직을 수행할 수도 있으나,
    별도로 분리된 이유가 있다면 여기서 추가 처리 가능
    """
    max_attempts = 3
    attempt = 0
    while attempt < max_attempts:
        query = params["user_input"]
        model = params["model"]
        tokenizer = params["tokenizer"]
        embed_model = params["embed_model"]
        embed_tokenizer = params["embed_tokenizer"]
        data = params["data"]
        config = params["config"]

        PROMPT = QUERY_SORT_PROMPT.format(user_query=query)
        print("##### query_sort is starting, attempt:", attempt + 1, "#####")

        if config.use_vllm:
            from vllm import SamplingParams

            sampling_params = SamplingParams(
                max_tokens=config.model.max_new_tokens,
                temperature=config.model.temperature,
                top_k=config.model.top_k,
                top_p=config.model.top_p,
                repetition_penalty=config.model.repetition_penalty,
            )
            accepted_request_id = str(uuid.uuid4())
            answer = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
        else:
            input_ids = tokenizer(
                PROMPT, return_tensors="pt", truncation=True, max_length=4024
            ).to("cuda")
            token_count = input_ids["input_ids"].shape[1]
            outputs = model.generate(
                **input_ids,
                max_new_tokens=config.model.max_new_tokens,
                do_sample=config.model.do_sample,
                temperature=config.model.temperature,
                top_k=config.model.top_k,
                top_p=config.model.top_p,
                repetition_penalty=config.model.repetition_penalty,
                eos_token_id=tokenizer.eos_token_id,
                pad_token_id=tokenizer.eos_token_id,
            )
            answer = tokenizer.decode(outputs[0][token_count:], skip_special_tokens=True)

        print("[DEBUG query_sort] Generated answer:")
        print(answer)

        query_pattern = r"<query.*?>(.*?)<query.*?>"
        keyword_pattern = r"<keyword.*?>(.*?)<keyword.*?>"
        table_pattern = r"<table.*?>(.*?)<table.*?>"
        time_pattern = r"<time.*?>(.*?)<time.*?>"

        m_query = re.search(query_pattern, answer, re.DOTALL)
        m_keyword = re.search(keyword_pattern, answer, re.DOTALL)
        m_table = re.search(table_pattern, answer, re.DOTALL)
        m_time = re.search(time_pattern, answer, re.DOTALL)

        if m_query and m_keyword and m_table and m_time:
            QU = m_query.group(1).strip()
            KE = m_keyword.group(1).strip()
            TA = m_table.group(1).strip()
            TI = m_time.group(1).strip()
            if TI == "all":
                TI = "1900-01-01:2099-01-01"
            print(beep)
            print(f"구체화 질문: {QU}, 키워드 : {KE}, 테이블 필요 유무: {TA}, 시간: {TI}")
            print(beep)
            return QU, KE, TA, TI
        else:
            print("[ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.")
            attempt += 1

    raise ValueError("LLM이 올바른 태그 형식의 답변을 생성하지 못했습니다.")


@time_tracker
def sort_by_time(time_bound, data):
    """
    원본 데이터는 유지하고 필터링된 복사본을 반환하는 함수
    """
    original_count = len(data["times"])
    print(f"[시간 필터 전] 문서 수: {original_count}")

    if time_bound == "all" or time_bound == "1900-01-01:2099-01-01":
        print(f"[시간 필터] 전체 기간 사용 - 모든 문서 포함")
        return data  # 원본 그대로

    date_format = "%Y-%m-%d"
    target_date_start = datetime.strptime(time_bound.split(":")[0], date_format)
    target_date_end = datetime.strptime(time_bound.split(":")[1], date_format)

    matching_indices = [
        i
        for i, date in enumerate(data["times"])
        if (not isinstance(date, str)) and (target_date_start < date < target_date_end)
    ]

    filtered_count = len(matching_indices)
    print(f"[시간 필터 후] 문서 수: {filtered_count}, 기간: {time_bound}")

    if filtered_count < 50 and filtered_count < original_count * 0.1:
        print(f"[경고] 시간 필터로 인해 문서가 크게 줄었습니다: {original_count} → {filtered_count}")

    filtered_data = {}
    filtered_data["file_names"] = [data["file_names"][i] for i in matching_indices]
    filtered_data["titles"] = [data["titles"][i] for i in matching_indices]
    filtered_data["times"] = [data["times"][i] for i in matching_indices]
    filtered_data["chunk_ids"] = [data["chunk_ids"][i] for i in matching_indices]

    if isinstance(data["vectors"], torch.Tensor):
        filtered_data["vectors"] = data["vectors"][matching_indices]
    else:
        filtered_data["vectors"] = [data["vectors"][i] for i in matching_indices]

    filtered_data["texts"] = [data["texts"][i] for i in matching_indices]
    filtered_data["texts_short"] = [data["texts_short"][i] for i in matching_indices]
    filtered_data["texts_vis"] = [data["texts_vis"][i] for i in matching_indices]

    return filtered_data


@time_tracker
def retrieve(query, data, N, embed_model, embed_tokenizer):
    print("[SOOWAN] retrieve : 진입")
    logging.info(f"Retrieval for query: '{query}'")
    logging.info(f"Available documents: {len(data['vectors'])}")

    try:
        sim_score = cal_sim_score(query, data["vectors"], embed_model, embed_tokenizer)
        logging.info(f"Similarity score shape: {sim_score.shape}")

        bm25_score = cal_bm25_score(query, data["texts_short"], embed_tokenizer)
        logging.info(f"BM25 score shape: {bm25_score.shape}")

        scaled_sim_score = min_max_scaling(sim_score)
        scaled_bm25_score = min_max_scaling(bm25_score)

        score = scaled_sim_score * 0.4 + scaled_bm25_score * 0.6
        score_values = score[:, 0, 0]
        top_k = score[:, 0, 0].argsort()[-N:][::-1]

        logging.info(f"Top {N} document indices: {top_k}")
        logging.info(f"Top {N} document scores: {[score[:, 0, 0][i] for i in top_k]}")
        logging.info(f"Top document titles: {[data['titles'][i] for i in top_k]}")

        documents = ""
        documents_list = []
        for i, index in enumerate(top_k):
            score_str = f"{score_values[index]:.4f}"
            documents += f"{i+1}번째 검색자료 (출처:{data['file_names'][index]}) :\n{data['texts_short'][index]}, , Score: {score_str}\n"
            documents_list.append(
                {
                    "file_name": data["file_names"][index],
                    "title": data["titles"][index],
                    "contents": data["texts_vis"][index],
                    "chunk_id": data["chunk_ids"][index],
                }
            )
        print("-------------자료 검색 성공--------------")
        print("-------", documents_list, "-------")
        print("---------------------------------------")
        return documents, documents_list

    except Exception as e:
        logging.error(f"Retrieval error: {str(e)}", exc_info=True)
        return "", []


@time_tracker
def expand_time_range_if_needed(time_bound, data, min_docs=50):
    """
    시간 필터링 결과가 너무 적은 경우 자동으로 시간 범위를 확장하는 함수
    """
    if time_bound == "all" or time_bound == "1900-01-01:2099-01-01":
        print(f"[시간 범위] 전체 기간 사용")
        return data

    filtered_data = sort_by_time(time_bound, data)
    filtered_count = len(filtered_data.get("times", []))

    if filtered_count >= min_docs:
        print(f"[시간 범위] 원래 범위로 충분한 문서 확보: {filtered_count}개")
        return filtered_data

    print(f"[시간 범위 확장] 원래 범위는 {filtered_count}개 문서만 제공 (최소 필요: {min_docs}개)")

    date_format = "%Y-%m-%d"
    try:
        start_date = datetime.strptime(time_bound.split(":")[0], date_format)
        end_date = datetime.strptime(time_bound.split(":")[1], date_format)
    except Exception as e:
        print(f"[시간 범위 오류] 날짜 형식 오류: {time_bound}, 오류: {e}")
        return data

    expansions = [
        (3, "3개월"),
        (6, "6개월"),
        (12, "1년"),
        (24, "2년"),
        (60, "5년"),
    ]

    for months, label in expansions:
        new_start = start_date - timedelta(days=30 * months // 2)
        new_end = end_date + timedelta(days=30 * months // 2)

        new_range = f"{new_start.strftime(date_format)}:{new_end.strftime(date_format)}"
        print(f"[시간 범위 확장] {label} 확장 시도: {new_range}")

        expanded_data = sort_by_time(new_range, data)
        expanded_count = len(expanded_data.get("times", []))

        if expanded_count >= min_docs:
            print(f"[시간 범위 확장] {label} 확장으로 {expanded_count}개 문서 확보")
            return expanded_data

    print(f"[시간 범위 확장] 모든 확장 시도 실패, 전체 데이터셋 사용")
    return data


@time_tracker
def cal_sim_score(query, chunks, embed_model, embed_tokenizer):
    print("[SOOWAN] cal_sim_score : 진입 / query : ", query)
    query_V = embed(query, embed_model, embed_tokenizer)
    print("[SOOWAN] cal_sim_score : query_V 생산 완료")
    if len(query_V.shape) == 1:
        query_V = query_V.unsqueeze(0)
        print("[SOOWAN] cal_sim_score : query_V.shape == 1")
    score = []
    for chunk in chunks:
        if len(chunk.shape) == 1:
            chunk = chunk.unsqueeze(0)
        query_norm = query_V / query_V.norm(dim=1)[:, None]
        chunk_norm = chunk / chunk.norm(dim=1)[:, None]
        tmp = torch.mm(query_norm, chunk_norm.transpose(0, 1)) * 100
        score.append(tmp.detach())
    return np.array(score)


@time_tracker
def cal_bm25_score(query, indexes, embed_tokenizer):
    logging.info(f"Starting BM25 calculation for query: {query}")
    logging.info(f"Document count: {len(indexes)}")

    if not indexes:
        logging.warning("Empty document list provided to BM25")
        return np.zeros(0)

    tokenized_corpus = []
    for i, text in enumerate(indexes):
        try:
            tokens = embed_tokenizer(
                text,
                return_token_type_ids=False,
                return_attention_mask=False,
                return_offsets_mapping=False,
            )
            tokens = embed_tokenizer.convert_ids_to_tokens(tokens["input_ids"])
            if len(tokens) == 0:
                logging.warning(f"Document {i} tokenized to empty list")
                tokens = ["<empty>"]
            tokenized_corpus.append(tokens)
        except Exception as e:
            logging.error(f"Failed to tokenize document {i}: {str(e)}")
            tokenized_corpus.append(["<error>"])

    try:
        bm25 = rank_bm25.BM25Okapi(tokenized_corpus)
        tokenized_query = embed_tokenizer.convert_ids_to_tokens(embed_tokenizer(query)["input_ids"])
        scores = bm25.get_scores(tokenized_query)

        if np.isnan(scores).any() or np.isinf(scores).any():
            logging.warning("BM25 produced NaN/Inf scores - replacing with zeros")
            scores = np.nan_to_num(scores)

        logging.info(
            f"BM25 scores: min={scores.min():.4f}, max={scores.max():.4f}, mean={scores.mean():.4f}"
        )
        return scores
    except Exception as e:
        logging.error(f"BM25 scoring failed: {str(e)}")
        return np.zeros(len(indexes))


@time_tracker
def embed(query, embed_model, embed_tokenizer):
    print("[SOOWAN] embed: 진입")
    inputs = embed_tokenizer(query, padding=True, truncation=True, return_tensors="pt")
    embeddings, _ = embed_model(**inputs, return_dict=False)
    print("[SOOWAN] embed: 완료")
    return embeddings[0][0]


@time_tracker
def min_max_scaling(arr):
    arr_min = arr.min()
    arr_max = arr.max()
    if arr_max == arr_min:
        print("[SOOWAN] min_max_scaling: Zero range detected, returning zeros.")
        return np.zeros_like(arr)
    return (arr - arr_min) / (arr_max - arr_min)


@time_tracker
async def generate(docs, query, model, tokenizer, config):
    PROMPT = GENERATE_PROMPT_TEMPLATE.format(docs=docs, query=query)
    print("Inference steps")
    if config.use_vllm:
        from vllm import SamplingParams
        sampling_params = SamplingParams(
            max_tokens=config.model.max_new_tokens,
            temperature=config.model.temperature,
            top_k=config.model.top_k,
            top_p=config.model.top_p,
            repetition_penalty=config.model.repetition_penalty,
        )
        accepted_request_id = str(uuid.uuid4())
        answer = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
    else:
        input_ids = tokenizer(PROMPT, return_tensors="pt", truncation=True, max_length=4024).to(
            "cuda"
        )
        token_count = input_ids["input_ids"].shape[1]
        outputs = model.generate(
            **input_ids,
            max_new_tokens=config.model.max_new_tokens,
            do_sample=config.model.do_sample,
            temperature=config.model.temperature,
            top_k=config.model.top_k,
            top_p=config.model.top_p,
            repetition_penalty=config.model.repetition_penalty,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.eos_token_id,
        )
        answer = tokenizer.decode(outputs[0][token_count:], skip_special_tokens=True)
        print(answer)
        print(">>> decode done, returning answer")
    return answer


@time_tracker
async def collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id):
    import asyncio, concurrent.futures
    print("[SOOWAN] collect_vllm_text 진입 PROMPT: ")
    outputs = []
    async for output in model.generate(PROMPT, request_id=accepted_request_id, sampling_params=sampling_params):
        outputs.append(output)
    if not outputs:
        raise RuntimeError("No outputs were generated by the model.")
    final_output = next((o for o in outputs if getattr(o, "finished", False)), outputs[-1])
    answer = "".join([getattr(comp, "text", "") for comp in getattr(final_output, "outputs", [])])
    return answer


@time_tracker
async def generate_answer_stream(query, docs, model, tokenizer, config):
    prompt = STREAM_PROMPT_TEMPLATE.format(docs=docs, query=query)
    print("최종 LLM 추론용 prompt 생성 : ", prompt)
    if config.use_vllm:
        from vllm import SamplingParams
        sampling_params = SamplingParams(
            max_tokens=config.model.max_new_tokens,
            temperature=config.model.temperature,
            top_k=config.model.top_k,
            top_p=config.model.top_p,
            repetition_penalty=config.model.repetition_penalty,
        )
        request_id = str(uuid.uuid4())
        async for partial_chunk in collect_vllm_text_stream(prompt, model, sampling_params, request_id):
            yield partial_chunk
    else:
        import torch
        from transformers import TextIteratorStreamer

        input_ids = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=4024).to("cuda")
        streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)
        generation_kwargs = dict(
            **input_ids,
            streamer=streamer,
            max_new_tokens=config.model.max_new_tokens,
            do_sample=config.model.do_sample,
            temperature=config.model.temperature,
            top_k=config.model.top_k,
            top_p=config.model.top_p,
            repetition_penalty=config.model.repetition_penalty,
        )
        import threading

        t = threading.Thread(target=model.generate, kwargs=generation_kwargs)
        t.start()
        for new_token in streamer:
            yield new_token


@time_tracker
async def collect_vllm_text_stream(prompt, engine: AsyncLLMEngine, sampling_params, request_id) -> str:
    async for request_output in engine.generate(prompt, request_id=request_id, sampling_params=sampling_params):
        if not request_output.outputs:
            continue
        for completion in request_output.outputs:
            yield completion.text


# ---------------------------
# *** 새로 추가된 generate_sql 함수 ***
# *** (기존에는 SQL_NS.py 안에 있었음) ***
# ---------------------------
@time_tracker
async def generate_sql(user_query, model, tokenizer, config):
    """
    기존 SQL_NS.py에서 VLLM을 통해 <unno>, <class>, <pol_port>, <pod_port>를 추출한 뒤
    run_sql_unno, run_sql_bl를 호출하는 로직을 RAG.py로 옮겼습니다.
    """
    # 먼저 메타데이터를 읽어옴
    metadata_location, metadata_unno = get_metadata(config)

    # 프롬프트 생성
    PROMPT = f'''
<bos>
<system>
"YourRole": "질문으로 부터 조건을 추출하는 역할",
"YourJob": "아래 요구 사항에 맞추어 'unno', 'class', 'pol_port', 'pod_port' 정보를 추출하여, 예시처럼 답변을 구성해야 합니다.",
"Requirements": [
    unno: UNNO Number는 4개의 숫자로 이루어진 위험물 번호 코드야. 
    class : UN Class는 2.1, 6.0,,, 의 숫자로 이루어진 코드야.
    pol_port, pod_port: 항구 코드는 5개의 알파벳 또는 나라의 경우 2개의 알파벳과 %로 이루어져 있어. 다음은 항구 코드에 대한 메타데이터야 {metadata_location}. 여기에서 매칭되는 코드만을 사용해야 해. 항구는 항구코드, 나라는 2개의 나라코드와 %를 사용해.
    unknown : 질문에서 찾을 수 없는 정보는 NULL을 출력해줘.
]

"Examples": [
    "질문": "UN 번호 1689 화물의 부산에서 미즈시마로의 선적 가능 여부를 확인해 주세요.",
    "답변": "<unno/>1689<unno>\\n<class/>NULL<class>\\n<pol_port/>KRPUS<pol_port>\\n<pod_port/>JPMIZ<pod_port>"

    "질문": "UN 클래스 2.1 화물의 한국에서 일본으로의 선적 가능 여부를 확인해 주세요.",
    "답변": "<unno/>NULL<unno>\\n<class/>2.1<class>\\n<pol_port/>KR%<pol_port>\\n<pod_port/>JP%<pod_port>"
]
- 최종 출력은 반드시 다음 4가지 항목을 포함해야 합니다:
    <unno/>...<unno>
    <class/>...<class>
    <pol_port/>...<pol_port>
    <pod_port/>...<pod_port>
</system>

<user>
질문: "{user_query}"
</user>

<assistant>
답변:
</assistant>
'''

    from vllm import SamplingParams
    import uuid

    sampling_params = SamplingParams(
        max_tokens=config.model.max_new_tokens,
        temperature=config.model.temperature,
        top_k=config.model.top_k,
        top_p=config.model.top_p,
        repetition_penalty=config.model.repetition_penalty,
    )

    # 최대 3회 시도
    max_attempts = 3
    attempt = 0
    UN_number = UN_class = POL = POD = "NULL"
    unno_pattern = r'<unno.*?>(.*?)<unno.*?>'
    class_pattern = r'<class.*?>(.*?)<class.*?>'
    pol_port_pattern = r'<pol_port.*?>(.*?)<pol_port.*?>'
    pod_port_pattern = r'<pod_port.*?>(.*?)<pod_port.*?>'

    while attempt < max_attempts:
        accepted_request_id = str(uuid.uuid4())
        outputs_result = await collect_vllm_text(PROMPT, model, sampling_params, accepted_request_id)
        print(f"[GENERATE_SQL] Attempt {attempt+1}, SQL Model Outputs: {outputs_result}")

        match_unno = re.search(unno_pattern, outputs_result, re.DOTALL)
        UN_number = match_unno.group(1).strip() if match_unno else "NULL"

        match_class = re.search(class_pattern, outputs_result, re.DOTALL)
        UN_class = match_class.group(1).strip() if match_class else "NULL"

        match_pol = re.search(pol_port_pattern, outputs_result, re.DOTALL)
        POL = match_pol.group(1).strip() if match_pol else "NULL"

        match_pod = re.search(pod_port_pattern, outputs_result, re.DOTALL)
        POD = match_pod.group(1).strip() if match_pod else "NULL"

        print(f"[GENERATE_SQL] 추출 결과 - UN_number: {UN_number}, UN_class: {UN_class}, POL: {POL}, POD: {POD}")

        # 조건: (UN_number != NULL or UN_class != NULL) and (POL != NULL) and (POD != NULL)
        if ((UN_number != "NULL" or UN_class != "NULL") and POL != "NULL" and POD != "NULL"):
            break
        attempt += 1

    print(f"[GENERATE_SQL] 최종 추출 값 - UN_number: {UN_number}, UN_class: {UN_class}, POL: {POL}, POD: {POD}")

    # run_sql_unno로 DG 가능 여부 확인
    final_sql_query, result = run_sql_unno(UN_class, UN_number, POL, POD)
    # 상세 B/L SQL
    detailed_sql_query, detailed_result = run_sql_bl(UN_class, UN_number, POL, POD)

    # Temporary: title, explain, table_json, chart_json = None
    title, explain, table_json, chart_json = (None,) * 4

    return final_sql_query, title, explain, result, chart_json, detailed_result

```


--- core/SQL_NS.py

```python

# SQL_NS.py

import os
import subprocess
from utils.tracking import time_tracker
import json
import yaml
from box import Box
import re

# [ë³€ê²½ ì „] from utils import load_model  # (ì‚­ì œë�¨: ì˜¤ì§� SQL ìš©ë�„ë§Œ ë‚¨ê¹€)
# [ë³€ê²½ ì „] import code  # (í•„ìš” ì‹œ ë””ë²„ê¹…ìš©, ì§€ê¸ˆì�€ ì œê±°)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['ORACLE_HOME'] = '/workspace/oracle/instantclient_23_7'
os.environ['LD_LIBRARY_PATH'] = os.environ['ORACLE_HOME'] + ':' + os.environ.get('LD_LIBRARY_PATH', '')
os.environ['PATH'] = os.environ['ORACLE_HOME'] + ':' + os.environ.get('PATH', '')

# Config ë¶ˆëŸ¬ì˜¤ê¸° (DB ì ‘ì†� ë“± ê¸°íƒ€ ì •ë³´ë¥¼ config.yamlì—�ì„œ ê°€ì ¸ì˜¨ë‹¤ê³  ê°€ì •)
with open("./config.yaml", "r") as f:
    config_yaml = yaml.load(f, Loader=yaml.FullLoader)
    config = Box(config_yaml)

# ê¸°ë³¸ SQL ì ‘ì†�ì½”ë“œ (â€» ì‹¤ì œ DB ì ‘ì†� ê³„ì •/ì£¼ì†ŒëŠ” ë³¸ì�¸ í™˜ê²½ì—� ë§�ê²Œ ìˆ˜ì • í•„ìš”)
sqlplus_command = [
    "sqlplus", "-S", "LLM/L9SD2TT9XJ0H@//210.113.16.230:1521/ORA11GDR"
]


'''
### ORACLE DB ì •ë³´ ###
TABLE : ai_dg_check
    COLUMNS : CLS (ìœ„í—˜ë¬¼ í�´ë�˜ìŠ¤)
              UNNO (ìœ„í—˜ë¬¼ UN ë²ˆí˜¸)
              PORT (í�¬íŠ¸ ë²ˆí˜¸)
              ALLOW_YN (ì·¨ê¸‰ ê°€ëŠ¥ ì—¬ë¶€)
'''

SQL_UNNO_PROMPT = \
"""
<bos>
<system>
ë„ˆëŠ” ë‚¨ì„±í•´ìš´ì�˜ ë‚´ë¶€ ë�°ì�´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì—� ë‹µí•˜ëŠ” ë�°ì�´í„° ë¶„ì„�ê°€ì•¼.
- ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì �ì�¸ ë‹µë³€ì�„ í•œë‹¤.
- ë¬¸ì„œì—� ì—†ëŠ” ë‚´ìš©ì�€ "ë‚´ë¶€ ì��ë£Œì—� í•´ë‹¹ ì��ë£Œ ì—†ì�Œ"ì�´ë�¼ê³  ëª…ì‹œí•œë‹¤.
- í‘œ ë�°ì�´í„°ë¥¼ ë§�ë¡œ í’€ì–´ í•´ì„�í•œ ë’¤ ì�¸ì‚¬ì�´íŠ¸ë¥¼ ì œê³µí•œë‹¤.
- ì¶œì²˜ í‘œê¸°ëŠ” í•„ìˆ˜ë‹¤.
</system>

<user>
ë‚´ë¶€ ì��ë£Œ: {docs}
ì§ˆë¬¸: {query}
</user>

<assistant>
ë‹µë³€:
</assistant>
"""


@time_tracker
def check_sqlplus():
    """
    sqlplus ë²„ì „ ì •ë³´ í™•ì�¸
    """
    try:
        result = subprocess.run(['sqlplus', '-version'], capture_output=True, text=True, check=True)
        print(" SQL*Plus is working!")
        print("Version info:\n", result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"Error: {e.stderr}")


@time_tracker
def check_db_connection():
    """
    DB ì—°ê²°ì�´ ì •ìƒ�ì �ì�¸ì§€ í…ŒìŠ¤íŠ¸
    """
    try:
        sql_query = "SELECT 1 FROM dual;\nEXIT;\n"
        result = subprocess.run(
            sqlplus_command,
            input=sql_query,
            capture_output=True,
            text=True
        )

        if "1" in result.stdout:
            print("  Successfully connected to the Namsung database!")
        else:
            print(" Connection to the database failed!")

    except subprocess.CalledProcessError as e:
        print(f" Error: {e.stderr}")


@time_tracker
def get_all_schema_tables():
    """
    ëª¨ë“  ìŠ¤í‚¤ë§ˆ, í…Œì�´ë¸” ëª©ë¡� ì¡°íšŒ
    """
    try:
        sqlplus_cmd = [
            'sqlplus', '-S', 'LLM/L9SD2TT9XJ0H@//210.113.16.230:1521/ORA11GDR'
        ]
        sql_query = """SET PAGESIZE 0 FEEDBACK OFF VERIFY OFF HEADING OFF ECHO OFF;
        SELECT OWNER, TABLE_NAME FROM ALL_TABLES ORDER BY OWNER, TABLE_NAME;
        EXIT;"""

        result = subprocess.run(
            sqlplus_cmd,
            input=sql_query,
            capture_output=True,
            text=True
        )

        schema_tables = {}
        for line in result.stdout.splitlines():
            line = line.strip()
            if line:
                parts = line.split()
                if len(parts) >= 2:
                    schema, table = parts[0], parts[1]
                    if schema not in schema_tables:
                        schema_tables[schema] = []
                    schema_tables[schema].append(table)

        if schema_tables:
            print("  ìŠ¤í‚¤ë§ˆë³„ í…Œì�´ë¸” ëª©ë¡�:")
            for schema, tables in schema_tables.items():
                print(f"\nğŸ”¹ ìŠ¤í‚¤ë§ˆ: {schema}")
                for t in tables:
                    print(f"  - {t}")
        else:
            print(" í…Œì�´ë¸”ì�´ ì¡´ì�¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        return schema_tables

    except subprocess.CalledProcessError as e:
        print(f" Error: {e.stderr}")
        return {}


def make_metadata_from_table(schema_name="ICON", table_name="OPRAIMDG"):
    """
    ì˜ˆì‹œ í•¨ìˆ˜: OPRAIMDG í…Œì�´ë¸”ë¡œë¶€í„° UN, CLASS, DESCRIPTION ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜
    """
    sql_query = f"""
    SET LINESIZE 2000;
    SET PAGESIZE 0;
    SET TRIMSPOOL ON;
    COL IMDCOM FORMAT A200;
    SELECT IMDUNM, IMDCLS, REPLACE(REPLACE(IMDCOM, CHR(10), ' '), CHR(13), ' ') AS IMDCOM 
    FROM {schema_name}.{table_name};
    EXIT;
    """

    try:
        result = subprocess.run(sqlplus_command, input=sql_query, capture_output=True, text=True)
        print(f"  RESULT: \n{str(result)[:1000]}")
        output = result.stdout
        print(f"  OUTPUT: \n{str(output)[:1000]}")

        lines = output.strip().split("\n")
        print(f"  LINE: \n{str(lines)[:1000]}")
        metadata = []

        for line in lines[:-1]:
            values = line.split(None, 2)
            if len(values) == 3:
                imdunm = values[0].strip()
                imdcls = values[1].strip()
                imdcom = values[2].strip()
                metadata.append({
                    "UNNO": imdunm,
                    "Class": imdcls,
                    "Description": imdcom
                })

        json_filename = "/workspace/data/METADATA_OPRAIMDG.json"
        with open(json_filename, "w", encoding="utf-8") as json_file:
            json.dump(metadata, json_file, indent=4, ensure_ascii=False)

        print(f"  Metadata saved to {json_filename}")

    except subprocess.CalledProcessError as e:
        print(f" SQL Execution Error: {e.stderr}")


@time_tracker
def run_sql_unno(cls=None, unno=None, pol_port='KR%', pod_port='JP%'):
    """
    ai_dg_check í…Œì�´ë¸”ì—�ì„œ CLS, UNNO, PORTì—� ëŒ€í•œ DG ì„ ì � ê°€ëŠ¥ ì—¬ë¶€ ì¡°íšŒ
    """
    cls_val = "NULL" if (cls is None or cls == "NULL") else f"'{cls}'"
    unno_val = "NULL" if (unno is None or unno == "NULL") else f"'{unno}'"

    sql_query = f"""
    SET LINESIZE 150;
    SET PAGESIZE 1000;
    SET TRIMSPOOL ON;

    SELECT 
        p.cls  AS CLS,
        p.unno AS UNNO,
        p.port AS POL_PORT,
        d.port AS POD_PORT,
        DECODE(p.allow_yn,'Y','OK','N','Forbidden','Need to contact PIC of POL') AS Landing_STATUS,
        DECODE(d.allow_yn,'Y','OK','N','Forbidden','Need to contact PIC of POL') AS Departure_STATUS
    FROM icon.ai_dg_check p
    JOIN icon.ai_dg_check d 
        ON p.unno = d.unno 
        AND p.cls = d.cls
    WHERE (p.cls={cls_val} OR {cls_val} IS NULL) AND (p.unno={unno_val} OR {unno_val} IS NULL) 
      AND p.port LIKE '{pol_port}'
      AND (p.cls={cls_val} OR {cls_val} IS NULL) AND (d.unno={unno_val} OR {unno_val} IS NULL) 
      AND d.port LIKE '{pod_port}';
    EXIT;
    """

    try:
        result = subprocess.run(sqlplus_command, input=sql_query, capture_output=True, text=True)
        print("  SQL Query Results:\n", result.stdout)
    except subprocess.CalledProcessError as e:
        print(f" Error: {e.stderr}")

    return sql_query, result.stdout


@time_tracker
def run_sql_bl(cls=None, unno=None, pol_port='KR%', pod_port='JP%'):
    """
    B/L ìƒ�ì„¸ ì¡°íšŒ
    """
    cls_val = "NULL" if (cls is None or cls == "NULL") else f"'{cls}'"
    unno_val = "NULL" if (unno is None or unno == "NULL") else f"'{unno}'"

    sql_query = f"""
    SELECT *
    FROM (
        SELECT
            MST.FRTBNO AS "B/L No",
            MST.FRTOBD AS onBoard_Date,
            MST.FRTPOL AS POL,
            MST.FRTPOD AS POD,
            MST.FRTSBM AS ship_back,
            CNT.KCTUNN AS UNNO,
            CNT.KCTCLS AS CLASS,
            COUNT(*) AS "DG_Container_Count"
        FROM ICON.WSDAMST MST
        JOIN ICON.WSDACNT CNT ON CNT.KCTBNO = MST.FRTBNO
        WHERE MST.BUKRS = '1000'
        AND CNT.BUKRS = '1000'
        AND MST.FRTOBD BETWEEN TO_CHAR(SYSDATE-1095,'YYYYMMDD')+1 AND TO_CHAR(SYSDATE+1,'YYYYMMDD')
        AND CNT.KCTUNN = {unno_val}
        AND CNT.KCTCLS = {cls_val}
        AND MST.FRTPOL = '{pol_port}'
        AND MST.FRTPOD = '{pod_port}'
        GROUP BY
            MST.FRTBNO,
            MST.FRTOBD,
            MST.FRTPOL,
            MST.FRTPOD,
            MST.FRTSBM,
            CNT.KCTUNN,
            CNT.KCTCLS
    )
    WHERE ROWNUM <= 5;
    EXIT;
    """

    try:
        result = subprocess.run(sqlplus_command, input=sql_query, capture_output=True, text=True)
        print("[SQL_NS] SQL Query run_sql_bl Results:\n", result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"[SQL_NS] run_sql_bl Error: {e.stderr}")

    return sql_query, result.stdout


def get_metadata(config):
    """
    metadata_path (port ë�°ì�´í„°), metadata_unno (UN ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸)ì—� ì�ˆëŠ” ë‚´ìš©ì�„ ë¶ˆëŸ¬ì™€ ë°˜í™˜
    """
    print("[SOOWAN] get_metadata ì§„ì�…")
    if not config or not hasattr(config, "metadata_unno"):
        raise ValueError("Config ê°�ì²´ì—� 'metadata_unno' ì†�ì„±ì�´ ì—†ìŠµë‹ˆë‹¤.")

    unno_path = config.metadata_unno
    port_path = config.metadata_path

    with open(port_path, "r", encoding="utf-8") as f:
        port_data = json.load(f)
    location_codes = json.dumps(port_data.get("location_code"), ensure_ascii=False)

    with open(unno_path, "r", encoding="utf-8") as f:
        unno_data = json.load(f)
    unno_list_as_string = json.dumps(unno_data, ensure_ascii=False)

    return location_codes, unno_list_as_string


# [ì¤‘ìš”] generate_sql í•¨ìˆ˜ ì œê±°ë�¨ (ì�´ì „ì—�ëŠ” ì—¬ê¸° ì¡´ì�¬í–ˆìœ¼ë‚˜ RAG.pyë¡œ ì�´ë�™)
#        ì˜¤ì§� SQLë§Œ ë‹´ë‹¹í•˜ë�„ë¡� ë³€ê²½.

if __name__ == "__main__":
    # ì•„ë�˜ëŠ” í…ŒìŠ¤íŠ¸/ë””ë²„ê¹…ìš© ì½”ë“œ
    # í•„ìš”í•œ ê²½ìš°ì—�ë§Œ ì‚¬ìš© ê°€ëŠ¥. ì‹¤ì œ ìš´ì˜� ì‹œì—” ì œê±°í•  ìˆ˜ë�„ ì�ˆì�Œ.

    check_sqlplus()             # sqlplusê°€ ì�˜ ë�™ì�‘í•˜ëŠ”ì§€ í™•ì�¸
    check_db_connection()       # ë�°ì�´í„°ë² ì�´ìŠ¤ ì ‘ì†� ì—¬ë¶€ í™•ì�¸
    schema_info = get_all_schema_tables()
    print("Schema info:", schema_info)
    # make_metadata_from_table()  # íŠ¹ì • í…Œì�´ë¸”ë¡œë¶€í„° ë©”íƒ€ë�°ì�´í„° ìƒ�ì„±í•˜ëŠ” ì˜ˆì‹œ
    # ì˜ˆì‹œ SQL ì‹¤í–‰
    sql_q, sql_res = run_sql_unno(cls=4.1, unno=1033, pol_port="KRPUS", pod_port="JPKOB")
    print("[TEST] run_sql_unno result:", sql_q, sql_res)
    sql_q2, sql_res2 = run_sql_bl(cls=4.1, unno=1033, pol_port="KRPUS", pod_port="JPKOB")
    print("[TEST] run_sql_bl result:", sql_q2, sql_res2)

```

```log

(InferenceActor pid=591) === [In-Flight Batching] Waiting for first item in request_queue... ===
(InferenceActor pid=591) [2025-03-20 08:36:54] INFO tracking.py:15: Exiting load_data() -- Elapsed: 1.38s
[2025-03-20 08:36:59] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:36:59] "GET /chat HTTP/1.1" 200 -
[2025-03-20 08:36:59] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:36:59] "GET /static/chat_styles.css HTTP/1.1" 200 -
INFO 2025-03-20 08:37:00,043 serve 1 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x788816e17090>.
[2025-03-20 08:37:00] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:00] "GET /history?request_id=1742459818907-9433 HTTP/1.1" 200 -
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:00,071 default_inference 1zebleoo 71ff39a0-4d23-4a81-987b-1aee4614f79a -- CALL get_history OK 4.9ms
[2025-03-20 08:37:00] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:00] "GET /static/NS_LOGO_ONLY.svg?height=80&width=80 HTTP/1.1" 304 -
[2025-03-20 08:37:01] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:01] "GET /test HTTP/1.1" 200 -
[2025-03-20 08:37:01] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:01] "GET /static/test_styles.css HTTP/1.1" 200 -
[2025-03-20 08:37:01] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:01] "GET /static/test_set.js HTTP/1.1" 200 -
[DEBUG] /query_stream called with qry_id='only3-1', user_id='', page_id='', qry_contents='남성해운 중국 시장 근황', qry_time='2025-03-20T08:37:01.949Z'
[DEBUG] Built http_query: {'qry_id': 'only3-1', 'user_id': '', 'page_id': '5d92db76-0666-4580-8089-b9798a234ea3', 'auth_class': 'admin', 'qry_contents': '남성해운 중국 시장 근황', 'qry_time': '2025-03-20T08:37:01.949Z'}
[DEBUG] /query_stream called with qry_id='only3-3', user_id='', page_id='', qry_contents='남성해운의 새로운 전략', qry_time='2025-03-20T08:37:01.949Z'
[DEBUG] Built http_query: {'qry_id': 'only3-3', 'user_id': '', 'page_id': '5f6eae2d-a83f-4086-9caf-73f27bff73f8', 'auth_class': 'admin', 'qry_contents': '남성해운의 새로운 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}
[DEBUG] /query_stream called with qry_id='only3-2', user_id='', page_id='', qry_contents='공 컨테이너 이송 전략', qry_time='2025-03-20T08:37:01.949Z'
[DEBUG] Built http_query: {'qry_id': 'only3-2', 'user_id': '', 'page_id': '5513e85e-164c-422f-9c3e-19c3d67b7335', 'auth_class': 'admin', 'qry_contents': '공 컨테이너 이송 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}
[DEBUG] streaming chat_id=5d92db76-0666-4580-8089-b9798a234ea3
[DEBUG] streaming chat_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
[DEBUG] streaming chat_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:03,293 default_inference 1zebleoo 4b0b3cc3-98f2-48cf-9aa9-766d4fdcdaa7 -- CALL process_query_stream OK 45.5ms
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:03,293 default_inference 1zebleoo 3da4d3fe-7483-4ee8-9efe-3691516dcb09 -- CALL process_query_stream OK 41.8ms
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:03,293 default_inference 1zebleoo 7bf130fa-530b-4323-aa47-c2b79a5b407f -- CALL process_query_stream OK 38.6ms
(InferenceActor pid=591) [STREAM] process_query_stream => chat_id=5d92db76-0666-4580-8089-b9798a234ea3, http_query={'qry_id': 'only3-1', 'user_id': '', 'page_id': '5d92db76-0666-4580-8089-b9798a234ea3', 'auth_class': 'admin', 'qry_contents': '남성해운 중국 시장 근황', 'qry_time': '2025-03-20T08:37:01.949Z'}
(InferenceActor pid=591) [STREAM] Created SSE queue for chat_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [STREAM] Putting item into request_queue for chat_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [STREAM] Done putting item in queue => chat_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [In-Flight Batching] Got the first request. Attempting to fill a batch...
(InferenceActor pid=591) [STREAM] process_query_stream => chat_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8, http_query={'qry_id': 'only3-3', 'user_id': '', 'page_id': '5f6eae2d-a83f-4086-9caf-73f27bff73f8', 'auth_class': 'admin', 'qry_contents': '남성해운의 새로운 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}
(InferenceActor pid=591) [STREAM] Created SSE queue for chat_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [STREAM] Putting item into request_queue for chat_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [STREAM] Done putting item in queue => chat_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [STREAM] process_query_stream => chat_id=5513e85e-164c-422f-9c3e-19c3d67b7335, http_query={'qry_id': 'only3-2', 'user_id': '', 'page_id': '5513e85e-164c-422f-9c3e-19c3d67b7335', 'auth_class': 'admin', 'qry_contents': '공 컨테이너 이송 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}
(InferenceActor pid=591) [STREAM] Created SSE queue for chat_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [STREAM] Putting item into request_queue for chat_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [STREAM] Done putting item in queue => chat_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [In-Flight Batching] +1 request => batch size now 2 <<< 5
(InferenceActor pid=591) [In-Flight Batching] +1 request => batch size now 3 <<< 5
(InferenceActor pid=591) [In-Flight Batching] Timeout reached => proceeding with the batch.
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO debug_tracking.py:26: [Batch Tracking] Batch size: 3, Token counts: [0, 0, 0]
(InferenceActor pid=591) [DEBUG] _process_single_query 시작: 08:37:03, 요청 내용: {'request_id': '5d92db76-0666-4580-8089-b9798a234ea3', 'http_query': {'qry_id': 'only3-1', 'user_id': '', 'page_id': '5d92db76-0666-4580-8089-b9798a234ea3', 'auth_class': 'admin', 'qry_contents': '남성해운 중국 시장 근황', 'qry_time': '2025-03-20T08:37:01.949Z'}}, 현재 스레드: AsyncIO Thread: default
(InferenceActor pid=591) [STREAM] _process_single_query: request_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [DEBUG] Creating new CustomConversationBufferMemory for session=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, 사용자 입력 질문: 8, 총합: 8
(InferenceActor pid=591) Using cached data
(InferenceActor pid=591)    ... calling query_sort() ...
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:03 [async_llm.py:204] Added request d96d8155-f81f-44fe-b563-0df8e46cac4a.
(InferenceActor pid=591) [DEBUG] _process_single_query 시작: 08:37:03, 요청 내용: {'request_id': '5f6eae2d-a83f-4086-9caf-73f27bff73f8', 'http_query': {'qry_id': 'only3-3', 'user_id': '', 'page_id': '5f6eae2d-a83f-4086-9caf-73f27bff73f8', 'auth_class': 'admin', 'qry_contents': '남성해운의 새로운 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}}, 현재 스레드: AsyncIO Thread: default
(InferenceActor pid=591) [STREAM] _process_single_query: request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [DEBUG] Creating new CustomConversationBufferMemory for session=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, 사용자 입력 질문: 7, 총합: 7
(InferenceActor pid=591) Using cached data
(InferenceActor pid=591)    ... calling query_sort() ...
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:03 [async_llm.py:204] Added request 1f24ef8d-5c16-4571-83fd-38ccd6f3ee59.
(InferenceActor pid=591) [DEBUG] _process_single_query 시작: 08:37:03, 요청 내용: {'request_id': '5513e85e-164c-422f-9c3e-19c3d67b7335', 'http_query': {'qry_id': 'only3-2', 'user_id': '', 'page_id': '5513e85e-164c-422f-9c3e-19c3d67b7335', 'auth_class': 'admin', 'qry_contents': '공 컨테이너 이송 전략', 'qry_time': '2025-03-20T08:37:01.949Z'}}, 현재 스레드: AsyncIO Thread: default
(InferenceActor pid=591) [STREAM] _process_single_query: request_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [DEBUG] Creating new CustomConversationBufferMemory for session=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, 사용자 입력 질문: 7, 총합: 7
(InferenceActor pid=591) Using cached data
(InferenceActor pid=591)    ... calling query_sort() ...
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:03 [async_llm.py:204] Added request f1602751-d97c-4f16-98bf-d71e16e55b2c.
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO debug_tracking.py:12: 배치 처리 전 상태 - Process Memory: RSS=1501.67 MB, VMS=23931.98 MB
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO debug_tracking.py:13: 배치 처리 전 상태 - GPU Memory: allocated=0.00 MB, reserved=0.00 MB
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering load_data()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting load_data() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering query_sort()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting query_sort() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering load_data()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting load_data() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering query_sort()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting query_sort() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering load_data()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting load_data() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering query_sort()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting query_sort() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:03] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>공 컨테이너 이송 전략에 대해 알려줘<query>
(InferenceActor pid=591) <keyword/>공 컨테이너 이송 전략<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 공 컨테이너 이송 전략에 대해 알려줘, 키워드 : 공 컨테이너 이송 전략, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591)    ... query_sort => QU=공 컨테이너 이송 전략에 대해 알려줘, KE=공 컨테이너 이송 전략, TA=no, TI=1900-01-01:2099-01-01
(InferenceActor pid=591) [SOOWAN] TA is No, before make a retrieval
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:04 [async_llm.py:204] Added request 503924d0-62ee-40a6-9d46-1bfeca8a4997.
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:11: Entering specific_question()
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:15: Exiting specific_question() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>남성해운의 새로운 전략에 대해 자세히 알려줘<query>
(InferenceActor pid=591) <keyword/>남성해운, 새로운 전략<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 남성해운의 새로운 전략에 대해 자세히 알려줘, 키워드 : 남성해운, 새로운 전략, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591)    ... query_sort => QU=남성해운의 새로운 전략에 대해 자세히 알려줘, KE=남성해운, 새로운 전략, TA=no, TI=1900-01-01:2099-01-01
(InferenceActor pid=591) [SOOWAN] TA is No, before make a retrieval
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:04 [async_llm.py:204] Added request d75b945c-9b03-4598-a054-eb9596d9eb5f.
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:11: Entering specific_question()
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:15: Exiting specific_question() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:04] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
[DEBUG] /query_stream called with qry_id='1742459823644-1834', user_id='user123', page_id='1742459818907-9433', qry_contents='디지털 기획팀의 우선과제가 어떻게 돼?', qry_time='2025-03-20T08:37:03.644Z'
[DEBUG] Built http_query: {'qry_id': '1742459823644-1834', 'user_id': 'user123', 'page_id': '1742459818907-9433', 'auth_class': 'admin', 'qry_contents': '디지털 기획팀의 우선과제가 어떻게 돼?', 'qry_time': '2025-03-20T08:37:03.644Z'}
[DEBUG] streaming chat_id=1742459818907-9433
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:04,954 default_inference 1zebleoo bccf38cc-5a62-417b-9b02-6bce4aee02eb -- CALL process_query_stream OK 4.3ms
(InferenceActor pid=591) [STREAM] process_query_stream => chat_id=1742459818907-9433, http_query={'qry_id': '1742459823644-1834', 'user_id': 'user123', 'page_id': '1742459818907-9433', 'auth_class': 'admin', 'qry_contents': '디지털 기획팀의 우선과제가 어떻게 돼?', 'qry_time': '2025-03-20T08:37:03.644Z'}
(InferenceActor pid=591) [STREAM] Created SSE queue for chat_id=1742459818907-9433
(InferenceActor pid=591) [STREAM] Putting item into request_queue for chat_id=1742459818907-9433
(InferenceActor pid=591) [STREAM] Done putting item in queue => chat_id=1742459818907-9433
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>남성해운의 중국 시장 최근 동향 및 현황을 알려줘<query>
(InferenceActor pid=591) <keyword/>남성해운, 중국 시장, 근황, 동향, 현황<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>2024-06-01:2025-3-20<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 남성해운의 중국 시장 최근 동향 및 현황을 알려줘, 키워드 : 남성해운, 중국 시장, 근황, 동향, 현황, 테이블 필요 유무: no, 시간: 2024-06-01:2025-3-20
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591)    ... query_sort => QU=남성해운의 중국 시장 최근 동향 및 현황을 알려줘, KE=남성해운, 중국 시장, 근황, 동향, 현황, TA=no, TI=2024-06-01:2025-3-20
(InferenceActor pid=591) [SOOWAN] TA is No, before make a retrieval
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:05 [async_llm.py:204] Added request 2089a2aa-36f1-486e-b35d-9e67a25ec3ed.
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:11: Entering specific_question()
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:15: Exiting specific_question() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>공 컨테이너 이송 전략에 대해 알려줘<query>
(InferenceActor pid=591) <keyword/>공 컨테이너 이송 전략</keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) [ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.
(InferenceActor pid=591) ##### query_sort is starting, attempt: 2 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:05 [async_llm.py:204] Added request 92355766-3267-4f7c-8cca-eee1bd663a4a.
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>남성해운의 새로운 전략에 대해 알려줘<query>
(InferenceActor pid=591) <keyword/>남성해운, 새로운 전략</keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) [ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.
(InferenceActor pid=591) ##### query_sort is starting, attempt: 2 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:05 [async_llm.py:204] Added request 36177a68-4206-4ad2-b41e-b1b15a8a5143.
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:05] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>공 컨테이너 이송 전략에 대해 알려줘<query>
(InferenceActor pid=591) <keyword/>공 컨테이너 이송 전략<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 공 컨테이너 이송 전략에 대해 알려줘, 키워드 : 공 컨테이너 이송 전략, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) [SOOWAN]: execute_rag : 진입
(InferenceActor pid=591) [SOOWAN]: execute_rag : 테이블 필요없음
(InferenceActor pid=591) [시간 범위] 전체 기간 사용
(InferenceActor pid=591) [RETRIEVE] 검색에 사용되는 문서 수: 3511
(InferenceActor pid=591) [SOOWAN] retrieve : 진입
(InferenceActor pid=591) [SOOWAN] cal_sim_score : 진입 / query :  공 컨테이너 이송 전략
(InferenceActor pid=591) [SOOWAN] embed: 진입
(InferenceActor pid=591) [SOOWAN] embed: 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V 생산 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V.shape == 1
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering execute_rag()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:15: Exiting execute_rag() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering expand_time_range_if_needed()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:15: Exiting expand_time_range_if_needed() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering retrieve()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO RAG.py:440: Retrieval for query: '공 컨테이너 이송 전략'
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO RAG.py:441: Available documents: 3511
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering cal_sim_score()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering embed()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:15: Exiting embed() -- Elapsed: 0.02s
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:15: Exiting cal_sim_score() -- Elapsed: 0.13s
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO RAG.py:445: Similarity score shape: (3511, 1, 1)
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO tracking.py:11: Entering cal_bm25_score()
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO RAG.py:557: Starting BM25 calculation for query: 공 컨테이너 이송 전략
(InferenceActor pid=591) [2025-03-20 08:37:07] INFO RAG.py:558: Document count: 3511
(InferenceActor pid=591) [2025-03-20 08:37:08] INFO RAG.py:591: BM25 scores: min=0.7488, max=15.8277, mean=3.7985
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting cal_bm25_score() -- Elapsed: 1.87s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:448: BM25 score shape: (3511,)
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
[2025-03-20 08:37:09] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:09] "POST /query_stream HTTP/1.1" 200 -
(InferenceActor pid=591) -------------자료 검색 성공--------------
(InferenceActor pid=591) ------- [{'file_name': '[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx', 'title': '[운영혁신본부] 2023년 년간 사업계획 > 컨테이너관리팀 중점 추진과제 실행계획', 'contents': [{'rsp_type': 'TB', 'rsp_tit': '컨테이너 보유량 통제 및 신규 서비스 지역 재고 관리', 'rsp_data': {'head': '유형||중점 추진과제||추진목표 및 중점 추진항목||과제수행 책임리더||비 고', 'body': '컨관팀\x0b추진과제||컨테이너 보유량 통제 (E/P관리 포함)||노후 임대 컨테이너 반납 및 재 연장 검토 노후VAN 교체를 위한 최소 14년 이상 경과 장비 매각 진행 검토 매각대상 20’DC X 1,847 &amp; 40HC X 2,145(2008년 이전 제작) 신규 서비스 및 선복 증감 대비 적정 운영수량 통제/관리 장비 운영 효율성 지속 관리/개선 노력 22년 65%→23년 68% IMBALANCE 개선을 통하여 지속 E/P 수량 제어 노력 국내외 지역간 적시 E/P를 통한 장비 재배치 및 효율성 제고 권역별 장기 미사용 적체 컨테이너 집중 관리||(主) 컨테이너관리팀 (協) 영업추진본부 운항관리팀 해외법인 및 사무소||물동량 및 컨테이너 시황 고려하여 장비 수급 조절 장비 효율성에 따라 E/P 수량 변동^||신규 서비스 지역 재고관리||신규항로 서비스 인도네시아/말레이시아/마닐라 재고 집중 관리 IMBALANCE로 인한 IDLE CNTR 장비 최소화 및 적시 해소 노력 ICON+를 활용 및 주기적 현황 파악을 통한 재고관리 강화||(主)컨테이너관리팀 (協)해외법인 및 사무소 영업추진본부||'}}], 'chunk_id': 916}, {'file_name': '[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx', 'title': '내륙운송화물 운송Mode별 (Barge/Rail/Trucking) Movement 도식화', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '*BARGE (Full) \n*RAIL (Full) \n*TRUCKING (Full) \nBX : Export Full Loading \nRX : Export Full Loading \nOX : Export Full Gate-out \nGX : Export Full Discharging \nLX : Export Full Discharging \nTX : Export Full Gate-in \nBI : Import Full Loading \nRI : Import Full Loading \nOI : Import Full Gate-out \nGI : Import Full Discharging \nLI : Import Full Discharging \nTI : Import Full Gate-in \n*BARGE (Empty) \n*RAIL (Empty) \n*TRUCKING (Empty) \nBE : Empty Loading \nRE : Empty Loading \nOE : Empty Loading'}], 'chunk_id': 920}, {'file_name': '남성해운_팀별 주간회의_W45_231107.pptx', 'title': '[신성장전략실] 디지털운영팀장 > 업무 자동화 영역 서비스 고도화', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '[협업]\n컨테이너관리팀\nIn 서비스\nTrans Mode Mvmt Status 표준화 관리 고도화\nland\n. 現, 멀티모달 비즈니스에 맞는 Mvmt Status 코드 표준안 개선 시급\n. Ocean 구간이외 Trans mode별 Mvmt Status 모호\n. Trans mode별 서비스 지역의 컨테이너 이동 현황 핀셋 관리 필요\n. Trans mode의 Mvmt Status에 맞는 코드 로직 재정의 및 신규 코드로 Cntr Mvmt 등록/관리\n. Trans mode의 Mvmt Status에 맞는 Dem/Det배치 로직 재정의\n. 신규 코드 생성\n. 등록 관리 ( 5201,5202,5211,5203 : ICON+)\n. Dem/Det daily batch계산 로직 적용 결과도출\n배경\n배경\n배경\n배경\n배경\nAs is\n[ Trans mode : Barge]\nTo be\n[ Trans mode :Barge]\n신규 Mvmt 코드 정의\nBF :\xa0Barge\xa0Full loading\nGF :\xa0Barge full\xa0Discharging\nBE :\xa0Barge\xa0Empty loading\nRF :\xa0Rail\xa0Full loading\nAF :\xa0Rail full\xa0Discharging\nRE :\xa0Rail\xa0Empty loading\nOF : Truck\xa0Full loading\nTF : Truck\xa0Full Discharging\nOE : Truck \xa0Empty loading\nKRINC\nKRINC\n[ Trans mode ]\nVF\nVF\nCNSHA\nCNSHA\nDF\nDF\nCNSHA\nCNSHA\nVF\nBF\nCNZHE\nOcean과 같은 mvmt status를 사용하여 가장 마지막 DF/CF/TE로 계산\nCNZHE\nGF : Barge full\xa0Discharging이후 TE까지 계산\nDF\nGF\nCNZHE\nCNZHE\nCF\nCF\nCNZHE\nCNZHE\nTE\nTE'}], 'chunk_id': 1813}, {'file_name': '[남성해운] 24년 2사분기 수정사업계획 및 핵심추진과제 진행경과 공유회_20240404.pptx', 'title': '[컨/관리팀] 2024년도 핵심추진과제 > #1. 주요장비 적체지역 집중 관리 및 M&R 비용관리 통제', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '[해외 M&R 관리 현황]\n10개 주요 권역 VAN당 수리비 목표금액(USD) 설정하여\n수리비 인하 및 수리수량 감소 노력\n동중국 상해 추가 및 태국지역 방콕 & 람차방 구분으로\n집중 관리지역 총 10권역으로 확대 관리\n화물 증감 및 수리비 감면 비율 등에 따라 수리비 변화 영향,\n지속 관리를 통하여 사업목표 남성(-11%) & 동영(-5%) 달성 노력\n월평균 수리비(24년 1~2월 기준)\n23년 전체 월평균 수리비 대비 태국 일부 증가하였으나\n중국 주요지역 상해/셔코우/청도 감소\n일본지역 남성 & 동영 모두 수리비 총액기준 관리 중에 있으며\n수리총액 및 단가 전년 월평균 대비 감소\n23년 대비 24년 1~2월 평균 수리비\n남성해운 USD11,140/월 → USD8,533\n& 동영해운 USD5,223/월 → USD2,611/월'}, {'rsp_type': 'TB', 'rsp_tit': '10개 주요 권역의 건조선박 M&R 예산 및 평균 수리 비용', 'rsp_data': {'head': '※ Dry cargo - M&amp;R Budget management - Average repair cost per Van - Icon 5437 Owner cost only||||||||||||||||||||', 'body': 'Sq.||RHQ||Location||NS||||||||DY||||||^||||||2022||2023||2024||||2022||2023||2024||^||||||||||Target||%||||||Target||%^1||China\x0b(North)||CNTXG||20.9||23.0||21.9||-5%||24.7||20.6||19.5||-5%^2||||CNTAO||32.8||27.8||26.5||-5%||28.7||26.3||25.0||-5%^3||(East)||CNSHA||17.2||21.8||20.8||-5%||20.3||19.9||19.0||-5%^4||China\x0b(South)||HKHKG||46.9||38.8||37.0||-5%||43.6||40.3||36.3||-10%^5||||CNSHK||32.2||34.2||30.0||-12%||22.2||25.3||20.3||-20%^6||VN||VNSGN||7.5||6.9||6.8||-1%||||||||^7||||VNHPH||13.0||11.1||10.6||-5%||9.9||8.3||7.9||-5%^8||TH||THBKK||30.1||24.4||23.3||-5%||||||||^9||||THLCH||19.0||33.4||25.2||-25%||||||||^10||SG||SGSIN||60.8||44.6||35.9||-20%||||||||^10개 주요 권역 누계||||||17.4||18.2||16.2||-11%||12.5||12.8||12.1||-5%'}}], 'chunk_id': 775}, {'file_name': '남성해운_팀별 주간회의_W47_231121.pptx', 'title': '[신성장전략실] 신성장실현팀장 > 거점/운송인프라', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '해상+육상운송 연계 활성화\n(11월 진행사항)\n* 영업목적 CY – Door term 연계 통한 서비스 확대\n당사 or 운송사 미사용 업체 사용 유도 통한 물동량 확대 / 신규화주 유치\nA : 연계 진행업체\nB : 연계 진행 검토, 또는 미정\nC : 연계 부정적 업체(관심 X)'}, {'rsp_type': 'TB', 'rsp_tit': '투더블유로직스, 해외 물류 파트너십 확대 추진 중', 'rsp_data': {'head': '신성장실현팀||투더블유로직스||||', 'body': '||논의내용||주요진행구간||진행가능성^온누리로지스틱스||우수선화주선정사로 양사간 협업 통한 사례확보 및 미주,유럽에 편중된 지역에 대한 탈피/확보차원 협력 예정 -&gt; 부산출항분이긴 하나 미진행 건이던 부산-&gt;South Manila 소량 진행(11월 22일) 40’X1||미주,유럽 main 북중국,동중국 등 해외파트너사 nomi건||B(현지 노미건 물량에 따라 연계 가능물량이 차이 날 것으로 보임)^로지스틱스 파트너즈||인천-신강향 차량 수출로 컨택, 작업지 등 이슈 등 변수는 남아있음. 운송사 연계 등에 대한 큰 거부감은 없는 상황||중국향 위주(소량 진행 중)||B(진행가능성은 높으나 소량 물량 + 인천-신강 구간 40’제한 등 변수 존재)^이허브에스티||한국발 냉동위주 소량 당사 진행 중으로 운임 경쟁력 확보 위해 비용 절감 부분에 관심 많음. 운임수준은 대부분 하향세인 상황서 운송료 연계로 향후 경쟁력 확보에 목표||부산-홍콩,마카오,베트남 등||B(인천보단 부산위주 진행 중, 향후 부산확장 계획 등 공유 완료)^카고솔루션||이전 엠트랜스 영업부장이던 박래천 부장 이직으로 연결, 신규업체 마음으로 최근 영업 진행 중, 당사 인프라에 대한 소개 연계 할 수 있게 협조요청||인천-&gt;싱가포르 진행||A(door term은 아니지만 11월 선적분에 대해 투더블유 운송사 사용 잠정 확정) 40’x4 선적+운송 확정 향후 door term 확대 검토^밸류링크유||디지털포워딩 활용한 인천발 door 연계 지속 검토||인천-&gt;하이퐁||A(인천-하이퐁 태웅식품 진행 확정(40’x1))^뉴웨이브로지스틱스||투더블유와 인연있는 대표님 통해 조만간 진행건 투더블유 연계 검토||check||A(11월 부킹 접수 예정)^스타콩코드||부산물량 메인, 인천물량은 소량이지만 적극적으로 검토하기로(황선아지점장)||||B(조만간 진행 가능할 것으로 기대 중)^나오스월드||최근 라오스착/발 화물에 대해 확대 거래 중인 상황서 현지 door term 진행 중인 상황, 향후 한국까지 Door term 확대에 대해 검토/노력하자는 당사 의도 전달||한국 – 라오스(태국) 한국-몽골(신강)||B(한국 운송은 아직 진행되지 않았으나, 인천발 라오스 진행시는 최대한 투더블유 Try 압박 예정)^카스해운||플렉시설치 및 ISO TNK 주요 진행업체로 일부 플렉시 설치에 대한 야드 및 운송연계 활용 가능여부에 대한 논의||한국-동남아||B(서비스 중인 고객사들이 대부분 운송사 지정하고 있는 경우가 많음, 설치 작업의 경우 대부분 남항에서 이뤄지고 있음, 향후 신항 병행작업에 대한 검토)'}}], 'chunk_id': 1839}] -------
(InferenceActor pid=591) ---------------------------------------
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 리트리버
(InferenceActor pid=591) [SOOWAN] TA is No, and make a retrieval is successed
(InferenceActor pid=591) [STREAM] Starting partial generation for request_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [STREAM] _stream_partial_answer => request_id=5513e85e-164c-422f-9c3e-19c3d67b7335, chart=None
(InferenceActor pid=591) [DEBUG] Prepared reference data: {"type": "reference", "status_code": 200, "result": "OK", "detail": "Reference data", "evt_time": "2025-03-20T08:37:09.051340", "data_list": [{"rsp_type": "R", "rsp_tit": "남성 내부 데이터", "rsp_data": [{"rsp_tit": "1번째 검색데이터: [운영혁신본부] 2023년 년간 사업계획 > 컨테이너관리팀 중점 추진과제 실행계획 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx)", "rsp_data": [{"rsp_type": "TB", "rsp_tit": "컨테이너 보유량 통제 및 신규 서비스 지역 재고 관리", "rsp_data": {"head": "유형||중점 추진과제||추진목표 및 중점 추진항목||과제수행 책임리더||비 고", "body": "컨관팀\u000b추진과제||컨테이너 보유량 통제 (E/P관리 포함)||노후 임대 컨테이너 반납 및 재 연장 검토 노후VAN 교체를 위한 최소 14년 이상 경과 장비 매각 진행 검토 매각대상 20’DC X 1,847 &amp; 40HC X 2,145(2008년 이전 제작) 신규 서비스 및 선복 증감 대비 적정 운영수량 통제/관리 장비 운영 효율성 지속 관리/개선 노력 22년 65%→23년 68% IMBALANCE 개선을 통하여 지속 E/P 수량 제어 노력 국내외 지역간 적시 E/P를 통한 장비 재배치 및 효율성 제고 권역별 장기 미사용 적체 컨테이너 집중 관리||(主) 컨테이너관리팀 (協) 영업추진본부 운항관리팀 해외법인 및 사무소||물동량 및 컨테이너 시황 고려하여 장비 수급 조절 장비 효율성에 따라 E/P 수량 변동^||신규 서비스 지역 재고관리||신규항로 서비스 인도네시아/말레이시아/마닐라 재고 집중 관리 IMBALANCE로 인한 IDLE CNTR 장비 최소화 및 적시 해소 노력 ICON+를 활용 및 주기적 현황 파악을 통한 재고관리 강화||(主)컨테이너관리팀 (協)해외법인 및 사무소 영업추진본부||"}}], "chunk_id": 916}, {"rsp_tit": "2번째 검색데이터: 내륙운송화물 운송Mode별 (Barge/Rail/Trucking) Movement 도식화 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "*BARGE (Full) \n*RAIL (Full) \n*TRUCKING (Full) \nBX : Export Full Loading \nRX : Export Full Loading \nOX : Export Full Gate-out \nGX : Export Full Discharging \nLX : Export Full Discharging \nTX : Export Full Gate-in \nBI : Import Full Loading \nRI : Import Full Loading \nOI : Import Full Gate-out \nGI : Import Full Discharging \nLI : Import Full Discharging \nTI : Import Full Gate-in \n*BARGE (Empty) \n*RAIL (Empty) \n*TRUCKING (Empty) \nBE : Empty Loading \nRE : Empty Loading \nOE : Empty Loading"}], "chunk_id": 920}, {"rsp_tit": "3번째 검색데이터: [신성장전략실] 디지털운영팀장 > 업무 자동화 영역 서비스 고도화 (출처:남성해운_팀별 주간회의_W45_231107.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "[협업]\n컨테이너관리팀\nIn 서비스\nTrans Mode Mvmt Status 표준화 관리 고도화\nland\n. 現, 멀티모달 비즈니스에 맞는 Mvmt Status 코드 표준안 개선 시급\n. Ocean 구간이외 Trans mode별 Mvmt Status 모호\n. Trans mode별 서비스 지역의 컨테이너 이동 현황 핀셋 관리 필요\n. Trans mode의 Mvmt Status에 맞는 코드 로직 재정의 및 신규 코드로 Cntr Mvmt 등록/관리\n. Trans mode의 Mvmt Status에 맞는 Dem/Det배치 로직 재정의\n. 신규 코드 생성\n. 등록 관리 ( 5201,5202,5211,5203 : ICON+)\n. Dem/Det daily batch계산 로직 적용 결과도출\n배경\n배경\n배경\n배경\n배경\nAs is\n[ Trans mode : Barge]\nTo be\n[ Trans mode :Barge]\n신규 Mvmt 코드 정의\nBF : Barge Full loading\nGF : Barge full Discharging\nBE : Barge Empty loading\nRF : Rail Full loading\nAF : Rail full Discharging\nRE : Rail Empty loading\nOF : Truck Full loading\nTF : Truck Full Discharging\nOE : Truck  Empty loading\nKRINC\nKRINC\n[ Trans mode ]\nVF\nVF\nCNSHA\nCNSHA\nDF\nDF\nCNSHA\nCNSHA\nVF\nBF\nCNZHE\nOcean과 같은 mvmt status를 사용하여 가장 마지막 DF/CF/TE로 계산\nCNZHE\nGF : Barge full Discharging이후 TE까지 계산\nDF\nGF\nCNZHE\nCNZHE\nCF\nCF\nCNZHE\nCNZHE\nTE\nTE"}], "chunk_id": 1813}, {"rsp_tit": "4번째 검색데이터: [컨/관리팀] 2024년도 핵심추진과제 > #1. 주요장비 적체지역 집중 관리 및 M&R 비용관리 통제 (출처:[남성해운] 24년 2사분기 수정사업계획 및 핵심추진과제 진행경과 공유회_20240404.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "[해외 M&R 관리 현황]\n10개 주요 권역 VAN당 수리비 목표금액(USD) 설정하여\n수리비 인하 및 수리수량 감소 노력\n동중국 상해 추가 및 태국지역 방콕 & 람차방 구분으로\n집중 관리지역 총 10권역으로 확대 관리\n화물 증감 및 수리비 감면 비율 등에 따라 수리비 변화 영향,\n지속 관리를 통하여 사업목표 남성(-11%) & 동영(-5%) 달성 노력\n월평균 수리비(24년 1~2월 기준)\n23년 전체 월평균 수리비 대비 태국 일부 증가하였으나\n중국 주요지역 상해/셔코우/청도 감소\n일본지역 남성 & 동영 모두 수리비 총액기준 관리 중에 있으며\n수리총액 및 단가 전년 월평균 대비 감소\n23년 대비 24년 1~2월 평균 수리비\n남성해운 USD11,140/월 → USD8,533\n& 동영해운 USD5,223/월 → USD2,611/월"}, {"rsp_type": "TB", "rsp_tit": "10개 주요 권역의 건조선박 M&R 예산 및 평균 수리 비용", "rsp_data": {"head": "※ Dry cargo - M&amp;R Budget management - Average repair cost per Van - Icon 5437 Owner cost only||||||||||||||||||||", "body": "Sq.||RHQ||Location||NS||||||||DY||||||^||||||2022||2023||2024||||2022||2023||2024||^||||||||||Target||%||||||Target||%^1||China\u000b(North)||CNTXG||20.9||23.0||21.9||-5%||24.7||20.6||19.5||-5%^2||||CNTAO||32.8||27.8||26.5||-5%||28.7||26.3||25.0||-5%^3||(East)||CNSHA||17.2||21.8||20.8||-5%||20.3||19.9||19.0||-5%^4||China\u000b(South)||HKHKG||46.9||38.8||37.0||-5%||43.6||40.3||36.3||-10%^5||||CNSHK||32.2||34.2||30.0||-12%||22.2||25.3||20.3||-20%^6||VN||VNSGN||7.5||6.9||6.8||-1%||||||||^7||||VNHPH||13.0||11.1||10.6||-5%||9.9||8.3||7.9||-5%^8||TH||THBKK||30.1||24.4||23.3||-5%||||||||^9||||THLCH||19.0||33.4||25.2||-25%||||||||^10||SG||SGSIN||60.8||44.6||35.9||-20%||||||||^10개 주요 권역 누계||||||17.4||18.2||16.2||-11%||12.5||12.8||12.1||-5%"}}], "chunk_id": 775}, {"rsp_tit": "5번째 검색데이터: [신성장전략실] 신성장실현팀장 > 거점/운송인프라 (출처:남성해운_팀별 주간회의_W47_231121.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "해상+육상운송 연계 활성화\n(11월 진행사항)\n* 영업목적 CY – Door term 연계 통한 서비스 확대\n당사 or 운송사 미사용 업체 사용 유도 통한 물동량 확대 / 신규화주 유치\nA : 연계 진행업체\nB : 연계 진행 검토, 또는 미정\nC : 연계 부정적 업체(관심 X)"}, {"rsp_type": "TB", "rsp_tit": "투더블유로직스, 해외 물류 파트너십 확대 추진 중", "rsp_data": {"head": "신성장실현팀||투더블유로직스||||", "body": "||논의내용||주요진행구간||진행가능성^온누리로지스틱스||우수선화주선정사로 양사간 협업 통한 사례확보 및 미주,유럽에 편중된 지역에 대한 탈피/확보차원 협력 예정 -&gt; 부산출항분이긴 하나 미진행 건이던 부산-&gt;South Manila 소량 진행(11월 22일) 40’X1||미주,유럽 main 북중국,동중국 등 해외파트너사 nomi건||B(현지 노미건 물량에 따라 연계 가능물량이 차이 날 것으로 보임)^로지스틱스 파트너즈||인천-신강향 차량 수출로 컨택, 작업지 등 이슈 등 변수는 남아있음. 운송사 연계 등에 대한 큰 거부감은 없는 상황||중국향 위주(소량 진행 중)||B(진행가능성은 높으나 소량 물량 + 인천-신강 구간 40’제한 등 변수 존재)^이허브에스티||한국발 냉동위주 소량 당사 진행 중으로 운임 경쟁력 확보 위해 비용 절감 부분에 관심 많음. 운임수준은 대부분 하향세인 상황서 운송료 연계로 향후 경쟁력 확보에 목표||부산-홍콩,마카오,베트남 등||B(인천보단 부산위주 진행 중, 향후 부산확장 계획 등 공유 완료)^카고솔루션||이전 엠트랜스 영업부장이던 박래천 부장 이직으로 연결, 신규업체 마음으로 최근 영업 진행 중, 당사 인프라에 대한 소개 연계 할 수 있게 협조요청||인천-&gt;싱가포르 진행||A(door term은 아니지만 11월 선적분에 대해 투더블유 운송사 사용 잠정 확정) 40’x4 선적+운송 확정 향후 door term 확대 검토^밸류링크유||디지털포워딩 활용한 인천발 door 연계 지속 검토||인천-&gt;하이퐁||A(인천-하이퐁 태웅식품 진행 확정(40’x1))^뉴웨이브로지스틱스||투더블유와 인연있는 대표님 통해 조만간 진행건 투더블유 연계 검토||check||A(11월 부킹 접수 예정)^스타콩코드||부산물량 메인, 인천물량은 소량이지만 적극적으로 검토하기로(황선아지점장)||||B(조만간 진행 가능할 것으로 기대 중)^나오스월드||최근 라오스착/발 화물에 대해 확대 거래 중인 상황서 현지 door term 진행 중인 상황, 향후 한국까지 Door term 확대에 대해 검토/노력하자는 당사 의도 전달||한국 – 라오스(태국) 한국-몽골(신강)||B(한국 운송은 아직 진행되지 않았으나, 인천발 라오스 진행시는 최대한 투더블유 Try 압박 예정)^카스해운||플렉시설치 및 ISO TNK 주요 진행업체로 일부 플렉시 설치에 대한 야드 및 운송연계 활용 가능여부에 대한 논의||한국-동남아||B(서비스 중인 고객사들이 대부분 운송사 지정하고 있는 경우가 많음, 설치 작업의 경우 대부분 남항에서 이뤄지고 있음, 향후 신항 병행작업에 대한 검토)"}}], "chunk_id": 1839}]}]}
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>남성해운의 중국 시장 현황에 대해 알려줘.<query>
(InferenceActor pid=591) <keyword/>남성해운, 중국 시장, 현황<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>2024-06-01:2025-3-20<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 남성해운의 중국 시장 현황에 대해 알려줘., 키워드 : 남성해운, 중국 시장, 현황, 테이블 필요 유무: no, 시간: 2024-06-01:2025-3-20
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) [SOOWAN]: execute_rag : 진입
(InferenceActor pid=591) [SOOWAN]: execute_rag : 테이블 필요없음
(InferenceActor pid=591) [시간 필터 전] 문서 수: 3511
(InferenceActor pid=591) [시간 필터 후] 문서 수: 540, 기간: 2024-06-01:2025-3-20
(InferenceActor pid=591) [시간 범위] 원래 범위로 충분한 문서 확보: 540개
(InferenceActor pid=591) [RETRIEVE] 검색에 사용되는 문서 수: 540
(InferenceActor pid=591) [SOOWAN] retrieve : 진입
(InferenceActor pid=591) [SOOWAN] cal_sim_score : 진입 / query :  남성해운, 중국 시장, 현황
(InferenceActor pid=591) [SOOWAN] embed: 진입
(InferenceActor pid=591) [SOOWAN] embed: 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V 생산 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V.shape == 1
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:457: Top 5 document indices: [ 915  919 1812  774 1838]
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:458: Top 5 document scores: [0.505448995216034, 0.48653238831295786, 0.4825736862255555, 0.481283066852234, 0.47915923414959727]
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:459: Top document titles: ['[운영혁신본부] 2023년 년간 사업계획 > 컨테이너관리팀 중점 추진과제 실행계획', '내륙운송화물 운송Mode별 (Barge/Rail/Trucking) Movement 도식화', '[신성장전략실] 디지털운영팀장 > 업무 자동화 영역 서비스 고도화', '[컨/관리팀] 2024년도 핵심추진과제 > #1. 주요장비 적체지역 집중 관리 및 M&R 비용관리 통제', '[신성장전략실] 신성장실현팀장 > 거점/운송인프라']
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting retrieve() -- Elapsed: 2.04s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering execute_rag()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting execute_rag() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering expand_time_range_if_needed()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering sort_by_time()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting sort_by_time() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting expand_time_range_if_needed() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering retrieve()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:440: Retrieval for query: '남성해운, 중국 시장, 현황'
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:441: Available documents: 540
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering cal_sim_score()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering embed()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting embed() -- Elapsed: 0.01s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting cal_sim_score() -- Elapsed: 0.03s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:445: Similarity score shape: (540, 1, 1)
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering cal_bm25_score()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:557: Starting BM25 calculation for query: 남성해운, 중국 시장, 현황
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:558: Document count: 540
[2025-03-20 08:37:09] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:09] "POST /query_stream HTTP/1.1" 200 -
(InferenceActor pid=591) -------------자료 검색 성공--------------
(InferenceActor pid=591) ------- [{'file_name': '남성해운_팀별 주간회의_W26_240625.pptx', 'title': '[국내영업본부] 수입영업팀장> 월누적 영업실적 및 주간 주요 특이사항', 'contents': [{'rsp_type': 'TB', 'rsp_tit': '월 누적 영업 실적 및 운임율, 매출 달성도', 'rsp_data': {'head': '월누적\x0b영업\x0b실적||실적(TEU)||||||||운임율(RPT/$), 1 Count||||||||운임율(RPT/$), 2 Count||||||||운임매출(천$)||||||', 'body': '||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)^||14,940||15,150||12,888||85%||401||403||399||99%||392||394||368||94%||5,994||6,105||5,145||84%'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '실적 중국 동남아 운임 동향 주요 이슈 및 영업 방향\n[북중국]\n청도 신규 문의 증가\n더불어 부산TS인천착 증가세\n연운항 운임 회복 시도중\n천진 마켓흐름 약세 선사간 경쟁심화.\n시장 선복 감소 가능성은 존재\n[동중국]\n상해 장비안정\n닝보 장비부족 -> 장비 선별 제공．\n인천향 2주 연속 100%\n난징 장가항 약세진행\n20피트 집화 운임 조정.\n충칭발 한국타이어 운임 상향 입찰예정\n[남중국]\n3/4주차 및 7월 부킹 증가세 진행\n\uf0e0 마켓 장비 공급 부족과 연계\n금주 장비 부족예정으로 집중적인 공급 주력\n(부킹 대비 550F 부족)\n6월 목표대비 실적 84%, 매출 83%\nRPT 398$ (전월 $388 대비 $10▲ )\n[하이퐁]\n개선중\n7월 운임 통지, 마켓 수긍 분위기\n저가화종 20”소량 선적(코일)\n[호치민]\n인천 양호, 부산/광양 약세(KVT & VTX).\n팰릿운임 화주반발 불구, 인상 진행.\n이탈예상시 빠른 장비 활용 추진(EP)\n[태국]\n운임율 개선중\n$256 -> $270 -> $287 -> $308 - >$329 (월 기준)\n[싱/말]\n말레이 7월 계획 운임 수용 어려운 분위기.\n고객사별 조정협의중\n[인니 ]\n증가세\n전 노선 120% 비딩화주 비중 높아 운임회복율 낮으나 7월부 개선 전망\n7월 운임 통지에 대한 구간별 고객사 분위기\n[수긍] 남중국/베트남/태국/청도\n-> 부킹 추이 확인 필요\n[관망] 닝보/상해/인도네시아\n[반발] 말레이시아/천진\n중국 동남아 운임회복 추진(7월 10일자)'}, {'rsp_type': 'TB', 'rsp_tit': '동남아시아 항로 운임 인상, 6월 대비 최대 200달러 상승', 'rsp_data': {'head': 'POL||POD||인상 폭(6월대비)', 'body': '베트남||인천/평택||$200^||부산/울산/광양||$150^태국||인천/평택||$200^||부산/울산/광양||$150^인도네시아||인천||$150^||부산/울산/광양||$100^말레이시아||인천||$150^||부산/울산/광양||$100^심천||인천/평택||$200^||부산/광양||$100^샤먼||인천/평택||$100^||부산/광양||$100^남중국||인천/평택||$200^||부산/광양||$200^청도||한국||$100^연운항||한국||$100^상해/닝보||부산/광양/울산||$50'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '단위:TEU'}], 'chunk_id': 1425}, {'file_name': 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G', 'title': 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page1', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'AGENCY AGREEMENT (CARGO BOOKING) This Agreement is made as of 1st of August, 2024 between Namsung Shipping Co., Ltd. (Address: 17 th Floor, Jangkyo Bldg., 1, Jangkyo-dong Chung-ku, Seoul 100-760, Korea/hereinafter referred to as "Principals") and SINOTRANS CENTRAL CHINA CO.,LTD.CONTAINER SHIPPING BRANCH (Address:11-12 Floor, Sinotrans Mansion, No.5 Henan Road, Qingdao, China /hereinafter referred to as "Agents"). Whereas, Principals are engaged in the business of owning, operating and managing vessels in international commerce and NOW, THEREFORE, in consideration of the reciprocal undertaking and the promises of the parties herein expressed, the parties agree as follows: ARTICLE 1.<APPOINTMENT> Principals appoint Agents as their booking agent in Qingdao, China to perform all of the customary Agency services as hereinafter further described, serving "Principals" liner service from Qingdao, China to the other ports, Agents accept such appointment and agree to use their best efforts to perform the cargo and equipment control agency services provided for by this Agreement in conformance with the lawful policies and practices and instructions of Principal. ARTICLE 2<SCOPE OF AGENCY SERVICES> Agents shall provide necessary agency service for booking cargoes to be loaded from Qingdao, cargo handlings and for all Principal owned or leased containers, and other equipment (hereinafter referred to as "Equipments"). 1. Maintain favorable customer relations with the Principals clients or prospective clients; 2. Upon request from Principals solicit cargo both outbound and inbound from and to ports and places served by Principals, in the area covered by this Agreement as set forth in ARTICLE 1, from shippers, consignees, trade associations and others engaged in transportation activities in the foreign and domestic commerce of the shipping business; 3. Quote rates in accordance with Principals then effective tariffs, book cargo subject to space allotments, arrange for the receipt and delivery of cargo and issue and sign bills of lading by its authorized person whose specimen signature registered to Principals and other shipping documents for and on behalf of Principals pursuant to instructions and guidelines which may be given from time to time by Principals; 4. Adopt collection procedures and collect freights and other moneys due to Principals pursuant to the provisions of this Agreement all applicable conference agreements, FMC rules and/or'}], 'chunk_id': 2637}, {'file_name': 'BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)', 'title': 'BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)_page8', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'ADDENDUM NO.1 TO AGENCY AGREEMENT DATED With reference to article 11 of the above agency agreement between Namsung Shipping Co., Ltd. (hereinafter the "Company") and BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRANCH (hereinafter the "Agent") dated 1st of October, 2024, it is hereby agreed that the Company shall compensate the Agent on the following basis: Cargo Commission: Only for the cargoes exported from Qingdao to the other ports served by the Company a) 3% of prepaid basic ocean freight revenue b) 1.5% of collected basic ocean freight revenue • As the Booking Agent, 30% of the profit per unit shall be shared with NB LOGISTICS. • The same terms outlined above (30% profit share with NB LOGISTICS) shall apply to BESCON SHANGHAI, as they do with BESCON QINGDAO. The Addendum No.1 will be effective starting from the date indicated on the top paragraph of Addendum No.1 of the Agency Agreement. The "Principals" Namsung Shipping By Title: The "Agents" BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRA By Title: The "Agents" NB Logistics Co., Ltd For and on behalf of NB Logistics Limited m R W W W R A R By Title: futhorized Signature(s) r o st ff'}], 'chunk_id': 2726}, {'file_name': 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G', 'title': 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page4', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': "services or its vessels as Agents and Principals may agree from time to time. 14. Furnish Principals with information relative to cargo movement statistics and prevailing market trend and etc. in accordance with principal's request. 15. Arrange the delivery of cargo to consignees in accordance with original B/L issued by on behalf of Principals. ARTICLE 3.<ACCOUNTING, COLLECTIONS, DISBURSEMENTS AND REMITTANCES> 1. Pursuant to instructions from Principals, Agents maintain separate accounts in the name of Principals or Agents for the purpose of transacting the receipt, payment, deposit and remittance of all moneys handled for the account of or on behalf of Principals. All freight revenues and other receipts or moneys earned by or owing to Principals, Agents or other person shall let consignee or shipper's or debtors also pay any, and all freight direct to the Principals bank account. Agents should aim to cause consignees or shippers or debtors to issue checks made payable to the Principals. In no event shall any such funds be deposited in any account of Agents nor shall funds belonging to others be commingled in Principals accounts. 2. Principals shall provide Agents with Agents commission charges after computation of Agents commission based on the manifest to be forwarded by Agents. Agents shall remit total freight earning both prepaid and collect in the area to Principals designated bank accounts on each voyage basis within one month after the departure date of Principals, Agents Commission and any other charges in connection with cargo freight could be deducted from the freight then remitted the balance to the Principals on each voyage basis. Agents shall maintain and report the statement of Principals' freight earning and expenditure on each voyage basis. 3. Principals shall remit the disbursement such as terminal, CFS, haulage etc within the credit period or payment allowed by the service contractors in case there is no plus balance. In extraordinary cases acceptable to Principals, Principals shall remit the disbursement confirmed by Principals' representative promptly. 4. All monetary obligations of Principals which are handled by Agents pursuant to the provisions of this Agency Agreement shall be paid from such disbursements and transmittals made strictly in accordance with instructions and practices as may be established by Principals. 5. Agents will exercise their best efforts and due diligence to collect all freight and other charges due and payable to Principals at the place of payment whether on inbound or outbound cargo and including all detention, demurrage, per diem, terminal, depot and other charges assessed against cargo, containers or chassis or other equipment involved in principal services."}], 'chunk_id': 2698}, {'file_name': 'TZH 中集世联达 (2024.02)', 'title': 'TZH 中集世联达 (2024.02)_page1', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'TJCD20240126 AGENCY AGREEMENT It is this day mutually agreed on 1st of Aug, 2024 between NAMSUNG SHIPPING CO.,LTD..(addressed in 17/f., Auggkyo Bldg., 1, Auggkyo-dong, Chung-ku, Seoul, Korea herein after referred to as the “PRINCIPALS”) And CIMC Wetrans International Shipping(Tianjin) Co.,Ltd.(addressed in No. 158 Jingmen Blvd, Free Trade Zoon Tianjin Port, China herein after referred as the “AGENTS”) And CIMC Wetrans Logistics Management Co Ltd. (Address : Floor 9, Block B1, Modem Service District , No .62 Second BLVD , Economic & Technical Development Zone , Tianjin China / hereinafter referred to as “ Settlement Company”). I . Principle: 1. The PRINCIPALS agree to entrust the AGENTS to act as Husbanding AGENTS for their liners calling at Xingang port. 2. The AGENTS accept the appointment and will endeavor to protect and promote the PRINCIPALS interests. The AGENTS will also effectively execute this agreement. II . The AGENTS’ Service and Responsibilities: A) Husbanding 1. Notify local port officials concerning vessels’ arrival and secure berths for all vessels owned/operated/chartered/managed by the PRINCIPALS. 2. Arrange entry and clearance of the vessels complying with all applicable port regulations. 3. Arrange payment of port charges and any dues payable in respect of the vessels. 4. Arrange for the supply of fuel, water provisions and ship’s stores. 5. Arrange for ship’s repairs required.'}], 'chunk_id': 2842}] -------
(InferenceActor pid=591) ---------------------------------------
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 리트리버
(InferenceActor pid=591) [SOOWAN] TA is No, and make a retrieval is successed
(InferenceActor pid=591) [STREAM] Starting partial generation for request_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [STREAM] _stream_partial_answer => request_id=5d92db76-0666-4580-8089-b9798a234ea3, chart=None
(InferenceActor pid=591) [DEBUG] Prepared reference data: {"type": "reference", "status_code": 200, "result": "OK", "detail": "Reference data", "evt_time": "2025-03-20T08:37:09.455449", "data_list": [{"rsp_type": "R", "rsp_tit": "남성 내부 데이터", "rsp_data": [{"rsp_tit": "1번째 검색데이터: [국내영업본부] 수입영업팀장> 월누적 영업실적 및 주간 주요 특이사항 (출처:남성해운_팀별 주간회의_W26_240625.pptx)", "rsp_data": [{"rsp_type": "TB", "rsp_tit": "월 누적 영업 실적 및 운임율, 매출 달성도", "rsp_data": {"head": "월누적\u000b영업\u000b실적||실적(TEU)||||||||운임율(RPT/$), 1 Count||||||||운임율(RPT/$), 2 Count||||||||운임매출(천$)||||||", "body": "||사계\u000b목표||수정\u000b목표||누적\u000b실적||달성율(%)||사계\u000b목표||수정\u000b목표||누적\u000b실적||달성율(%)||사계\u000b목표||수정\u000b목표||누적\u000b실적||달성율(%)||사계\u000b목표||수정\u000b목표||누적\u000b실적||달성율(%)^||14,940||15,150||12,888||85%||401||403||399||99%||392||394||368||94%||5,994||6,105||5,145||84%"}}, {"rsp_type": "TT", "rsp_tit": "", "rsp_data": "실적 중국 동남아 운임 동향 주요 이슈 및 영업 방향\n[북중국]\n청도 신규 문의 증가\n더불어 부산TS인천착 증가세\n연운항 운임 회복 시도중\n천진 마켓흐름 약세 선사간 경쟁심화.\n시장 선복 감소 가능성은 존재\n[동중국]\n상해 장비안정\n닝보 장비부족 -> 장비 선별 제공．\n인천향 2주 연속 100%\n난징 장가항 약세진행\n20피트 집화 운임 조정.\n충칭발 한국타이어 운임 상향 입찰예정\n[남중국]\n3/4주차 및 7월 부킹 증가세 진행\n 마켓 장비 공급 부족과 연계\n금주 장비 부족예정으로 집중적인 공급 주력\n(부킹 대비 550F 부족)\n6월 목표대비 실적 84%, 매출 83%\nRPT 398$ (전월 $388 대비 $10▲ )\n[하이퐁]\n개선중\n7월 운임 통지, 마켓 수긍 분위기\n저가화종 20”소량 선적(코일)\n[호치민]\n인천 양호, 부산/광양 약세(KVT & VTX).\n팰릿운임 화주반발 불구, 인상 진행.\n이탈예상시 빠른 장비 활용 추진(EP)\n[태국]\n운임율 개선중\n$256 -> $270 -> $287 -> $308 - >$329 (월 기준)\n[싱/말]\n말레이 7월 계획 운임 수용 어려운 분위기.\n고객사별 조정협의중\n[인니 ]\n증가세\n전 노선 120% 비딩화주 비중 높아 운임회복율 낮으나 7월부 개선 전망\n7월 운임 통지에 대한 구간별 고객사 분위기\n[수긍] 남중국/베트남/태국/청도\n-> 부킹 추이 확인 필요\n[관망] 닝보/상해/인도네시아\n[반발] 말레이시아/천진\n중국 동남아 운임회복 추진(7월 10일자)"}, {"rsp_type": "TB", "rsp_tit": "동남아시아 항로 운임 인상, 6월 대비 최대 200달러 상승", "rsp_data": {"head": "POL||POD||인상 폭(6월대비)", "body": "베트남||인천/평택||$200^||부산/울산/광양||$150^태국||인천/평택||$200^||부산/울산/광양||$150^인도네시아||인천||$150^||부산/울산/광양||$100^말레이시아||인천||$150^||부산/울산/광양||$100^심천||인천/평택||$200^||부산/광양||$100^샤먼||인천/평택||$100^||부산/광양||$100^남중국||인천/평택||$200^||부산/광양||$200^청도||한국||$100^연운항||한국||$100^상해/닝보||부산/광양/울산||$50"}}, {"rsp_type": "TT", "rsp_tit": "", "rsp_data": "단위:TEU"}], "chunk_id": 1425}, {"rsp_tit": "2번째 검색데이터: SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page1 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "AGENCY AGREEMENT (CARGO BOOKING) This Agreement is made as of 1st of August, 2024 between Namsung Shipping Co., Ltd. (Address: 17 th Floor, Jangkyo Bldg., 1, Jangkyo-dong Chung-ku, Seoul 100-760, Korea/hereinafter referred to as \"Principals\") and SINOTRANS CENTRAL CHINA CO.,LTD.CONTAINER SHIPPING BRANCH (Address:11-12 Floor, Sinotrans Mansion, No.5 Henan Road, Qingdao, China /hereinafter referred to as \"Agents\"). Whereas, Principals are engaged in the business of owning, operating and managing vessels in international commerce and NOW, THEREFORE, in consideration of the reciprocal undertaking and the promises of the parties herein expressed, the parties agree as follows: ARTICLE 1.<APPOINTMENT> Principals appoint Agents as their booking agent in Qingdao, China to perform all of the customary Agency services as hereinafter further described, serving \"Principals\" liner service from Qingdao, China to the other ports, Agents accept such appointment and agree to use their best efforts to perform the cargo and equipment control agency services provided for by this Agreement in conformance with the lawful policies and practices and instructions of Principal. ARTICLE 2<SCOPE OF AGENCY SERVICES> Agents shall provide necessary agency service for booking cargoes to be loaded from Qingdao, cargo handlings and for all Principal owned or leased containers, and other equipment (hereinafter referred to as \"Equipments\"). 1. Maintain favorable customer relations with the Principals clients or prospective clients; 2. Upon request from Principals solicit cargo both outbound and inbound from and to ports and places served by Principals, in the area covered by this Agreement as set forth in ARTICLE 1, from shippers, consignees, trade associations and others engaged in transportation activities in the foreign and domestic commerce of the shipping business; 3. Quote rates in accordance with Principals then effective tariffs, book cargo subject to space allotments, arrange for the receipt and delivery of cargo and issue and sign bills of lading by its authorized person whose specimen signature registered to Principals and other shipping documents for and on behalf of Principals pursuant to instructions and guidelines which may be given from time to time by Principals; 4. Adopt collection procedures and collect freights and other moneys due to Principals pursuant to the provisions of this Agreement all applicable conference agreements, FMC rules and/or"}], "chunk_id": 2637}, {"rsp_tit": "3번째 검색데이터: BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)_page8 (출처:BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ))", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "ADDENDUM NO.1 TO AGENCY AGREEMENT DATED With reference to article 11 of the above agency agreement between Namsung Shipping Co., Ltd. (hereinafter the \"Company\") and BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRANCH (hereinafter the \"Agent\") dated 1st of October, 2024, it is hereby agreed that the Company shall compensate the Agent on the following basis: Cargo Commission: Only for the cargoes exported from Qingdao to the other ports served by the Company a) 3% of prepaid basic ocean freight revenue b) 1.5% of collected basic ocean freight revenue • As the Booking Agent, 30% of the profit per unit shall be shared with NB LOGISTICS. • The same terms outlined above (30% profit share with NB LOGISTICS) shall apply to BESCON SHANGHAI, as they do with BESCON QINGDAO. The Addendum No.1 will be effective starting from the date indicated on the top paragraph of Addendum No.1 of the Agency Agreement. The \"Principals\" Namsung Shipping By Title: The \"Agents\" BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRA By Title: The \"Agents\" NB Logistics Co., Ltd For and on behalf of NB Logistics Limited m R W W W R A R By Title: futhorized Signature(s) r o st ff"}], "chunk_id": 2726}, {"rsp_tit": "4번째 검색데이터: SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page4 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "services or its vessels as Agents and Principals may agree from time to time. 14. Furnish Principals with information relative to cargo movement statistics and prevailing market trend and etc. in accordance with principal's request. 15. Arrange the delivery of cargo to consignees in accordance with original B/L issued by on behalf of Principals. ARTICLE 3.<ACCOUNTING, COLLECTIONS, DISBURSEMENTS AND REMITTANCES> 1. Pursuant to instructions from Principals, Agents maintain separate accounts in the name of Principals or Agents for the purpose of transacting the receipt, payment, deposit and remittance of all moneys handled for the account of or on behalf of Principals. All freight revenues and other receipts or moneys earned by or owing to Principals, Agents or other person shall let consignee or shipper's or debtors also pay any, and all freight direct to the Principals bank account. Agents should aim to cause consignees or shippers or debtors to issue checks made payable to the Principals. In no event shall any such funds be deposited in any account of Agents nor shall funds belonging to others be commingled in Principals accounts. 2. Principals shall provide Agents with Agents commission charges after computation of Agents commission based on the manifest to be forwarded by Agents. Agents shall remit total freight earning both prepaid and collect in the area to Principals designated bank accounts on each voyage basis within one month after the departure date of Principals, Agents Commission and any other charges in connection with cargo freight could be deducted from the freight then remitted the balance to the Principals on each voyage basis. Agents shall maintain and report the statement of Principals' freight earning and expenditure on each voyage basis. 3. Principals shall remit the disbursement such as terminal, CFS, haulage etc within the credit period or payment allowed by the service contractors in case there is no plus balance. In extraordinary cases acceptable to Principals, Principals shall remit the disbursement confirmed by Principals' representative promptly. 4. All monetary obligations of Principals which are handled by Agents pursuant to the provisions of this Agency Agreement shall be paid from such disbursements and transmittals made strictly in accordance with instructions and practices as may be established by Principals. 5. Agents will exercise their best efforts and due diligence to collect all freight and other charges due and payable to Principals at the place of payment whether on inbound or outbound cargo and including all detention, demurrage, per diem, terminal, depot and other charges assessed against cargo, containers or chassis or other equipment involved in principal services."}], "chunk_id": 2698}, {"rsp_tit": "5번째 검색데이터: TZH 中集世联达 (2024.02)_page1 (출처:TZH 中集世联达 (2024.02))", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "TJCD20240126 AGENCY AGREEMENT It is this day mutually agreed on 1st of Aug, 2024 between NAMSUNG SHIPPING CO.,LTD..(addressed in 17/f., Auggkyo Bldg., 1, Auggkyo-dong, Chung-ku, Seoul, Korea herein after referred to as the “PRINCIPALS”) And CIMC Wetrans International Shipping(Tianjin) Co.,Ltd.(addressed in No. 158 Jingmen Blvd, Free Trade Zoon Tianjin Port, China herein after referred as the “AGENTS”) And CIMC Wetrans Logistics Management Co Ltd. (Address : Floor 9, Block B1, Modem Service District , No .62 Second BLVD , Economic & Technical Development Zone , Tianjin China / hereinafter referred to as “ Settlement Company”). I . Principle: 1. The PRINCIPALS agree to entrust the AGENTS to act as Husbanding AGENTS for their liners calling at Xingang port. 2. The AGENTS accept the appointment and will endeavor to protect and promote the PRINCIPALS interests. The AGENTS will also effectively execute this agreement. II . The AGENTS’ Service and Responsibilities: A) Husbanding 1. Notify local port officials concerning vessels’ arrival and secure berths for all vessels owned/operated/chartered/managed by the PRINCIPALS. 2. Arrange entry and clearance of the vessels complying with all applicable port regulations. 3. Arrange payment of port charges and any dues payable in respect of the vessels. 4. Arrange for the supply of fuel, water provisions and ship’s stores. 5. Arrange for ship’s repairs required."}], "chunk_id": 2842}]}]}
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>남성해운의 새로운 전략에 대해 자세히 알려줘<query>
(InferenceActor pid=591) <keyword/>남성해운, 새로운 전략<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 남성해운의 새로운 전략에 대해 자세히 알려줘, 키워드 : 남성해운, 새로운 전략, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) [SOOWAN]: execute_rag : 진입
(InferenceActor pid=591) [SOOWAN]: execute_rag : 테이블 필요없음
(InferenceActor pid=591) [시간 범위] 전체 기간 사용
(InferenceActor pid=591) [RETRIEVE] 검색에 사용되는 문서 수: 3511
(InferenceActor pid=591) [SOOWAN] retrieve : 진입
(InferenceActor pid=591) [SOOWAN] cal_sim_score : 진입 / query :  남성해운, 새로운 전략
(InferenceActor pid=591) [SOOWAN] embed: 진입
(InferenceActor pid=591) [SOOWAN] embed: 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V 생산 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V.shape == 1
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:591: BM25 scores: min=1.8438, max=23.8247, mean=10.8971
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting cal_bm25_score() -- Elapsed: 0.37s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:448: BM25 score shape: (540,)
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:457: Top 5 document indices: [132 340 355 350 377]
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:458: Top 5 document scores: [0.6162068491273904, 0.606677258520701, 0.6064468567663217, 0.6045605187707925, 0.5939651375108743]
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:459: Top document titles: ['[국내영업본부] 수입영업팀장> 월누적 영업실적 및 주간 주요 특이사항', 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page1', 'BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)_page8', 'SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page4', 'TZH 中集世联达 (2024.02)_page1']
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting retrieve() -- Elapsed: 0.40s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering execute_rag()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting execute_rag() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering expand_time_range_if_needed()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting expand_time_range_if_needed() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering retrieve()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:440: Retrieval for query: '남성해운, 새로운 전략'
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:441: Available documents: 3511
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering cal_sim_score()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering embed()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting embed() -- Elapsed: 0.01s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:15: Exiting cal_sim_score() -- Elapsed: 0.34s
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:445: Similarity score shape: (3511, 1, 1)
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO tracking.py:11: Entering cal_bm25_score()
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:557: Starting BM25 calculation for query: 남성해운, 새로운 전략
(InferenceActor pid=591) [2025-03-20 08:37:09] INFO RAG.py:558: Document count: 3511
[2025-03-20 08:37:11] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:37:11] "POST /query_stream HTTP/1.1" 200 -
(InferenceActor pid=591) -------------자료 검색 성공--------------
(InferenceActor pid=591) ------- [{'file_name': '남성해운_팀별 주간회의_W9_240227.pptx', 'title': '[신성장전략실] 신성장실현팀 > 비대면영업채널확대', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '디지털포워더 & 플랫폼\n(비대면영업채널확대)'}, {'rsp_type': 'TB', 'rsp_tit': '파트너사 협력으로 해상 운송 효율성 증대 및 Bkg 유입 확대 추진 중', 'rsp_data': {'head': '파트너사||추진 사항||’24년 진행 현황', 'body': '[신규] 포스코플로우||연근해 지역 우선순위 전략적 파트너 선사로 협업 각 파트너사로부터 월간 약 30 Teu ↑ Bkg 유입 목표 (특히, 북중국향 및 싱/말 등 우리사 필요지역) 스케쥴 및 해상운임 제공 온라인마케팅 채널 활용 (NS 브랜드 노출/홍보)||[2/7, 수] 간담회 참석 (포워더 및 선사) [2/23, 금] 컨테이너섹션 과 ‘플로우멤버스’ 협업안 논의 개시 - 포스코플로우 멤버사用 S/C 제공 및 선복 운영안, 필요 구간 등 - 예일GLS ‘코일포터’ (기존 ‘목재’ 쇼링 대체재) 활용 검토키로 → 3/8일 후속 미팅^[진행 중] 판토스NOW||||[1/8, 월] 판토스NOW 플랫폼 정식 런칭 → 오픈 이후 오류/이슈사항 개선 중 으로 확인 [2월 현재] 서비스 프로모션/마케팅 진행 中 → 우리사로 유입 기대 - 1분기 적용 S/C 및 선복운영안 유효 하나 실 Bkg 유입은 가시적으로 ‘없음’ - 2분기 예상 Bkg 수준 재확인 및 운임, 선복운영안 전달 예정^[진행 중] 쉽다||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 (KCC 등) - 중국발 위주 월간 약 20~30 Teu ‘수입’ Bkg 유입 중 → 우리사 필요지역인 싱/말/인니발 유치 확대 Try (수입영업팀 공조)^[진행 중] 서프컴퍼니||||[2/20, 화] 북중국향 포워더 대상 이벤트성 프로모션 수행 검토 - 국제물류주선업 라이센스 미취득 → ‘중개자‘ 역할로써 마케팅 수행 - CY~Door 포함 남성해운 서비스를 플랫폼/채널 통한 홍보, 영업지원키로^[진행 중] 밸류링크유||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 - 평택발 하이퐁착 월간 약 10~30Teu ‘냉동화물’ 수출 지속 (‘23년 $71,000불)^[유지] 지비티에스||||[정기] 스케쥴 및 월간 해상운임 안내 Bkg 유입 미미 → ’24년 1월 부 자체 포워더팀 신설 및 영업 진행 중 ※ 모기업이 관세사(베스트관세사) 로 20년차 업력 → 19년 부 플랫폼사업 진출'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '‘21년 부\n‘21년 부\n‘22년 부\n‘22년 부\n‘24년 부\n‘23년 부\n‘22년\n‘23년\n‘24년\n‘21년 마켓 전환 → 대면영업 중요도↑\n우리사 역할 측면은 계속 지원하며 시도가능영역은 계속 Try (단, 팀의 Workforce/효율성 등 감안)\n디지털전환(DT) 요구 및 마켓 수요 증가 → 파트너사 확대/협업\n운영프로세스 구축(선복/SC) 및 API 기반 스케쥴 연동, Bkg 유입'}], 'chunk_id': 2057}, {'file_name': '[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx', 'title': '우수 선화주기업 인증제도 현장평가 > 7. 차별화 서비스 제공현황', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '남성해운의 차별화 서비스는 이렇습니다!\n차별화 서비스 요약\n해운물류서비스\n디지털 연계\n- 물류 패러다임의 변화에 대응하여 다양한 디지털 기술의 융합/연계로 연결성을 강화하고,\n디지털기반 확장된 물류 생태계 구성원을 대상으로 기존의 logistic Provider와 차별화 되는 경험을 제공 중'}, {'rsp_type': 'TB', 'rsp_tit': '해운물류 디지털화, 운임 경쟁력 강화, 아세안 내륙 운송 확대', 'rsp_data': {'head': '구분||차별화 서비스||세부 전략', 'body': '1||해운물류서비스 디지털 연계||DT로드맵 추진과제 수행^2||경쟁력 있는 운임 제공||거점/운송인프라 연결한 패키지딜^3||복합운송연계 서비스 계획||아세안지역 (캄보디아 등) 내륙개발^4||해외거점 터미널 확보||해외지역 운송, 창고 등 J/V 추진^5||피더 네트워크 확보||일본, 중국, 인니 등 소규모 항구개발^6||친환경, 고효율 선박 확충||해양진흥공사 등 정책지원사업 참여'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '상세 내용\nDT 추진과제 및 로드맵을 통해서\nDT 가치체계로 인한 변화의 모습은 이와 같으며\n지속적인 투자, 조직대응수준 강화로\n차별적 서비스 제공\n전면 재편된 e-Service 및 플랫폼 파트너사,\n디지털 포워더사와 협업 진행 중\n확장된 물류 생태계 내\n디지털 가치 전파와 저변 확대를 위한 선도적 역할\n디지털 혁신 비전 선포 (Digitalized Logistics to Empower your Experience)\n로드맵을 통한 Enabler 도출 및 시행 중'}], 'chunk_id': 879}, {'file_name': 'Huangpu terminal 2023', 'title': 'Huangpu terminal 2023_page15', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '第 1 页 共 14 页 GCT-BDD-2023-A-5 (外贸) 外贸贸轮港口作业协议 [ GCT-X-23-90070 ] 甲方：南星海运林式会社 乙方：广州港股份有限公司 八方：广州集装箱码头有限公司 甲、乙、八三方依照中华人民共和国有关法律、法规，在平等互利的 基础上，经友好协商，就甲方在广州港新港港区经宣集装箱贸轮运输 的有关事项达成如下协议： 一、甲方在广州港集国码头作业的集装箱贸轮航线必须取得中华 人民共和国交通部的核准许可，其所属集装箱贸轮依协议约定著沿广 州港码头开展正常的普运活动。乙方经与甲方协商安排甲方集装箱贸 轮航线在八方著沿作业，八方受甲方委托进行集装箱船船的停著、装 细、维存以及其他作业。 甲方指定广州港中联国际船务代理有限公司为其船船代理，并书 面告知乙方、八方其他代理权限。在此权限内，乙方、八方在今后的操作中，可无需事先知照甲方，而遭照来自其指定代理的指引、要求、 通知等进行操作。甲方有权对代理及代理权限进行变更，但需提前一个月书面通知乙方、八方，并得到乙方、八方的确认。否则因此产生 的损失及费用，乙方、八方不予负责。甲方及其代理需提供运营许可证明的资料复印作，包括企业法人普业执照、组织机构代码证、税务 登记证等，一般纳税人资格证（加盖公章）以及船船代理资质证明等 。 乙方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、八方的责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的责，当与甲方、当方、当方的质责，当与甲方、当方的质责，当与甲方、当方、当方的质责，当与甲方、当方的责，当与甲方、当方的责，当与甲方、当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的'}], 'chunk_id': 3005}, {'file_name': '20230731155302_GNE 계약서', 'title': '20230731155302_GNE 계약서_page2', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': "CONTENTS Article Heading Page 1. APPOINTMENT .....................................................................................................................3 2. DUE CARE.............................................................................................................................3 3. AGENT'S ROLES AND FUNCTIONS....................................................................................3 (a). HUSBANDING..........................................................................................................3 (b). MARKETING, CARGO BOOKING AND OPERATION...........................................4 (c). EQUIPMENT CONTROL .........................................................................................5 (d). RISKSAND CLAIMS MANAGEMENT.....................................................................6 (e). DOCUMENTA TION AND CUSTOMER SERVICE...................................................6 (f). INFORMATION........................................................................................................6 (g). CLAIMS...................................................................................................................7 (h). STAFF AND RESOURCES. .......................................................................................7 4. BILL OF LADING ..................................................................................................7 5. RELEASING OF CARGOES ..................................................................................7 6. ACCOUNTING.......................................................................................................8 (a). COLLECTION OF FREIGHT..................................................................................8 (b). DISBURSEMENTS....................................................................................................8 (c). REMITTANCE OF FUNDS.........................................................................................9 (d). ACCOUNTING INSTRUCTIONS...............................................................................9 (e). FOREIGN EXCHANGE REGULA TION.....................................................................9 7. MONIES AND FUNDS RECEIVED BY THE AGENT...........................................................9 8. THIRD PARTY SERVICE PROVIDERS..................................................................................9 9. OFFICES AND SUB-AGENTS .............................................................................................10 10. REMUNERATION................................................................................................................10 11. DISBURESMENT..................................................................................................................10 12. COSTS AND EXPENSES........................................................................................................10 13. ASSIGNMENT.........................................................................................................................11 14. CHANGE OF THE AGENT'S STRUCTURE ........................................................................11 15. DEFAULT ...............................................................................................................................11 16. THE AGENT'S DUTIES AFTER TERMINATION.................................................................12 17. INDEMNITY...........................................................................................................................12 18. FORCE MAJEURE ................................................................................................................12 19. CONFIDENTIALITY..............................................................................................................12 20. COUNTERPARTS ..................................................................................................................13 21. GOVERNING LAW AND ARBITRATION..........................................................................13 22. EFFECTIVE DATE................................................................................................................13 Appendix I: COMPENSATIONS........................................................................................................................................14 2"}], 'chunk_id': 2434}, {'file_name': '[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx', 'title': '우수 선화주기업 인증제도 현장평가 > 1. 회사 소개', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '주요 연혁\n● 남성해운은 1953년 8월 대한민국 최초 민간 외항선사로, 약 70년간 해운업을 영위하였으며,\n 現, 18척의 국적 자사선과 용선 3척 총 29,739 TEU의 선복량을 보유하였으며,\n 한중일 외 베트남, 싱가포르, 인도네시아 등 총 64 개 기항지에 서비스를 제공\n대한민국 최초 한-일 부정기항로 개설로 외국항행 개시\n한-일 컨테이너 정기항로 취항/ 피더 컨테이너 서비스 개시\n남성해운㈜ 설립\n한-중 항로(부산 – 대련/청도/상해) 개설\n한-동남아 항로(홍콩/셔코우 직기항) 개설\n한-베트남 항로(인천 – 홍콩 - 하이퐁 – 셔코우) 개설\n홍콩 현지 법인 설립\n홍콩-베트남(호치민)-태국(방콕/람차방) 삼국간 항로 개설\n전사 Process Innovation (프로세스, IT 및 조직 혁신)\n중국 멀티모달(Sea+Rail) 본격 개시\n베트남 현지 법인 설립\n우수선화주인증 1등급 획득, 호치민 Depot 및 IGDC 물류거점 확보\n우수 선화주기업 상생협력 우수사례 최우수 수상\n태국 방콕 Depot/CFS 물류거점 확보\n인도네시아(자카르타) 서비스 개시\n국내 자영운송사 및 싱가포르/ 말레이시아 서비스 개시\n자사선 선대 현황'}, {'rsp_type': 'TB', 'rsp_tit': '컨테이너선 정보: 선박명, 용량, 인도일, 항로, 서비스명', 'rsp_data': {'head': '||선명||TEU||인도일||항로||서비스명', 'body': '1||STAR CLIPPER||962||2010.03||한중일||PD2^2||STAR SKIPPER||962||2010.06||한중일||BKH^3||STAR PIONEER||953||2010.08||한중일||PD2^4||STAR EXPRESS||953||2010.10||한중일||NTP^5||STARSHIP LEO||1,891||2013.02||동남아||KHP^6||STARSHIP URSA||1,891||2013.02||동남아||KVT^7||STARSHIP PEGASUS||1,891||2013.03||동남아||VTX^8||STAR CHALLENGER||1,003||2016.02||한중일||BJ1^9||STAR VOYAGER||1,003||2016.04||한중일||NSP^10||STARSHIP TAURUS||1,614||2017.07||동남아||NTX^11||STARSHIP AQUILA||1,614||2017.10||동남아||NKT^12||STAR EXPLORER||1,011||2020.06||동남아||BIH^13||STAR FRONTIER||1,011||2020.07||동남아||IHS^14||STAR CHASER||963||2021.12||한일||NTP^15||STAR RANGER||963||2022.02||한중일||PD1^16||STARSHIP DRACO||1,607||2022.11||동남아||KMV^17||STARSHIP JUPITER||2,548||2023.06||동남아||ANX^18||STARSHIP NEPTUNE||2,548||2023.10||동남아||KCI'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '```\n23년 11월 2일 기준\n```'}], 'chunk_id': 866}] -------
(InferenceActor pid=591) ---------------------------------------
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 리트리버
(InferenceActor pid=591) [SOOWAN] TA is No, and make a retrieval is successed
(InferenceActor pid=591) [STREAM] Starting partial generation for request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [STREAM] _stream_partial_answer => request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8, chart=None
(InferenceActor pid=591) [DEBUG] Prepared reference data: {"type": "reference", "status_code": 200, "result": "OK", "detail": "Reference data", "evt_time": "2025-03-20T08:37:11.764743", "data_list": [{"rsp_type": "R", "rsp_tit": "남성 내부 데이터", "rsp_data": [{"rsp_tit": "1번째 검색데이터: [신성장전략실] 신성장실현팀 > 비대면영업채널확대 (출처:남성해운_팀별 주간회의_W9_240227.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "디지털포워더 & 플랫폼\n(비대면영업채널확대)"}, {"rsp_type": "TB", "rsp_tit": "파트너사 협력으로 해상 운송 효율성 증대 및 Bkg 유입 확대 추진 중", "rsp_data": {"head": "파트너사||추진 사항||’24년 진행 현황", "body": "[신규] 포스코플로우||연근해 지역 우선순위 전략적 파트너 선사로 협업 각 파트너사로부터 월간 약 30 Teu ↑ Bkg 유입 목표 (특히, 북중국향 및 싱/말 등 우리사 필요지역) 스케쥴 및 해상운임 제공 온라인마케팅 채널 활용 (NS 브랜드 노출/홍보)||[2/7, 수] 간담회 참석 (포워더 및 선사) [2/23, 금] 컨테이너섹션 과 ‘플로우멤버스’ 협업안 논의 개시 - 포스코플로우 멤버사用 S/C 제공 및 선복 운영안, 필요 구간 등 - 예일GLS ‘코일포터’ (기존 ‘목재’ 쇼링 대체재) 활용 검토키로 → 3/8일 후속 미팅^[진행 중] 판토스NOW||||[1/8, 월] 판토스NOW 플랫폼 정식 런칭 → 오픈 이후 오류/이슈사항 개선 중 으로 확인 [2월 현재] 서비스 프로모션/마케팅 진행 中 → 우리사로 유입 기대 - 1분기 적용 S/C 및 선복운영안 유효 하나 실 Bkg 유입은 가시적으로 ‘없음’ - 2분기 예상 Bkg 수준 재확인 및 운임, 선복운영안 전달 예정^[진행 중] 쉽다||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 (KCC 등) - 중국발 위주 월간 약 20~30 Teu ‘수입’ Bkg 유입 중 → 우리사 필요지역인 싱/말/인니발 유치 확대 Try (수입영업팀 공조)^[진행 중] 서프컴퍼니||||[2/20, 화] 북중국향 포워더 대상 이벤트성 프로모션 수행 검토 - 국제물류주선업 라이센스 미취득 → ‘중개자‘ 역할로써 마케팅 수행 - CY~Door 포함 남성해운 서비스를 플랫폼/채널 통한 홍보, 영업지원키로^[진행 중] 밸류링크유||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 - 평택발 하이퐁착 월간 약 10~30Teu ‘냉동화물’ 수출 지속 (‘23년 $71,000불)^[유지] 지비티에스||||[정기] 스케쥴 및 월간 해상운임 안내 Bkg 유입 미미 → ’24년 1월 부 자체 포워더팀 신설 및 영업 진행 중 ※ 모기업이 관세사(베스트관세사) 로 20년차 업력 → 19년 부 플랫폼사업 진출"}}, {"rsp_type": "TT", "rsp_tit": "", "rsp_data": "‘21년 부\n‘21년 부\n‘22년 부\n‘22년 부\n‘24년 부\n‘23년 부\n‘22년\n‘23년\n‘24년\n‘21년 마켓 전환 → 대면영업 중요도↑\n우리사 역할 측면은 계속 지원하며 시도가능영역은 계속 Try (단, 팀의 Workforce/효율성 등 감안)\n디지털전환(DT) 요구 및 마켓 수요 증가 → 파트너사 확대/협업\n운영프로세스 구축(선복/SC) 및 API 기반 스케쥴 연동, Bkg 유입"}], "chunk_id": 2057}, {"rsp_tit": "2번째 검색데이터: 우수 선화주기업 인증제도 현장평가 > 7. 차별화 서비스 제공현황 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "남성해운의 차별화 서비스는 이렇습니다!\n차별화 서비스 요약\n해운물류서비스\n디지털 연계\n- 물류 패러다임의 변화에 대응하여 다양한 디지털 기술의 융합/연계로 연결성을 강화하고,\n디지털기반 확장된 물류 생태계 구성원을 대상으로 기존의 logistic Provider와 차별화 되는 경험을 제공 중"}, {"rsp_type": "TB", "rsp_tit": "해운물류 디지털화, 운임 경쟁력 강화, 아세안 내륙 운송 확대", "rsp_data": {"head": "구분||차별화 서비스||세부 전략", "body": "1||해운물류서비스 디지털 연계||DT로드맵 추진과제 수행^2||경쟁력 있는 운임 제공||거점/운송인프라 연결한 패키지딜^3||복합운송연계 서비스 계획||아세안지역 (캄보디아 등) 내륙개발^4||해외거점 터미널 확보||해외지역 운송, 창고 등 J/V 추진^5||피더 네트워크 확보||일본, 중국, 인니 등 소규모 항구개발^6||친환경, 고효율 선박 확충||해양진흥공사 등 정책지원사업 참여"}}, {"rsp_type": "TT", "rsp_tit": "", "rsp_data": "상세 내용\nDT 추진과제 및 로드맵을 통해서\nDT 가치체계로 인한 변화의 모습은 이와 같으며\n지속적인 투자, 조직대응수준 강화로\n차별적 서비스 제공\n전면 재편된 e-Service 및 플랫폼 파트너사,\n디지털 포워더사와 협업 진행 중\n확장된 물류 생태계 내\n디지털 가치 전파와 저변 확대를 위한 선도적 역할\n디지털 혁신 비전 선포 (Digitalized Logistics to Empower your Experience)\n로드맵을 통한 Enabler 도출 및 시행 중"}], "chunk_id": 879}, {"rsp_tit": "3번째 검색데이터: Huangpu terminal 2023_page15 (출처:Huangpu terminal 2023)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "第 1 页 共 14 页 GCT-BDD-2023-A-5 (外贸) 外贸贸轮港口作业协议 [ GCT-X-23-90070 ] 甲方：南星海运林式会社 乙方：广州港股份有限公司 八方：广州集装箱码头有限公司 甲、乙、八三方依照中华人民共和国有关法律、法规，在平等互利的 基础上，经友好协商，就甲方在广州港新港港区经宣集装箱贸轮运输 的有关事项达成如下协议： 一、甲方在广州港集国码头作业的集装箱贸轮航线必须取得中华 人民共和国交通部的核准许可，其所属集装箱贸轮依协议约定著沿广 州港码头开展正常的普运活动。乙方经与甲方协商安排甲方集装箱贸 轮航线在八方著沿作业，八方受甲方委托进行集装箱船船的停著、装 细、维存以及其他作业。 甲方指定广州港中联国际船务代理有限公司为其船船代理，并书 面告知乙方、八方其他代理权限。在此权限内，乙方、八方在今后的操作中，可无需事先知照甲方，而遭照来自其指定代理的指引、要求、 通知等进行操作。甲方有权对代理及代理权限进行变更，但需提前一个月书面通知乙方、八方，并得到乙方、八方的确认。否则因此产生 的损失及费用，乙方、八方不予负责。甲方及其代理需提供运营许可证明的资料复印作，包括企业法人普业执照、组织机构代码证、税务 登记证等，一般纳税人资格证（加盖公章）以及船船代理资质证明等 。 乙方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、八方的责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的责，当与甲方、当方、当方的质责，当与甲方、当方的质责，当与甲方、当方、当方的质责，当与甲方、当方的责，当与甲方、当方的责，当与甲方、当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的"}], "chunk_id": 3005}, {"rsp_tit": "4번째 검색데이터: 20230731155302_GNE 계약서_page2 (출처:20230731155302_GNE 계약서)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "CONTENTS Article Heading Page 1. APPOINTMENT .....................................................................................................................3 2. DUE CARE.............................................................................................................................3 3. AGENT'S ROLES AND FUNCTIONS....................................................................................3 (a). HUSBANDING..........................................................................................................3 (b). MARKETING, CARGO BOOKING AND OPERATION...........................................4 (c). EQUIPMENT CONTROL .........................................................................................5 (d). RISKSAND CLAIMS MANAGEMENT.....................................................................6 (e). DOCUMENTA TION AND CUSTOMER SERVICE...................................................6 (f). INFORMATION........................................................................................................6 (g). CLAIMS...................................................................................................................7 (h). STAFF AND RESOURCES. .......................................................................................7 4. BILL OF LADING ..................................................................................................7 5. RELEASING OF CARGOES ..................................................................................7 6. ACCOUNTING.......................................................................................................8 (a). COLLECTION OF FREIGHT..................................................................................8 (b). DISBURSEMENTS....................................................................................................8 (c). REMITTANCE OF FUNDS.........................................................................................9 (d). ACCOUNTING INSTRUCTIONS...............................................................................9 (e). FOREIGN EXCHANGE REGULA TION.....................................................................9 7. MONIES AND FUNDS RECEIVED BY THE AGENT...........................................................9 8. THIRD PARTY SERVICE PROVIDERS..................................................................................9 9. OFFICES AND SUB-AGENTS .............................................................................................10 10. REMUNERATION................................................................................................................10 11. DISBURESMENT..................................................................................................................10 12. COSTS AND EXPENSES........................................................................................................10 13. ASSIGNMENT.........................................................................................................................11 14. CHANGE OF THE AGENT'S STRUCTURE ........................................................................11 15. DEFAULT ...............................................................................................................................11 16. THE AGENT'S DUTIES AFTER TERMINATION.................................................................12 17. INDEMNITY...........................................................................................................................12 18. FORCE MAJEURE ................................................................................................................12 19. CONFIDENTIALITY..............................................................................................................12 20. COUNTERPARTS ..................................................................................................................13 21. GOVERNING LAW AND ARBITRATION..........................................................................13 22. EFFECTIVE DATE................................................................................................................13 Appendix I: COMPENSATIONS........................................................................................................................................14 2"}], "chunk_id": 2434}, {"rsp_tit": "5번째 검색데이터: 우수 선화주기업 인증제도 현장평가 > 1. 회사 소개 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "주요 연혁\n● 남성해운은 1953년 8월 대한민국 최초 민간 외항선사로, 약 70년간 해운업을 영위하였으며,\n 現, 18척의 국적 자사선과 용선 3척 총 29,739 TEU의 선복량을 보유하였으며,\n 한중일 외 베트남, 싱가포르, 인도네시아 등 총 64 개 기항지에 서비스를 제공\n대한민국 최초 한-일 부정기항로 개설로 외국항행 개시\n한-일 컨테이너 정기항로 취항/ 피더 컨테이너 서비스 개시\n남성해운㈜ 설립\n한-중 항로(부산 – 대련/청도/상해) 개설\n한-동남아 항로(홍콩/셔코우 직기항) 개설\n한-베트남 항로(인천 – 홍콩 - 하이퐁 – 셔코우) 개설\n홍콩 현지 법인 설립\n홍콩-베트남(호치민)-태국(방콕/람차방) 삼국간 항로 개설\n전사 Process Innovation (프로세스, IT 및 조직 혁신)\n중국 멀티모달(Sea+Rail) 본격 개시\n베트남 현지 법인 설립\n우수선화주인증 1등급 획득, 호치민 Depot 및 IGDC 물류거점 확보\n우수 선화주기업 상생협력 우수사례 최우수 수상\n태국 방콕 Depot/CFS 물류거점 확보\n인도네시아(자카르타) 서비스 개시\n국내 자영운송사 및 싱가포르/ 말레이시아 서비스 개시\n자사선 선대 현황"}, {"rsp_type": "TB", "rsp_tit": "컨테이너선 정보: 선박명, 용량, 인도일, 항로, 서비스명", "rsp_data": {"head": "||선명||TEU||인도일||항로||서비스명", "body": "1||STAR CLIPPER||962||2010.03||한중일||PD2^2||STAR SKIPPER||962||2010.06||한중일||BKH^3||STAR PIONEER||953||2010.08||한중일||PD2^4||STAR EXPRESS||953||2010.10||한중일||NTP^5||STARSHIP LEO||1,891||2013.02||동남아||KHP^6||STARSHIP URSA||1,891||2013.02||동남아||KVT^7||STARSHIP PEGASUS||1,891||2013.03||동남아||VTX^8||STAR CHALLENGER||1,003||2016.02||한중일||BJ1^9||STAR VOYAGER||1,003||2016.04||한중일||NSP^10||STARSHIP TAURUS||1,614||2017.07||동남아||NTX^11||STARSHIP AQUILA||1,614||2017.10||동남아||NKT^12||STAR EXPLORER||1,011||2020.06||동남아||BIH^13||STAR FRONTIER||1,011||2020.07||동남아||IHS^14||STAR CHASER||963||2021.12||한일||NTP^15||STAR RANGER||963||2022.02||한중일||PD1^16||STARSHIP DRACO||1,607||2022.11||동남아||KMV^17||STARSHIP JUPITER||2,548||2023.06||동남아||ANX^18||STARSHIP NEPTUNE||2,548||2023.10||동남아||KCI"}}, {"rsp_type": "TT", "rsp_tit": "", "rsp_data": "```\n23년 11월 2일 기준\n```"}], "chunk_id": 866}]}]}
(InferenceActor pid=591) [STREAM] Sent reference data for request_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [STREAM] final_query =
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 공 컨테이너 이송 전략에 대해 알려줘
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, RAG 검색 자료: 3464, 사용자 구체화 질문: 11, 총합: 3482
(InferenceActor pid=591) [STREAM] SSE: calling generate_answer_stream for request_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO RAG.py:591: BM25 scores: min=2.1850, max=21.6779, mean=10.5820
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting cal_bm25_score() -- Elapsed: 1.93s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO RAG.py:448: BM25 score shape: (3511,)
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO RAG.py:457: Top 5 document indices: [2056  878 3004 2433  865]
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO RAG.py:458: Top 5 document scores: [0.6138442701260235, 0.6006552225510265, 0.5967639035145428, 0.5910248702923443, 0.588505799190202]
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO RAG.py:459: Top document titles: ['[신성장전략실] 신성장실현팀 > 비대면영업채널확대', '우수 선화주기업 인증제도 현장평가 > 7. 차별화 서비스 제공현황', 'Huangpu terminal 2023_page15', '20230731155302_GNE 계약서_page2', '우수 선화주기업 인증제도 현장평가 > 1. 회사 소개']
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting retrieve() -- Elapsed: 2.31s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering generate_answer_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting generate_answer_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering collect_vllm_text_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting collect_vllm_text_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) 최종 LLM 추론용 prompt 생성 :
(InferenceActor pid=591) <bos><start_of_turn>user
(InferenceActor pid=591) 너는 남성해운의 도움을 주는 데이터 분석가야.
(InferenceActor pid=591)
(InferenceActor pid=591) 주어진 **내부 자료**를 바탕으로 **내 질문**에 **상세하고 논리정연한** 답변을 작성해줘.
(InferenceActor pid=591) **답변은 반드시 아래 규칙에 맞춰 Markdown 형식**으로 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 1. **문단/제목:** `#`, `##`, `###` 등의 헤더를 사용하고, 문단 사이에 **한 줄 이상의 공백**을 넣어줘.
(InferenceActor pid=591) 2. **강조**: 강조할 단어나 문구는 `**굵게**`(이중별표) 또는 `*기울임*`(단일별표)를 사용해줘.
(InferenceActor pid=591) 3. **목록**: 필요하다면 `-` 또는 `*` 기호를 사용해 **목록**을 만들어줘.
(InferenceActor pid=591) 4. **표**: SQL 표 결과가 답변에 포함될 경우, 반드시 표의 시작 부분에 "<<<TABLE>>>"와 끝 부분에 "<<<END_TABLE>>>"라는 구분자를 추가해서 출력해줘.
(InferenceActor pid=591) 5. **코드 블록**: 예시 코드나 특수한 데이터는 ``` ``` 언어명 ... ``` ``` 을 사용해 표시해줘.
(InferenceActor pid=591) 6. **출처**: 내부 자료를 참조했다면 **어디서 어떤 내용을 사용했는지**를 마지막에 간단히 표기해줘.
(InferenceActor pid=591) 7. **각주(footnotes)**: 답변에 각주가 필요한 경우, 본문 중에 `[^1]`, `[^2]`와 같은 형태로 표시하고, 마크다운 형식과 같게 답변 마지막에 해당 각주 내용을 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 만약 **주어진 자료**에 질문에 해당하는 내용이 **없다면**, `"내부 자료에 해당 자료 없음"`이라고만 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) **주의**:
(InferenceActor pid=591) - 너무 짧거나 단답형이 아닌, 충분히 **길고 자세한 보고서 형태**로 답변해줘.
(InferenceActor pid=591) - 가능하면 **논리적 근거**와 **예시**를 들어 설명해줘.
(InferenceActor pid=591) - **문단**을 명확히 구분하여 **읽기 편하게** 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 아래는 **내부 자료**와 **질문**이 주어질 것이니, 꼭 이 지침을 따라 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 내부 자료: 1번째 검색자료 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx) :
(InferenceActor pid=591) 컨테이너관리팀은 컨테이너 보유량 통제와 신규 서비스 지역 재고 관리를 중점 추진과제로 삼고 있다. 컨테이너 보유량 통제는 노후 임대 컨테이너 반납 및 재 연장 검토, 노후 VAN 교체를 위한 최소 14년 이상 경과 장비 매각 진행 검토, 신규 서비스 및 선복 증감 대비 적정 운영수량 통제/관리, 장비 운영 효율성 지속 관리/개선 노력, IMBALANCE 개선을 통한 지속 E/P 수량 제어 노력, 국내외 지역간 적시 E/P를 통한 장비 재배치 및 효율성 제고, 권역별 장기 미사용 적체 컨테이너 집중 관리 등을 통해 추진될 예정이다. 신규 서비스 지역 재고 관리에서는 인도네시아/말레이시아/마닐라 재고 집중 관리, IMBALANCE로 인한 IDLE CNTR 장비 최소화 및 적시 해소 노력, ICON+를 활용 및 주기적 현황 파악을 통한 재고관리 강화 등을 추진할 계획이다. 이러한 과제는 컨테이너관리팀, 영업추진본부, 운항관리팀, 해외법인 및 사무소의 협력을 통해 추진될 예정이다., , Score: 0.5054
(InferenceActor pid=591) 2번째 검색자료 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx) :
(InferenceActor pid=591) 컨테이너 운송 모드별로 풀컨테이너와 엠티컨테이너의 이동 상황을 보여주는 도표입니다. 풀컨테이너는 바지, 철도, 트럭 운송 모두 수출 및 수입 적재, 하역, 게이트인/아웃 상황을 BX, RX, OX, GX, LX, TX, BI, RI, OI, GI, LI, TI 로 구분하여 나타냅니다. 엠티컨테이너는 바지, 철도, 트럭 운송 모두 BE, RE, OE 로 표기됩니다., , Score: 0.4865
(InferenceActor pid=591) 3번째 검색자료 (출처:남성해운_팀별 주간회의_W45_231107.pptx) :
(InferenceActor pid=591) 컨테이너 관리팀은 멀티모달 비즈니스에 맞는 컨테이너 이동 상태(Mvmt Status) 코드 표준안 개선을 위해 노력하고 있습니다. 현재 Ocean 구간 이외의 운송 방식별 Mvmt Status가 모호하고, 각 운송 방식별 서비스 지역의 컨테이너 이동 현황을 정확하게 관리하기 어렵습니다. 이에 따라 컨테이너 관리팀은 운송 방식별 Mvmt Status에 맞는 코드 로직을 재정의하고, 신규 코드를 생성하여 컨테이너 이동 등록 및 관리를 개선할 계획입니다. 또한, 운송 방식별 Mvmt Status에 맞는 Dem/Det 배치 로직도 재정의하여 더욱 효율적인 시스템 운영을 도모할 것입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 구체적으로, 컨테이너 관리팀은 Barge, Rail, Truck 등 다양한 운송 방식에 대한 새로운 Mvmt 코드를 정의하고, 이를 기반으로 Dem/Det daily batch 계산 로직을 적용할 것입니다. 예를 들어, Barge 운송 방식의 경우 Full loading, Full Discharging, Empty loading 등의 상태를 나타내는 코드를 신규로 생성하고, 이에 따라 Dem/Det 배치 계산 로직도 변경될 것입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 이러한 개선을 통해 컨테이너 관리팀은 멀티모달 환경에서의 컨테이너 이동을 보다 효율적이고 정확하게 관리할 수 있을 것으로 기대됩니다., , Score: 0.4826
(InferenceActor pid=591) 4번째 검색자료 (출처:[남성해운] 24년 2사분기 수정사업계획 및 핵심추진과제 진행경과 공유회_20240404.pptx) :
(InferenceActor pid=591) 남성해운은 컨테이너 운영 개선 및 비용 절감을 위한 핵심 추진 과제를 진행하고 있습니다. 이는 2024년 2사분기 수정 사업 계획 및 핵심 추진 과제 진행 경과를 공유하는 회의에서 발표되었습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **주요 내용은 다음과 같습니다.**
(InferenceActor pid=591)
(InferenceActor pid=591) * **장비 회전율 제고:** E/P 계획 및 장비 재배치를 통해 장비 회전율을 제고하고, 장비 적체 지역(동남아/일본 등) 개선 노력을 기울입니다. 장비 부족 지역에는 ONE-WAY 장비를 적극 활용하여 비용을 절감합니다.
(InferenceActor pid=591) * **컨테이너 수요 지역 적시 공급:** 화물 부킹 현황을 공유하고 신속하게 장비를 공급하여 컨테이너 수요 지역에 적시 공급을 실현합니다. 제한적 장비는 우선순위 공급 지역을 지속적으로 협의합니다.
(InferenceActor pid=591) * **장기적체화물 관리:** 장기적체화물을 정기적으로 관리하고 정보를 공유합니다.
(InferenceActor pid=591) * **M&R 비용 절감:** M&R 비용 절감을 위한 관리를 강화합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **구체적인 실행 계획은 다음과 같습니다.**
(InferenceActor pid=591)
(InferenceActor pid=591) 1. **일본 주요 장비 적체 지역 관리:** 일본 주요 장비 적체 지역을 지속적으로 관리하고, 영업/일본 법인 담당자와 현황을 공유하고 협조하여 개선 노력을 기울입니다. 1분기에는 JP발 한국착 20DC 4,262대, 40HC 739대가 적체되었습니다. JPTYO/JPOSA/JPKUH/JPSGM/JPSMZ/JPTMK 순으로 적체가 심했습니다.
(InferenceActor pid=591) 2. **중국 E/P 공급:** 운항/영업 유관 부서와 협조하여 중국 E/P 공급을 확대합니다. NTP/NCK/NCQ 항로를 활용하여 중국향 Direct E/P를 운영하고, NCQ(NSEP2403W)/NCJ(NSTC2401W) 스페셜 JPSBS 기항 및 북중국(대련/천진) E/P를 진행합니다.
(InferenceActor pid=591) 3. **동남아시아 지역 장기적체 장비 관리:** 동남아시아 지역 장기적체 장비 관리를 강화하고 개선합니다. 1분기 기준 포트켈랑 일평균 재고는 40HC 776대였습니다. 잉여 장비를 지속적으로 E/P 진행하여 회전율 제고를 확인합니다.
(InferenceActor pid=591) 4. **대량 화물 부킹 정보 공유:** 대량 화물 부킹 정보를 공유하고 적체 지역 장비 해소 노력을 기울입니다. 국내 장비 수급 상황 및 회전율을 고려하여 물량을 조절합니다.
(InferenceActor pid=591) 5. **장기적체 현황 확인:** 국내외 장기적체 현황을 매월 1회 확인하고 개선 노력을 기울입니다.
(InferenceActor pid=591) 6. **ICON+ 활용:** ICON+(5437)을 활용하여 매월 현황을 분석하고 특이 사항을 지속적으로 확인합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 이러한 노력을 통해 컨테이너 운영 효율성을 높이고 비용을 절감하여 경쟁력을 강화할 계획입니다., , Score: 0.4813
(InferenceActor pid=591) 5번째 검색자료 (출처:남성해운_팀별 주간회의_W47_231121.pptx) :
(InferenceActor pid=591) 남성해운 신성장실현팀은 11월에 해상+육상운송 연계를 활성화하기 위해 여러 업체와 협력하고 있습니다. 온누리로지스틱스와는 미주, 유럽에 편중된 지역에서 벗어나 북중국, 동중국 등으로의 물동량 확대를 위한 협력을 추진하고 있습니다. 로지스틱스 파트너즈와는 인천-신강향 차량 수출로 컨택하여 중국향 물량 연계를 검토하고 있습니다. 이허브에스티와는 부산-홍콩, 마카오, 베트남 등에서 한국발 냉동물량 연계를 진행하고 있습니다. 카고솔루션과는 신규업체로서 투더블유 운송사를 사용하여 인천-싱가포르 물량 연계를 확정했습니다. 밸류링크유와는 디지털 포워딩 활용한 인천발 door 연계를 지속 검토하고 있으며, 인천-하이퐁 태웅식품 물량 연계를 확정했습니다. 뉴웨이브로지스틱스와는 투더블유와 인연있는 대표님을 통해 조만간 진행될 물량 연계를 검토할 예정입니다. 스타콩코드와는 부산 물량 메인으로 인천 물량은 소량이지만 적극적으로 검토하고 있습니다. 나오스월드와는 한국까지 Door term 확대에 대해 검토하고 노력하자는 의도를 전달했습니다. 카스해운과는 플렉시 설치 및 ISO TNK 주요 진행업체로 일부 플렉시 설치에 대한 야드 및 운송 연계 활용 가능여부에 대한 논의를 진행했습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) *, , Score: 0.4792
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) 질문:
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 공 컨테이너 이송 전략에 대해 알려줘<end_of_turn>
(InferenceActor pid=591) <start_of_turn>model
(InferenceActor pid=591) 답변:
(InferenceActor pid=591)
(InferenceActor pid=591) INFO 03-20 08:37:11 [async_llm.py:204] Added request 176b0852-7233-48d9-945b-111acbc58879.
(InferenceActor pid=591) [STREAM] Sent reference data for request_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [STREAM] final_query =
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 남성해운의 중국 시장 현황에 대해 알려줘.
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, RAG 검색 자료: 3429, 사용자 구체화 질문: 14, 총합: 3450
(InferenceActor pid=591) [STREAM] SSE: calling generate_answer_stream for request_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) 최종 LLM 추론용 prompt 생성 :
(InferenceActor pid=591) <bos><start_of_turn>user
(InferenceActor pid=591) 너는 남성해운의 도움을 주는 데이터 분석가야.
(InferenceActor pid=591)
(InferenceActor pid=591) 주어진 **내부 자료**를 바탕으로 **내 질문**에 **상세하고 논리정연한** 답변을 작성해줘.
(InferenceActor pid=591) **답변은 반드시 아래 규칙에 맞춰 Markdown 형식**으로 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 1. **문단/제목:** `#`, `##`, `###` 등의 헤더를 사용하고, 문단 사이에 **한 줄 이상의 공백**을 넣어줘.
(InferenceActor pid=591) 2. **강조**: 강조할 단어나 문구는 `**굵게**`(이중별표) 또는 `*기울임*`(단일별표)를 사용해줘.
(InferenceActor pid=591) 3. **목록**: 필요하다면 `-` 또는 `*` 기호를 사용해 **목록**을 만들어줘.
(InferenceActor pid=591) 4. **표**: SQL 표 결과가 답변에 포함될 경우, 반드시 표의 시작 부분에 "<<<TABLE>>>"와 끝 부분에 "<<<END_TABLE>>>"라는 구분자를 추가해서 출력해줘.
(InferenceActor pid=591) 5. **코드 블록**: 예시 코드나 특수한 데이터는 ``` ``` 언어명 ... ``` ``` 을 사용해 표시해줘.
(InferenceActor pid=591) 6. **출처**: 내부 자료를 참조했다면 **어디서 어떤 내용을 사용했는지**를 마지막에 간단히 표기해줘.
(InferenceActor pid=591) 7. **각주(footnotes)**: 답변에 각주가 필요한 경우, 본문 중에 `[^1]`, `[^2]`와 같은 형태로 표시하고, 마크다운 형식과 같게 답변 마지막에 해당 각주 내용을 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 만약 **주어진 자료**에 질문에 해당하는 내용이 **없다면**, `"내부 자료에 해당 자료 없음"`이라고만 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) **주의**:
(InferenceActor pid=591) - 너무 짧거나 단답형이 아닌, 충분히 **길고 자세한 보고서 형태**로 답변해줘.
(InferenceActor pid=591) - 가능하면 **논리적 근거**와 **예시**를 들어 설명해줘.
(InferenceActor pid=591) - **문단**을 명확히 구분하여 **읽기 편하게** 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 아래는 **내부 자료**와 **질문**이 주어질 것이니, 꼭 이 지침을 따라 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 내부 자료: 1번째 검색자료 (출처:남성해운_팀별 주간회의_W26_240625.pptx) :
(InferenceActor pid=591) ## 남성해운 월누적 영업실적 및 주요 특이사항 (2024년 6월 25일)
(InferenceActor pid=591)
(InferenceActor pid=591) **1. 월누적 영업 실적**
(InferenceActor pid=591)
(InferenceActor pid=591) * **총 실적:** 12,888 TEU (목표 대비 85% 달성)
(InferenceActor pid=591) * **운임율:**
(InferenceActor pid=591)     * 1 Count: $399 (목표 대비 99% 달성)
(InferenceActor pid=591)     * 2 Count: $368 (목표 대비 94% 달성)
(InferenceActor pid=591) * **운임 매출:** $5,145,000 (목표 대비 84% 달성)
(InferenceActor pid=591)
(InferenceActor pid=591) **2. 지역별 운임 동향 및 주요 이슈**
(InferenceActor pid=591)
(InferenceActor pid=591) * **중국:**
(InferenceActor pid=591)     * **북중국:** 청도 신규 문의 증가, 부산/인천 착 증가세, 연운항 운임 회복 시도 중. 천진 마켓 흐름 약세, 선사간 경쟁 심화로 시장 선복 감소 가능성 존재.
(InferenceActor pid=591)     * **동중국:** 상해 장비 안정, 닝보 장비 부족으로 장비 선별 제공. 인천 향 2주 연속 100% 달성. 난징 장가항 약세 진행, 20피트 집화 운임 조정. 충칭발 한국타이어 운임 상향 입찰 예정.
(InferenceActor pid=591)     * **남중국:** 3/4주차 및 7월 부킹 증가세 진행, 마켓 장비 공급 부족과 연계. 금주 장비 부족 예정으로 집중적인 공급 주력 (부킹 대비 550F 부족).
(InferenceActor pid=591) * **동남아:**
(InferenceActor pid=591)     * **하이퐁:** 개선 중, 7월 운임 통지, 마켓 수긍 분위기 저가화 종 20” 소량 선적 (코일).
(InferenceActor pid=591)     * **호치민:** 인천 양호, 부산/광양 약세 (KVT & VTX). 팰릿 운임 화주 반발 불구, 인상 진행. 이탈 예상 시 빠른 장비 활용 추진 (EP).
(InferenceActor pid=591)     * **태국:** 운임율 개선 중 ($256 -> $270 -> $287 -> $308 -> $329 - 월 기준).
(InferenceActor pid=591)     * **싱가포르/말레이시아:** 말레이 7월 계획 운임 수용 어려운 분위기. 고객사별 조정 협의 중.
(InferenceActor pid=591)     * **인도네시아:** 증가세, 전 노선 120%. 비딩 화주 비중 높아 운임 회복율 낮으나 7월부 개선 전망.
(InferenceActor pid=591)
(InferenceActor pid=591) **3. 7월 운임 통지 및 고객사 분위기**
(InferenceActor pid=591)
(InferenceActor pid=591) * **7월 운임 통지:**
(InferenceActor pid=591)     * 베트남 - 인천/평택: $200 인상
(InferenceActor pid=591)     * 베트남 - 부산/울산/광양: $150 인상
(InferenceActor pid=591)     * 태국 - 인천/평택: $200 인상
(InferenceActor pid=591)     * 태국 - 부산/울산/광양: $150 인상
(InferenceActor pid=591)     * 인도네시아 - 인천: $150 인상
(InferenceActor pid=591)     * 인도네시아 - 부산/울산/광양: $100 인상
(InferenceActor pid=591)     * 말레이시아 - 인천: $150 인상
(InferenceActor pid=591)     * 말레이시아 - 부산/울산/광양: $100 인상
(InferenceActor pid=591)     * 심천 - 인천/평택: $200 인상
(InferenceActor pid=591)     * 심천 - 부산/광양: $100 인상
(InferenceActor pid=591)     * 샤먼 - 인천/평택: $100 인상
(InferenceActor pid=591)     * 샤먼 - 부산/광양: $100 인상
(InferenceActor pid=591)     * 남중국 - 인천/평택: $200 인상
(InferenceActor pid=591)     * 남중국 - 부산/광양: $200 인상
(InferenceActor pid=591)     * 청도 - 한국: $100 인상
(InferenceActor pid=591)     * 연운항 - 한국: $100 인상
(InferenceActor pid=591)     * 상해/닝보 - 부산/광양/울산: $50 인상
(InferenceActor pid=591)
(InferenceActor pid=591) * **고객사 분위기:**
(InferenceActor pid=591)     * **수긍:** 남중국/베트남/태국/청도
(InferenceActor pid=591)     * **관망:** 닝보/상해/인도네시아
(InferenceActor pid=591)     * **반발:** 말레이시아/천진
(InferenceActor pid=591)
(InferenceActor pid=591) **4., , Score: 0.6162
(InferenceActor pid=591) 2번째 검색자료 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G(ID:OT_APRAPM8101_F_0187) 중 일부 입니다.
(InferenceActor pid=591) 이 문서는 남성해운(Principals)과 중국 Qingdao에 있는 Sinotrans Central China Co., Ltd. (Agents) 사이의 화물 예약 관련 계약서 일부입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **간략한 내용:**
(InferenceActor pid=591)
(InferenceActor pid=591) * 남성해운은 Sinotrans Central China Co., Ltd.에게 Qingdao에서의 화물 예약 및 운송 관련 업무를 위탁합니다.
(InferenceActor pid=591) * Sinotrans Central China Co., Ltd.는 남성해운의 지시에 따라 화물 예약, 운송, 그리고 관련 서류 처리 등을 담당합니다.
(InferenceActor pid=591) * 두 회사는 이 계약서에 명시된 조건에 따라 상호 협력하여 사업을 진행합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **참고:**
(InferenceActor pid=591)
(InferenceActor pid=591) * 계약서는  "ARTICLE 1: APPOINTMENT" 부분부터 시작됩니다., , Score: 0.6067
(InferenceActor pid=591) 3번째 검색자료 (출처:BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)(ID:OT_APRAPM8101_F_0182) 중 일부 입니다.
(InferenceActor pid=591) 이 텍스트는 남성해운(Namsung Shipping Co., Ltd.)과 베이징(BSC) 간의 운송 계약서 부속서 1번입니다. 핵심 내용은 다음과 같습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) * **계약의 목적**: 베이징의 칭다오 지점(BSC QINGDAO)이 남성해운의 선박 운송 대행을 수행하기 위한 계약 조건을 명시합니다.
(InferenceActor pid=591) * **대행 수수료**: 칭다오 출발 화물의 운송 수익의 3%를 베이징에 지급합니다.
(InferenceActor pid=591) * **지급 대상**: 베이징 칭다오 지점(BSC QINGDAO)에 지급합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **추가 정보**:
(InferenceActor pid=591)
(InferenceActor pid=591) * 계약은 2024년 10월 1일부터 효력이 발생합니다.
(InferenceActor pid=591) * 계약은 칭다오 지점 외에도 베이징의 다른 지점에도 적용됩니다., , Score: 0.6064
(InferenceActor pid=591) 4번째 검색자료 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G(ID:OT_APRAPM8101_F_0187) 중 일부 입니다.
(InferenceActor pid=591) 이 문서는 남성운수(Principals)와 중국에서 운영하는  대리점(Agents) 간의 계약서 일부입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **본문 내용:**
(InferenceActor pid=591)
(InferenceActor pid=591) * **대리점의 책임:** 대리점은 남성운수의 지시에 따라 화물 예약, 운임 수수, 운송 관련 비용 징수, 회계 처리 등의 업무를 수행해야 합니다.
(InferenceActor pid=591) * **결제:** 대리점은 남성운수의 지시에 따라 운임과 기타 비용을 수집하여 남성운수에 정산합니다.
(InferenceActor pid=591) * **보증금:** 남성운수는 대리점의 업무 수행을 보장하기 위해 보증금을 요구할 수 있습니다.
(InferenceActor pid=591) * **보상:** 대리점은 남성운수로부터 수수료를 받습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **전체적인 맥락:**
(InferenceActor pid=591)
(InferenceActor pid=591) 이 계약서는 남성운수가 중국에서 운영하는 대리점과의 업무 협력 방식을 명시하고 있습니다. 대리점은 남성운수의 대리로서 다양한 업무를 수행하며, 그에 대한 책임과 보상에 대한 내용을 담고 있습니다., , Score: 0.6046
(InferenceActor pid=591) 5번째 검색자료 (출처:TZH 中集世联达 (2024.02)) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 TZH 中集世联达 (2024.02)(ID:OT_APRAPM8101_F_0193) 중 일부 입니다.
(InferenceActor pid=591) 본 문서는  **남성해운**과 **CIMC Wetrans International Shipping(Tianjin) Co., Ltd.** 간의 **항만 대리 업무 협정**에 대한 내용입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **핵심 내용:**
(InferenceActor pid=591)
(InferenceActor pid=591) * **남성해운**은 **CIMC Wetrans International Shipping(Tianjin) Co., Ltd.**를  **TJ항**에서 **대리 업무**를 수행하도록 위임합니다.
(InferenceActor pid=591) * **CIMC Wetrans International Shipping(Tianjin) Co., Ltd.**는 **남성해운**의 선박 입출항, 화물 처리, 선박 및 선원에 필요한 물품 및 서비스 제공 등 다양한 업무를 수행합니다.
(InferenceActor pid=591) * **CIMC Wetrans International Shipping(Tianjin) Co., Ltd.**는 **남성해운**의 이익을 보호하고, 원활한 운영을 위해 최선을 다하겠다고 약속합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) **참고:**
(InferenceActor pid=591)
(InferenceActor pid=591) * **TJ항**은 중국의 항구 중 하나입니다.
(InferenceActor pid=591) * **대리 업무**란 선박 운영에 필요한 다양한 업무를 선주 대신 수행하는 것을 의미합니다., , Score: 0.5940
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) 질문:
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 남성해운의 중국 시장 현황에 대해 알려줘.<end_of_turn>
(InferenceActor pid=591) <start_of_turn>model
(InferenceActor pid=591) 답변:
(InferenceActor pid=591)
(InferenceActor pid=591) INFO 03-20 08:37:11 [async_llm.py:204] Added request 80b3ad90-1222-47da-a385-4ecebb03796c.
(InferenceActor pid=591) [STREAM] Sent reference data for request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [STREAM] final_query =
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 남성해운의 새로운 전략에 대해 자세히 알려줘
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, RAG 검색 자료: 6059, 사용자 구체화 질문: 13, 총합: 6079
(InferenceActor pid=591) [STREAM] SSE: calling generate_answer_stream for request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) 최종 LLM 추론용 prompt 생성 :
(InferenceActor pid=591) <bos><start_of_turn>user
(InferenceActor pid=591) 너는 남성해운의 도움을 주는 데이터 분석가야.
(InferenceActor pid=591)
(InferenceActor pid=591) 주어진 **내부 자료**를 바탕으로 **내 질문**에 **상세하고 논리정연한** 답변을 작성해줘.
(InferenceActor pid=591) **답변은 반드시 아래 규칙에 맞춰 Markdown 형식**으로 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 1. **문단/제목:** `#`, `##`, `###` 등의 헤더를 사용하고, 문단 사이에 **한 줄 이상의 공백**을 넣어줘.
(InferenceActor pid=591) 2. **강조**: 강조할 단어나 문구는 `**굵게**`(이중별표) 또는 `*기울임*`(단일별표)를 사용해줘.
(InferenceActor pid=591) 3. **목록**: 필요하다면 `-` 또는 `*` 기호를 사용해 **목록**을 만들어줘.
(InferenceActor pid=591) 4. **표**: SQL 표 결과가 답변에 포함될 경우, 반드시 표의 시작 부분에 "<<<TABLE>>>"와 끝 부분에 "<<<END_TABLE>>>"라는 구분자를 추가해서 출력해줘.
(InferenceActor pid=591) 5. **코드 블록**: 예시 코드나 특수한 데이터는 ``` ``` 언어명 ... ``` ``` 을 사용해 표시해줘.
(InferenceActor pid=591) 6. **출처**: 내부 자료를 참조했다면 **어디서 어떤 내용을 사용했는지**를 마지막에 간단히 표기해줘.
(InferenceActor pid=591) 7. **각주(footnotes)**: 답변에 각주가 필요한 경우, 본문 중에 `[^1]`, `[^2]`와 같은 형태로 표시하고, 마크다운 형식과 같게 답변 마지막에 해당 각주 내용을 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 만약 **주어진 자료**에 질문에 해당하는 내용이 **없다면**, `"내부 자료에 해당 자료 없음"`이라고만 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) **주의**:
(InferenceActor pid=591) - 너무 짧거나 단답형이 아닌, 충분히 **길고 자세한 보고서 형태**로 답변해줘.
(InferenceActor pid=591) - 가능하면 **논리적 근거**와 **예시**를 들어 설명해줘.
(InferenceActor pid=591) - **문단**을 명확히 구분하여 **읽기 편하게** 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 아래는 **내부 자료**와 **질문**이 주어질 것이니, 꼭 이 지침을 따라 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 내부 자료: 1번째 검색자료 (출처:남성해운_팀별 주간회의_W9_240227.pptx) :
(InferenceActor pid=591) 남성해운은 디지털 전환(DT) 요구와 마켓 수요 증가에 따라 비대면 영업 채널 확대를 추진하고 있다. 이를 위해 포스코플로우, 판토스NOW, 쉽다, 서프컴퍼니, 밸류링크유, 지비티에스 등 다양한 파트너사와 협력하고 있다.
(InferenceActor pid=591)
(InferenceActor pid=591) 포스코플로우와는 연근해 지역 우선순위 전략적 파트너로서 협업하고 있으며, 각 파트너사로부터 월간 약 30 TEU 이상의 Bkg 유입을 목표로 하고 있다. 판토스NOW 플랫폼은 1월에 정식 런칭되었으며, 현재 서비스 프로모션 및 마케팅 진행 중이다. 쉽다와는 중국발 위주로 월간 약 20~30 TEU의 수입 Bkg 유입을 진행하고 있으며, 싱가포르/말레이시아/인도네시아 등 우리사 필요지역으로의 유치를 확대하려고 노력하고 있다. 서프컴퍼니와는 북중국향 포워더 대상 이벤트성 프로모션 수행을 검토하고 있으며, CY~Door 포함 남성해운 서비스를 플랫폼/채널을 통한 홍보 및 영업 지원을 계획하고 있다. 밸류링크유와는 평택발 하이퐁착 월간 약 10~30 TEU의 냉동화물 수출을 지속하고 있다. 지비티에스는 Bkg 유입이 미미하여 2024년 1월부터 자체 포워더팀을 신설하여 영업을 진행하고 있다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 비대면 영업 채널 확대를 통해 시장 변화에 적응하고 경쟁력을 강화하고자 한다., , Score: 0.6138
(InferenceActor pid=591) 2번째 검색자료 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx) :
(InferenceActor pid=591) 남성해운은 디지털 기술을 활용하여 물류 패러다임을 변화시키고, 디지털 기반 확장된 물류 생태계 구성원들에게 차별화된 경험을 제공하는 데 중점을 두고 있습니다. 이를 위해 남성해운은 DT 로드맵 추진과제를 수행하고 있으며, e-Service 및 플랫폼 파트너사, 디지털 포워더사와 협업하고 있습니다. 또한, 남성해운은 경쟁력 있는 운임 제공, 아세안 지역 내륙 개발을 통한 복합 운송 연계 서비스 계획, 해외 거점 터미널 확보, 일본, 중국, 인도 등 소규모 항구 개발을 통한 피더 네트워크 확보, 친환경 고효율 선박 확충 등 다양한 전략을 통해 차별화된 서비스를 제공하고 있습니다. 남성해운은 디지털 혁신 비전인 "Digitalized Logistics to Empower your Experience"를 선포하고 로드맵을 통해 Enabler를 도출 및 시행 중입니다., , Score: 0.6007
(InferenceActor pid=591) 3번째 검색자료 (출처:Huangpu terminal 2023) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 Huangpu terminal 2023(ID:OT_APRAPM8101_F_0026) 중 일부 입니다.
(InferenceActor pid=591) This document appears to be a section of a larger contract between 남성해운 (likely a shipping company) and a terminal operator (possibly Huangpu terminal) concerning container ship operations.
(InferenceActor pid=591)
(InferenceActor pid=591) Here's a breakdown of the key points:
(InferenceActor pid=591)
(InferenceActor pid=591) * **New Route Notification:** 남성해운 is obligated to inform the terminal operator (Z方) at least 20 calendar days in advance via email (YW-IZX@CZPORT.COM) or written notice if they plan to launch a new shipping route.
(InferenceActor pid=591)
(InferenceActor pid=591) * **Coordination and Information Sharing:** All three parties (남성해운, its agent, and the terminal operator) need to maintain close communication to ensure smooth vessel operations. 남성해운 must provide timely updates on vessel schedules, including a monthly schedule by the 22nd of each month and a 3-day advance notice for each berth arrival.
(InferenceActor pid=591)
(InferenceActor pid=591) * **Detailed Cargo Information:** 남성해운 must provide the terminal operator with comprehensive details about incoming and outgoing cargo, including container count, weight, type (standard, refrigerated, dangerous goods), and transportation arrangements (transhipment vessel, trucking, etc.).
(InferenceActor pid=591)
(InferenceActor pid=591) * **Terminal Operator's Responsibilities:** The terminal operator (Z方) is responsible for developing and implementing a port operation plan based on 남성해운's vessel schedules and cargo information. They will also coordinate and guide the loading, unloading, and other port operations.
(InferenceActor pid=591)
(InferenceActor pid=591) Overall, this document outlines the communication protocols, information sharing requirements, and responsibilities of each party involved in handling 남성해운's container ships at the Huangpu terminal., , Score: 0.5968
(InferenceActor pid=591) 4번째 검색자료 (출처:20230731155302_GNE 계약서) :
(InferenceActor pid=591) 이 문서는 남성해운의 계약서 20230731155302_GNE 계약서(ID:OT_APRAPM8101_D_0043) 중 일부 입니다.
(InferenceActor pid=591) This document is part of a larger agreement between 남성해운 and another party.
(InferenceActor pid=591)
(InferenceActor pid=591) The specific excerpt you provided details the responsibilities of the agent (likely a shipping agency) representing 남성해운. These responsibilities include:
(InferenceActor pid=591)
(InferenceActor pid=591) * **Vessel Handling:** Arranging berths, customs clearance, immigration, pilotage, and other services for vessels owned or managed by 남성해운.
(InferenceActor pid=591) * **Supplies and Repairs:**  Arranging for fuel, provisions, stores, and emergency repairs for vessels as instructed by 남성해운.
(InferenceActor pid=591)
(InferenceActor pid=591) Essentially, this section outlines the day-to-day operational tasks the agent is expected to handle on behalf of 남성해운's vessels.
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) Let me know if you need me to elaborate on any specific part of this excerpt!, , Score: 0.5910
(InferenceActor pid=591) 5번째 검색자료 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx) :
(InferenceActor pid=591) 20년 동안 남성해운은 “Beyond Shipping, Engineering the future”라는 새로운 슬로건을 내세우며 기존의 Port to Port 서비스 강점을 바탕으로 해상운송에서 육상운송까지 서비스를 확대하는 Extended Logistics를 추진하고 있습니다. 이는 기존 Port to Port 서비스 운영 구조 혁신을 통한 성장, Port to Port 서비스 기반 Extended Logistics Service로의 확장, 그리고 컨테이너 운송업 중심에서 연관 타 업종으로의 확장을 의미합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 기존의 핵심 역량을 최대한 활용하여 비관련 사업으로 신규 진입하고, 기존 비즈니스와 관련 없는 신규 사업을 통한 지속적인 성장을 도모하고 있습니다. 또한, 컨테이너 운송업 중심에서 벗어나 제3자 물동량 처리, 배후부지/Depot/운송사 자영화 및 지분 투자 등을 통해 사업 영역을 확장하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 기존 노선 합리화를 통해 수익성을 지속적으로 개선하고 있으며, 신규 노선 개설을 통해 신규 지역 및 복합 운송 집중 지역으로 진출하고 있습니다. 또한, 컨테이너 선박 기반 Port-to-Port 서비스를 제공하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 기술 선도, 사업 창출, 조직 혁신을 통해 지속적인 변화를 추구하고 있습니다. 4차 산업혁명 기술을 활용한 혁신, 기존 인력에게 New Trend/New Society에 맞는 역량 교육 지원 등을 통해 컨테이너 운송업의 고객 혁신 및 운영 효율성 극대화를 도모하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 남성해운은 우수 선화주기업 인증제도 현장평가 참조자료에 따르면, 2023년 11월 3일 현재, 기존의 컨테이너 운송업에서 벗어나 제3자 물동량 처리, 배후부지/Depot/운송사 자영화 및 지분 투자 등을 통해 사업 영역을 확장하고 있습니다., , Score: 0.5885
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) 질문:
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 남성해운의 새로운 전략에 대해 자세히 알려줘<end_of_turn>
(InferenceActor pid=591) <start_of_turn>model
(InferenceActor pid=591) 답변:
(InferenceActor pid=591)
(InferenceActor pid=591) INFO 03-20 08:37:11 [async_llm.py:204] Added request 2bd55330-c68d-491e-97bc-ab33b798e4a8.
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering generate_answer_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting generate_answer_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering collect_vllm_text_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting collect_vllm_text_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) Token indices sequence length is longer than the specified maximum sequence length for this model (6059 > 4024). Running this sequence through the model will result in indexing errors
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering generate_answer_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting generate_answer_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:11: Entering collect_vllm_text_stream()
(InferenceActor pid=591) [2025-03-20 08:37:11] INFO tracking.py:15: Exiting collect_vllm_text_stream() -- Elapsed: 0.00s
[DEBUG] SSE closed.
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:51,373 default_inference 1zebleoo 7b6349c1-36c0-4961-9278-b717364f2879 -- CALL close_sse_queue OK 2.3ms
(InferenceActor pid=591) ---------------- chunk_id 찾기 :  [{'rsp_tit': '1번째 검색데이터: [국내영업본부] 수입영업팀장> 월누적 영업실적 및 주간 주요 특이사항 (출처:남성해운_팀별 주간회의_W26_240625.pptx)', 'rsp_data': [{'rsp_type': 'TB', 'rsp_tit': '월 누적 영업 실적 및 운임율, 매출 달성도', 'rsp_data': {'head': '월누적\x0b영업\x0b실적||실적(TEU)||||||||운임율(RPT/$), 1 Count||||||||운임율(RPT/$), 2 Count||||||||운임매출(천$)||||||', 'body': '||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)||사계\x0b목표||수정\x0b목표||누적\x0b실적||달성율(%)^||14,940||15,150||12,888||85%||401||403||399||99%||392||394||368||94%||5,994||6,105||5,145||84%'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '실적 중국 동남아 운임 동향 주요 이슈 및 영업 방향\n[북중국]\n청도 신규 문의 증가\n더불어 부산TS인천착 증가세\n연운항 운임 회복 시도중\n천진 마켓흐름 약세 선사간 경쟁심화.\n시장 선복 감소 가능성은 존재\n[동중국]\n상해 장비안정\n닝보 장비부족 -> 장비 선별 제공．\n인천향 2주 연속 100%\n난징 장가항 약세진행\n20피트 집화 운임 조정.\n충칭발 한국타이어 운임 상향 입찰예정\n[남중국]\n3/4주차 및 7월 부킹 증가세 진행\n\uf0e0 마켓 장비 공급 부족과 연계\n금주 장비 부족예정으로 집중적인 공급 주력\n(부킹 대비 550F 부족)\n6월 목표대비 실적 84%, 매출 83%\nRPT 398$ (전월 $388 대비 $10▲ )\n[하이퐁]\n개선중\n7월 운임 통지, 마켓 수긍 분위기\n저가화종 20”소량 선적(코일)\n[호치민]\n인천 양호, 부산/광양 약세(KVT & VTX).\n팰릿운임 화주반발 불구, 인상 진행.\n이탈예상시 빠른 장비 활용 추진(EP)\n[태국]\n운임율 개선중\n$256 -> $270 -> $287 -> $308 - >$329 (월 기준)\n[싱/말]\n말레이 7월 계획 운임 수용 어려운 분위기.\n고객사별 조정협의중\n[인니 ]\n증가세\n전 노선 120% 비딩화주 비중 높아 운임회복율 낮으나 7월부 개선 전망\n7월 운임 통지에 대한 구간별 고객사 분위기\n[수긍] 남중국/베트남/태국/청도\n-> 부킹 추이 확인 필요\n[관망] 닝보/상해/인도네시아\n[반발] 말레이시아/천진\n중국 동남아 운임회복 추진(7월 10일자)'}, {'rsp_type': 'TB', 'rsp_tit': '동남아시아 항로 운임 인상, 6월 대비 최대 200달러 상승', 'rsp_data': {'head': 'POL||POD||인상 폭(6월대비)', 'body': '베트남||인천/평택||$200^||부산/울산/광양||$150^태국||인천/평택||$200^||부산/울산/광양||$150^인도네시아||인천||$150^||부산/울산/광양||$100^말레이시아||인천||$150^||부산/울산/광양||$100^심천||인천/평택||$200^||부산/광양||$100^샤먼||인천/평택||$100^||부산/광양||$100^남중국||인천/평택||$200^||부산/광양||$200^청도||한국||$100^연운항||한국||$100^상해/닝보||부산/광양/울산||$50'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '단위:TEU'}], 'chunk_id': 1425}, {'rsp_tit': '2번째 검색데이터: SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page1 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'AGENCY AGREEMENT (CARGO BOOKING) This Agreement is made as of 1st of August, 2024 between Namsung Shipping Co., Ltd. (Address: 17 th Floor, Jangkyo Bldg., 1, Jangkyo-dong Chung-ku, Seoul 100-760, Korea/hereinafter referred to as "Principals") and SINOTRANS CENTRAL CHINA CO.,LTD.CONTAINER SHIPPING BRANCH (Address:11-12 Floor, Sinotrans Mansion, No.5 Henan Road, Qingdao, China /hereinafter referred to as "Agents"). Whereas, Principals are engaged in the business of owning, operating and managing vessels in international commerce and NOW, THEREFORE, in consideration of the reciprocal undertaking and the promises of the parties herein expressed, the parties agree as follows: ARTICLE 1.<APPOINTMENT> Principals appoint Agents as their booking agent in Qingdao, China to perform all of the customary Agency services as hereinafter further described, serving "Principals" liner service from Qingdao, China to the other ports, Agents accept such appointment and agree to use their best efforts to perform the cargo and equipment control agency services provided for by this Agreement in conformance with the lawful policies and practices and instructions of Principal. ARTICLE 2<SCOPE OF AGENCY SERVICES> Agents shall provide necessary agency service for booking cargoes to be loaded from Qingdao, cargo handlings and for all Principal owned or leased containers, and other equipment (hereinafter referred to as "Equipments"). 1. Maintain favorable customer relations with the Principals clients or prospective clients; 2. Upon request from Principals solicit cargo both outbound and inbound from and to ports and places served by Principals, in the area covered by this Agreement as set forth in ARTICLE 1, from shippers, consignees, trade associations and others engaged in transportation activities in the foreign and domestic commerce of the shipping business; 3. Quote rates in accordance with Principals then effective tariffs, book cargo subject to space allotments, arrange for the receipt and delivery of cargo and issue and sign bills of lading by its authorized person whose specimen signature registered to Principals and other shipping documents for and on behalf of Principals pursuant to instructions and guidelines which may be given from time to time by Principals; 4. Adopt collection procedures and collect freights and other moneys due to Principals pursuant to the provisions of this Agreement all applicable conference agreements, FMC rules and/or'}], 'chunk_id': 2637}, {'rsp_tit': '3번째 검색데이터: BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)_page8 (출처:BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ))', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'ADDENDUM NO.1 TO AGENCY AGREEMENT DATED With reference to article 11 of the above agency agreement between Namsung Shipping Co., Ltd. (hereinafter the "Company") and BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRANCH (hereinafter the "Agent") dated 1st of October, 2024, it is hereby agreed that the Company shall compensate the Agent on the following basis: Cargo Commission: Only for the cargoes exported from Qingdao to the other ports served by the Company a) 3% of prepaid basic ocean freight revenue b) 1.5% of collected basic ocean freight revenue • As the Booking Agent, 30% of the profit per unit shall be shared with NB LOGISTICS. • The same terms outlined above (30% profit share with NB LOGISTICS) shall apply to BESCON SHANGHAI, as they do with BESCON QINGDAO. The Addendum No.1 will be effective starting from the date indicated on the top paragraph of Addendum No.1 of the Agency Agreement. The "Principals" Namsung Shipping By Title: The "Agents" BSC SHANGHAI LOGISTICS CO LTD QINGDAO BRA By Title: The "Agents" NB Logistics Co., Ltd For and on behalf of NB Logistics Limited m R W W W R A R By Title: futhorized Signature(s) r o st ff'}], 'chunk_id': 2726}, {'rsp_tit': '4번째 검색데이터: SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G_page4 (출처:SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': "services or its vessels as Agents and Principals may agree from time to time. 14. Furnish Principals with information relative to cargo movement statistics and prevailing market trend and etc. in accordance with principal's request. 15. Arrange the delivery of cargo to consignees in accordance with original B/L issued by on behalf of Principals. ARTICLE 3.<ACCOUNTING, COLLECTIONS, DISBURSEMENTS AND REMITTANCES> 1. Pursuant to instructions from Principals, Agents maintain separate accounts in the name of Principals or Agents for the purpose of transacting the receipt, payment, deposit and remittance of all moneys handled for the account of or on behalf of Principals. All freight revenues and other receipts or moneys earned by or owing to Principals, Agents or other person shall let consignee or shipper's or debtors also pay any, and all freight direct to the Principals bank account. Agents should aim to cause consignees or shippers or debtors to issue checks made payable to the Principals. In no event shall any such funds be deposited in any account of Agents nor shall funds belonging to others be commingled in Principals accounts. 2. Principals shall provide Agents with Agents commission charges after computation of Agents commission based on the manifest to be forwarded by Agents. Agents shall remit total freight earning both prepaid and collect in the area to Principals designated bank accounts on each voyage basis within one month after the departure date of Principals, Agents Commission and any other charges in connection with cargo freight could be deducted from the freight then remitted the balance to the Principals on each voyage basis. Agents shall maintain and report the statement of Principals' freight earning and expenditure on each voyage basis. 3. Principals shall remit the disbursement such as terminal, CFS, haulage etc within the credit period or payment allowed by the service contractors in case there is no plus balance. In extraordinary cases acceptable to Principals, Principals shall remit the disbursement confirmed by Principals' representative promptly. 4. All monetary obligations of Principals which are handled by Agents pursuant to the provisions of this Agency Agreement shall be paid from such disbursements and transmittals made strictly in accordance with instructions and practices as may be established by Principals. 5. Agents will exercise their best efforts and due diligence to collect all freight and other charges due and payable to Principals at the place of payment whether on inbound or outbound cargo and including all detention, demurrage, per diem, terminal, depot and other charges assessed against cargo, containers or chassis or other equipment involved in principal services."}], 'chunk_id': 2698}, {'rsp_tit': '5번째 검색데이터: TZH 中集世联达 (2024.02)_page1 (출처:TZH 中集世联达 (2024.02))', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'TJCD20240126 AGENCY AGREEMENT It is this day mutually agreed on 1st of Aug, 2024 between NAMSUNG SHIPPING CO.,LTD..(addressed in 17/f., Auggkyo Bldg., 1, Auggkyo-dong, Chung-ku, Seoul, Korea herein after referred to as the “PRINCIPALS”) And CIMC Wetrans International Shipping(Tianjin) Co.,Ltd.(addressed in No. 158 Jingmen Blvd, Free Trade Zoon Tianjin Port, China herein after referred as the “AGENTS”) And CIMC Wetrans Logistics Management Co Ltd. (Address : Floor 9, Block B1, Modem Service District , No .62 Second BLVD , Economic & Technical Development Zone , Tianjin China / hereinafter referred to as “ Settlement Company”). I . Principle: 1. The PRINCIPALS agree to entrust the AGENTS to act as Husbanding AGENTS for their liners calling at Xingang port. 2. The AGENTS accept the appointment and will endeavor to protect and promote the PRINCIPALS interests. The AGENTS will also effectively execute this agreement. II . The AGENTS’ Service and Responsibilities: A) Husbanding 1. Notify local port officials concerning vessels’ arrival and secure berths for all vessels owned/operated/chartered/managed by the PRINCIPALS. 2. Arrange entry and clearance of the vessels complying with all applicable port regulations. 3. Arrange payment of port charges and any dues payable in respect of the vessels. 4. Arrange for the supply of fuel, water provisions and ship’s stores. 5. Arrange for ship’s repairs required.'}], 'chunk_id': 2842}]
(InferenceActor pid=591) 메시지 저장 직후 chunk_id 확인 :  chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='남성해운 중국 시장 근황', additional_kwargs={'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={}), AIMessage(content='## 남성해운 중국 시장 현황 보고서 (2024년 6월 25일 기준)\n\n본 보고서는 내부 자료를 바탕으로 남성해운의 중국 시장 현황을 분석한 결과입니다. 자료 출처는 남성해운 팀별 주간회의 자료(W26, 2024년 6월 25일)입니다.\n\n### 1. 지역별 운임 동향 및 이슈\n\n남성해운의 중국 시장은 크게 북중국, 동중국, 남중국으로 구분하여 살펴볼 수 있습니다.\n\n*   **북중국:**\n    *   청도 신규 문의가 증가하고 있으며, 부산/인천 착 증가세가 나타나고 있습니다.\n    *   연운항 운임은 회복을 시도하고 있으나, 천진 마켓은 흐름이 약세이며 선사 간 경쟁 심화로 인해 시장 선복 감소 가능성이 존재합니다. 이는 경쟁 심화로 인한 운임 하락 압력으로 이어질 수 있습니다.\n\n*   **동중국:**\n    *   상해는 장비 상황이 안정적이지만, 닝보는 장비 부족으로 장비 선별 제공이 이루어지고 있습니다. 이는 운송 효율성에 영향을 줄 수 있습니다.\n    *   인천 향은 2주 연속 100% 달성하여 긍정적인 신호로 보이나, 난징과 장가항은 약세가 지속되고 있으며, 20피트 집화 운임은 조정되었습니다.\n    *   충칭발 한국 타이어 운임은 상향 입찰이 예정되어 있습니다.\n\n*   **남중국:**\n    *   3/4주차 및 7월 부킹이 증가하고 있으며, 마켓 장비 공급 부족과 연계되고 있습니다. 이는 높은 수요에 비해 공급이 부족하다는 의미입니다.\n    *   금주 장비 부족이 예상되어 집중적인 공급 주력이 필요한 상황입니다. 부킹 대비 550F의 장비 부족이 예상됩니다.\n\n### 2. 7월 운임 통지 및 고객사 분위기\n\n남성해운은 7월 운임을 인상할 계획이며, 지역별 인상 폭은 다음과 같습니다.\n\n<<<TABLE>>>\n| 출발지        | 도착지         | 인상 폭 ($) |\n| ------------- | ------------- | ---------- |\n| 베트남        | 인천/평택      | 200        |\n| 베트남        | 부산/울산/광양  | 150        |\n| 태국          | 인천/평택      | 200        |\n| 태국          | 부산/울산/광양  | 150        |\n| 인도네시아     | 인천          | 150        |\n| 인도네시아     | 부산/울산/광양  | 100        |\n| 말레이시아     | 인천          | 150        |\n| 말레이시아     | 부산/울산/광양  | 100        |\n| 심천          | 인천/평택      | 200        |\n| 심천          | 부산/광양      | 100        |\n| 샤먼          | 인천/평택      | 100        |\n| 샤먼          | 부산/광양      | 100        |\n| 남중국        | 인천/평택      | 200        |\n| 남중국        | 부산/광양      | 200        |\n| 청도          | 한국          | 100        |\n| 연운항        | 한국          | 100        |\n| 상해/닝보     | 부산/광양/울산 | 50         |\n<<<END_TABLE>>>\n\n*   **고객사 분위기**는 지역별로 다르게 나타나고 있습니다.\n    *   **수긍:** 남중국, 베트남, 태국, 청도 지역 고객사들은 운임 인상에 대해 비교적 긍정적인 반응을 보이고 있습니다.\n    *   **관망:** 닝보, 상해, 인도네시아 지역 고객사들은 운임 인상에 대해 신중한 입장을 취하며 시장 상황을 지켜보고 있습니다.\n    *   **반발:** 말레이시아와 천진 지역 고객사들은 운임 인상에 대해 반발하고 있어 협상이 필요할 것으로 예상됩니다.\n\n### 3. 남성해운의 중국 내 파트너십 현황\n\n남성해운은 중국 내에서 다음과 같은 기업들과 파트너십을 맺고 있습니다.\n\n*   **Sinotrans Central China Co., Ltd.:** 청도에서의 화물 예약 및 운송 관련 업무를 위탁하고 있습니다.\n*   **CIMC Wetrans International Shipping(Tianjin) Co., Ltd.:** TJ항에서 항만 대리 업무를 위탁하고 있습니다.\n*   **Beijing(BSC):** 칭다오 지점을 통해 선박 운송 대행을 수행하고 (수익의 3% 수수료 지급), 베이징의 다른 지점에도 계약이 적용됩니다.\n\n### 4. 결론 및 시사점\n\n남성해운의 중국 시장은 지역별로 다른 특성을 보이고 있습니다. 특히 남중국과 동남아 지역은 장비 부족으로 인해 공급망에 차질이 발생할 가능성이 있습니다. 7월 운임 인상은 긍정적인 수익 개선에 기여할 수 있지만, 말레이시아와 천진 지역 고객과의 협상이 중요합니다.  또한, 중국 내 파트너십을 통해 청도, 톈진 등 주요 항만에서의 서비스 품질을 유지하고 강화하는 것이 중요합니다.\n\n**향후 전략**:\n\n*   장비 부족 문제를 해결하기 위한 적극적인 대책 마련 (예: 장비 확보, 효율적인 장비 운영).\n*   말레이시아 및 천진 지역 고객과의 협상을 통해 운임 인상에 대한 이해를 구하고 반발을 최소화.\n*   중국 내 파트너십을 더욱 강화하여 서비스 품질 및 경쟁력을 향상.\n\n---\n\n**출처:**\n\n*   남성해운_팀별 주간회의_W26_240625.pptx\n*   남성해운 계약서 SINOTRANS CENTRAL CHINA-AGENCY AGREEMENT(cargo booking) QSN 2024 (SAMPLE) - B.G(ID:OT_APRAPM8101_F_0187)\n*   남성해운 계약서 BSC QINGDAO-AGENCY AGREEMENT(cargo booking) 2024 (Deposit) - (QINGDAO BESCON) (HQ)(ID:OT_APRAPM8101_F_0182)\n*   남성해운 계약서 TZH 中集世联达 (2024.02)(ID:OT_APRAPM8101_F_0193)\n', additional_kwargs={'chunk_ids': [1425, 2637, 2726, 2698, 2842], 'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={})]) return_messages=True
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 대답
(InferenceActor pid=591) [STREAM] error in partial streaming => 'str' object has no attribute 'get'
(InferenceActor pid=591) [STREAM] close_sse_queue => removing SSE queue for request_id=5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [STREAM] close_sse_queue => no SSE queue found for 5d92db76-0666-4580-8089-b9798a234ea3
(InferenceActor pid=591) [2025-03-20 08:37:51] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:51] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:51] INFO tracking.py:11: Entering process_format_to_response()
(InferenceActor pid=591) [2025-03-20 08:37:51] INFO tracking.py:11: Entering error_format()
(InferenceActor pid=591) [2025-03-20 08:37:51] INFO tracking.py:15: Exiting error_format() -- Elapsed: 0.00s
[DEBUG] SSE closed.
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:53,202 default_inference 1zebleoo a105fa67-ed8e-42a6-bbc5-04fdf5401679 -- CALL close_sse_queue OK 2.5ms
(InferenceActor pid=591) ---------------- chunk_id 찾기 :  [{'rsp_tit': '1번째 검색데이터: [운영혁신본부] 2023년 년간 사업계획 > 컨테이너관리팀 중점 추진과제 실행계획 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx)', 'rsp_data': [{'rsp_type': 'TB', 'rsp_tit': '컨테이너 보유량 통제 및 신규 서비스 지역 재고 관리', 'rsp_data': {'head': '유형||중점 추진과제||추진목표 및 중점 추진항목||과제수행 책임리더||비 고', 'body': '컨관팀\x0b추진과제||컨테이너 보유량 통제 (E/P관리 포함)||노후 임대 컨테이너 반납 및 재 연장 검토 노후VAN 교체를 위한 최소 14년 이상 경과 장비 매각 진행 검토 매각대상 20’DC X 1,847 &amp; 40HC X 2,145(2008년 이전 제작) 신규 서비스 및 선복 증감 대비 적정 운영수량 통제/관리 장비 운영 효율성 지속 관리/개선 노력 22년 65%→23년 68% IMBALANCE 개선을 통하여 지속 E/P 수량 제어 노력 국내외 지역간 적시 E/P를 통한 장비 재배치 및 효율성 제고 권역별 장기 미사용 적체 컨테이너 집중 관리||(主) 컨테이너관리팀 (協) 영업추진본부 운항관리팀 해외법인 및 사무소||물동량 및 컨테이너 시황 고려하여 장비 수급 조절 장비 효율성에 따라 E/P 수량 변동^||신규 서비스 지역 재고관리||신규항로 서비스 인도네시아/말레이시아/마닐라 재고 집중 관리 IMBALANCE로 인한 IDLE CNTR 장비 최소화 및 적시 해소 노력 ICON+를 활용 및 주기적 현황 파악을 통한 재고관리 강화||(主)컨테이너관리팀 (協)해외법인 및 사무소 영업추진본부||'}}], 'chunk_id': 916}, {'rsp_tit': '2번째 검색데이터: 내륙운송화물 운송Mode별 (Barge/Rail/Trucking) Movement 도식화 (출처:[운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '*BARGE (Full) \n*RAIL (Full) \n*TRUCKING (Full) \nBX : Export Full Loading \nRX : Export Full Loading \nOX : Export Full Gate-out \nGX : Export Full Discharging \nLX : Export Full Discharging \nTX : Export Full Gate-in \nBI : Import Full Loading \nRI : Import Full Loading \nOI : Import Full Gate-out \nGI : Import Full Discharging \nLI : Import Full Discharging \nTI : Import Full Gate-in \n*BARGE (Empty) \n*RAIL (Empty) \n*TRUCKING (Empty) \nBE : Empty Loading \nRE : Empty Loading \nOE : Empty Loading'}], 'chunk_id': 920}, {'rsp_tit': '3번째 검색데이터: [신성장전략실] 디지털운영팀장 > 업무 자동화 영역 서비스 고도화 (출처:남성해운_팀별 주간회의_W45_231107.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '[협업]\n컨테이너관리팀\nIn 서비스\nTrans Mode Mvmt Status 표준화 관리 고도화\nland\n. 現, 멀티모달 비즈니스에 맞는 Mvmt Status 코드 표준안 개선 시급\n. Ocean 구간이외 Trans mode별 Mvmt Status 모호\n. Trans mode별 서비스 지역의 컨테이너 이동 현황 핀셋 관리 필요\n. Trans mode의 Mvmt Status에 맞는 코드 로직 재정의 및 신규 코드로 Cntr Mvmt 등록/관리\n. Trans mode의 Mvmt Status에 맞는 Dem/Det배치 로직 재정의\n. 신규 코드 생성\n. 등록 관리 ( 5201,5202,5211,5203 : ICON+)\n. Dem/Det daily batch계산 로직 적용 결과도출\n배경\n배경\n배경\n배경\n배경\nAs is\n[ Trans mode : Barge]\nTo be\n[ Trans mode :Barge]\n신규 Mvmt 코드 정의\nBF :\xa0Barge\xa0Full loading\nGF :\xa0Barge full\xa0Discharging\nBE :\xa0Barge\xa0Empty loading\nRF :\xa0Rail\xa0Full loading\nAF :\xa0Rail full\xa0Discharging\nRE :\xa0Rail\xa0Empty loading\nOF : Truck\xa0Full loading\nTF : Truck\xa0Full Discharging\nOE : Truck \xa0Empty loading\nKRINC\nKRINC\n[ Trans mode ]\nVF\nVF\nCNSHA\nCNSHA\nDF\nDF\nCNSHA\nCNSHA\nVF\nBF\nCNZHE\nOcean과 같은 mvmt status를 사용하여 가장 마지막 DF/CF/TE로 계산\nCNZHE\nGF : Barge full\xa0Discharging이후 TE까지 계산\nDF\nGF\nCNZHE\nCNZHE\nCF\nCF\nCNZHE\nCNZHE\nTE\nTE'}], 'chunk_id': 1813}, {'rsp_tit': '4번째 검색데이터: [컨/관리팀] 2024년도 핵심추진과제 > #1. 주요장비 적체지역 집중 관리 및 M&R 비용관리 통제 (출처:[남성해운] 24년 2사분기 수정사업계획 및 핵심추진과제 진행경과 공유회_20240404.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '[해외 M&R 관리 현황]\n10개 주요 권역 VAN당 수리비 목표금액(USD) 설정하여\n수리비 인하 및 수리수량 감소 노력\n동중국 상해 추가 및 태국지역 방콕 & 람차방 구분으로\n집중 관리지역 총 10권역으로 확대 관리\n화물 증감 및 수리비 감면 비율 등에 따라 수리비 변화 영향,\n지속 관리를 통하여 사업목표 남성(-11%) & 동영(-5%) 달성 노력\n월평균 수리비(24년 1~2월 기준)\n23년 전체 월평균 수리비 대비 태국 일부 증가하였으나\n중국 주요지역 상해/셔코우/청도 감소\n일본지역 남성 & 동영 모두 수리비 총액기준 관리 중에 있으며\n수리총액 및 단가 전년 월평균 대비 감소\n23년 대비 24년 1~2월 평균 수리비\n남성해운 USD11,140/월 → USD8,533\n& 동영해운 USD5,223/월 → USD2,611/월'}, {'rsp_type': 'TB', 'rsp_tit': '10개 주요 권역의 건조선박 M&R 예산 및 평균 수리 비용', 'rsp_data': {'head': '※ Dry cargo - M&amp;R Budget management - Average repair cost per Van - Icon 5437 Owner cost only||||||||||||||||||||', 'body': 'Sq.||RHQ||Location||NS||||||||DY||||||^||||||2022||2023||2024||||2022||2023||2024||^||||||||||Target||%||||||Target||%^1||China\x0b(North)||CNTXG||20.9||23.0||21.9||-5%||24.7||20.6||19.5||-5%^2||||CNTAO||32.8||27.8||26.5||-5%||28.7||26.3||25.0||-5%^3||(East)||CNSHA||17.2||21.8||20.8||-5%||20.3||19.9||19.0||-5%^4||China\x0b(South)||HKHKG||46.9||38.8||37.0||-5%||43.6||40.3||36.3||-10%^5||||CNSHK||32.2||34.2||30.0||-12%||22.2||25.3||20.3||-20%^6||VN||VNSGN||7.5||6.9||6.8||-1%||||||||^7||||VNHPH||13.0||11.1||10.6||-5%||9.9||8.3||7.9||-5%^8||TH||THBKK||30.1||24.4||23.3||-5%||||||||^9||||THLCH||19.0||33.4||25.2||-25%||||||||^10||SG||SGSIN||60.8||44.6||35.9||-20%||||||||^10개 주요 권역 누계||||||17.4||18.2||16.2||-11%||12.5||12.8||12.1||-5%'}}], 'chunk_id': 775}, {'rsp_tit': '5번째 검색데이터: [신성장전략실] 신성장실현팀장 > 거점/운송인프라 (출처:남성해운_팀별 주간회의_W47_231121.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '해상+육상운송 연계 활성화\n(11월 진행사항)\n* 영업목적 CY – Door term 연계 통한 서비스 확대\n당사 or 운송사 미사용 업체 사용 유도 통한 물동량 확대 / 신규화주 유치\nA : 연계 진행업체\nB : 연계 진행 검토, 또는 미정\nC : 연계 부정적 업체(관심 X)'}, {'rsp_type': 'TB', 'rsp_tit': '투더블유로직스, 해외 물류 파트너십 확대 추진 중', 'rsp_data': {'head': '신성장실현팀||투더블유로직스||||', 'body': '||논의내용||주요진행구간||진행가능성^온누리로지스틱스||우수선화주선정사로 양사간 협업 통한 사례확보 및 미주,유럽에 편중된 지역에 대한 탈피/확보차원 협력 예정 -&gt; 부산출항분이긴 하나 미진행 건이던 부산-&gt;South Manila 소량 진행(11월 22일) 40’X1||미주,유럽 main 북중국,동중국 등 해외파트너사 nomi건||B(현지 노미건 물량에 따라 연계 가능물량이 차이 날 것으로 보임)^로지스틱스 파트너즈||인천-신강향 차량 수출로 컨택, 작업지 등 이슈 등 변수는 남아있음. 운송사 연계 등에 대한 큰 거부감은 없는 상황||중국향 위주(소량 진행 중)||B(진행가능성은 높으나 소량 물량 + 인천-신강 구간 40’제한 등 변수 존재)^이허브에스티||한국발 냉동위주 소량 당사 진행 중으로 운임 경쟁력 확보 위해 비용 절감 부분에 관심 많음. 운임수준은 대부분 하향세인 상황서 운송료 연계로 향후 경쟁력 확보에 목표||부산-홍콩,마카오,베트남 등||B(인천보단 부산위주 진행 중, 향후 부산확장 계획 등 공유 완료)^카고솔루션||이전 엠트랜스 영업부장이던 박래천 부장 이직으로 연결, 신규업체 마음으로 최근 영업 진행 중, 당사 인프라에 대한 소개 연계 할 수 있게 협조요청||인천-&gt;싱가포르 진행||A(door term은 아니지만 11월 선적분에 대해 투더블유 운송사 사용 잠정 확정) 40’x4 선적+운송 확정 향후 door term 확대 검토^밸류링크유||디지털포워딩 활용한 인천발 door 연계 지속 검토||인천-&gt;하이퐁||A(인천-하이퐁 태웅식품 진행 확정(40’x1))^뉴웨이브로지스틱스||투더블유와 인연있는 대표님 통해 조만간 진행건 투더블유 연계 검토||check||A(11월 부킹 접수 예정)^스타콩코드||부산물량 메인, 인천물량은 소량이지만 적극적으로 검토하기로(황선아지점장)||||B(조만간 진행 가능할 것으로 기대 중)^나오스월드||최근 라오스착/발 화물에 대해 확대 거래 중인 상황서 현지 door term 진행 중인 상황, 향후 한국까지 Door term 확대에 대해 검토/노력하자는 당사 의도 전달||한국 – 라오스(태국) 한국-몽골(신강)||B(한국 운송은 아직 진행되지 않았으나, 인천발 라오스 진행시는 최대한 투더블유 Try 압박 예정)^카스해운||플렉시설치 및 ISO TNK 주요 진행업체로 일부 플렉시 설치에 대한 야드 및 운송연계 활용 가능여부에 대한 논의||한국-동남아||B(서비스 중인 고객사들이 대부분 운송사 지정하고 있는 경우가 많음, 설치 작업의 경우 대부분 남항에서 이뤄지고 있음, 향후 신항 병행작업에 대한 검토)'}}], 'chunk_id': 1839}]
(InferenceActor pid=591) 메시지 저장 직후 chunk_id 확인 :  chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='공 컨테이너 이송 전략', additional_kwargs={'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={}), AIMessage(content='## 남성해운 공 컨테이너 이송 전략 보고서\n\n### 1. 서론\n\n본 보고서는 남성해운의 공 컨테이너(Empty Container, E/P) 이송 전략에 대한 분석 내용을 담고 있습니다. 내부 자료 검토를 통해 현재 추진 중인 전략, 주요 개선 과제, 그리고 협력 방안 등을 종합적으로 제시합니다. 컨테이너 보유량 통제와 효율적인 재배치를 통해 장비 운영 비용을 절감하고 서비스 경쟁력을 강화하는 데 초점을 맞추었습니다.\n\n### 2. 공 컨테이너 이송 전략의 핵심 목표\n\n남성해운의 공 컨테이너 이송 전략은 다음과 같은 핵심 목표를 달성하는 데 주력하고 있습니다.\n\n*   **장비 회전율 제고**: E/P 계획 및 장비 재배치를 통해 컨테이너 회전율을 높이는 것을 최우선 과제로 삼고 있습니다.\n*   **적체 지역 해소**: 동남아시아 및 일본 등 장비 적체 지역을 중심으로 집중적인 관리 및 개선 노력을 기울이고 있습니다.\n*   **수요 지역 적시 공급**: 화물 부킹 현황을 기반으로 컨테이너 수요 지역에 필요한 장비를 적시에 공급하여, 고객 만족도를 높이고 있습니다.\n*   **비용 절감**: 장비 재배치 최적화, ONE-WAY 장비 활용, 운송 모드 다변화 등을 통해 컨테이너 이송 비용을 절감합니다.\n\n### 3. 주요 추진 과제 및 실행 계획\n\n남성해운은 위에서 제시된 목표를 달성하기 위해 다음과 같은 주요 추진 과제 및 실행 계획을 수립하여 진행하고 있습니다.\n\n*   **일본 주요 장비 적체 지역 관리**:\n    *   일본 주요 장비 적체 지역(JPTYO/JPOSA/JPKUH/JPSGM/JPSMZ/JPTMK 등)을 지속적으로 모니터링하고, 영업/일본 법인과 현황을 공유하며 협력합니다.\n    *   1분기에 JP발 한국착 20DC 4,262대, 40HC 739대가 적체된 사례를 바탕으로, 적체 원인을 분석하고 개선 방안을 마련합니다.\n*   **중국 E/P 공급 확대**:\n    *   운항/영업 부서와의 협력을 통해 중국 E/P 공급을 확대합니다.\n    *   NTP/NCK/NCQ 항로를 활용한 중국향 Direct E/P 운영, NCQ(NSEP2403W)/NCJ(NSTC2401W) 스페셜 JPSBS 기항, 북중국(대련/천진) E/P 운영 등이 포함됩니다.\n*   **동남아시아 지역 장비 관리**:\n    *   동남아시아 지역(포트켈랑 일평균 재고 40HC 776대)의 장기 적체 장비 관리를 강화하고 개선합니다.\n    *   잉여 장비를 지속적으로 E/P 진행하여 회전율을 제고하고, 적체 해소를 위한 노력을 지속합니다.\n*   **대량 화물 부킹 정보 공유**:\n    *   대량 화물 부킹 정보를 공유하여 적체 지역 장비 해소에 활용합니다.\n    *   국내 장비 수급 상황 및 회전율을 고려하여 물량을 조절하고, 효율적인 장비 배치를 통해 비용을 절감합니다.\n*   **장기적체 현황 확인 및 ICON+ 활용**:\n    *   국내외 장기적체 현황을 매월 1회 확인하고 개선 노력을 기울입니다.\n    *   ICON+(5437)을 활용하여 매월 현황을 분석하고 특이 사항을 지속적으로 확인합니다.\n\n### 4. 멀티모달 운송 환경에서의 Mvmt Status 코드 표준화\n\n컨테이너 관리팀은 멀티모달 비즈니스에 적합한 컨테이너 이동 상태(Mvmt Status) 코드 표준안 개선을 추진하고 있습니다.\n\n*   **문제점**: Ocean 구간 이외의 운송 방식별 Mvmt Status가 모호하여, 각 운송 방식별 서비스 지역의 컨테이너 이동 현황을 정확하게 관리하기 어렵습니다.\n*   **개선 방안**:\n    *   운송 방식별 Mvmt Status에 맞는 코드 로직을 재정의하고 신규 코드를 생성합니다.\n    *   Barge, Rail, Truck 등 다양한 운송 방식에 대한 새로운 Mvmt 코드를 정의합니다.\n    *   새로운 Mvmt 코드를 기반으로 Dem/Det daily batch 계산 로직을 적용하여 시스템 운영 효율성을 높입니다.\n\n### 5. 다양한 업체와의 협력 강화\n\n신성장실현팀은 해상+육상운송 연계 활성화를 위해 다양한 업체와 협력하고 있습니다.\n\n*   **온누리로지스틱스**: 미주, 유럽 중심 물동량을 북중국, 동중국 등으로 확대하기 위한 협력 추진\n*   **로지스틱스 파트너즈**: 인천-신강향 차량 수출 컨택을 통한 중국향 물량 연계 검토\n*   **이허브에스티**: 부산-홍콩, 마카오, 베트남 등 한국발 냉동물량 연계 진행\n*   **카고솔루션**: 투더블유 운송사 활용, 인천-싱가포르 물량 연계 확정\n*   **밸류링크유**: 디지털 포워딩 활용 인천발 door 연계 지속 검토, 인천-하이퐁 태웅식품 물량 연계 확정\n*   **뉴웨이브로지스틱스**: 투더블유와 연계된 물량 연계 검토 예정\n*   **스타콩코드**: 부산 물량 메인, 인천 물량 소량 적극 검토\n*   **나오스월드**: 한국까지 Door term 확대 검토\n*   **카스해운**: 플렉시 설치 및 ISO TNK 주요 진행업체로서 야드 및 운송 연계 활용 가능성에 대한 논의 진행\n\n### 6. 결론 및 제언\n\n남성해운은 컨테이너 운영 개선 및 비용 절감을 위한 다양한 전략과 실행 계획을 추진하고 있습니다. 특히 장비 회전율 제고, 적체 지역 해소, 수요 지역 적시 공급, 멀티모달 환경에서의 Mvmt Status 코드 표준화, 그리고 다양한 업체와의 협력 강화를 통해 효율적인 공 컨테이너 이송 시스템을 구축하고 있습니다.\n\n향후 지속적인 모니터링과 데이터 분석을 통해 개선점을 발굴하고, 변화하는 시장 환경에 유연하게 대응하여 경쟁 우위를 확보하는 것이 중요합니다.\n\n---\n\n**출처**:\n\n*   [운영혁신본부] 전사공통 중점 추진과제 1분기 경과 공유회 발표자료.pptx\n*   [남성해운_팀별 주간회의_W45_231107.pptx\n*   [남성해운] 24년 2사분기 수정사업계획 및 핵심추진과제 진행경과 공유회_20240404.pptx\n*   남성해운_팀별 주간회의_W47_231121.pptx\n', additional_kwargs={'chunk_ids': [916, 920, 1813, 775, 1839], 'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={})]) return_messages=True
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 대답
(InferenceActor pid=591) [STREAM] error in partial streaming => 'str' object has no attribute 'get'
(InferenceActor pid=591) [STREAM] close_sse_queue => removing SSE queue for request_id=5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [STREAM] close_sse_queue => no SSE queue found for 5513e85e-164c-422f-9c3e-19c3d67b7335
(InferenceActor pid=591) [2025-03-20 08:37:53] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:53] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:53] INFO tracking.py:11: Entering process_format_to_response()
(InferenceActor pid=591) [2025-03-20 08:37:53] INFO tracking.py:11: Entering error_format()
(InferenceActor pid=591) [2025-03-20 08:37:53] INFO tracking.py:15: Exiting error_format() -- Elapsed: 0.00s
[DEBUG] SSE closed.
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:37:55,955 default_inference 1zebleoo b0a53284-d8b8-46fe-9b51-5c4894cf07c3 -- CALL close_sse_queue OK 2.2ms
(InferenceActor pid=591) ---------------- chunk_id 찾기 :  [{'rsp_tit': '1번째 검색데이터: [신성장전략실] 신성장실현팀 > 비대면영업채널확대 (출처:남성해운_팀별 주간회의_W9_240227.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '디지털포워더 & 플랫폼\n(비대면영업채널확대)'}, {'rsp_type': 'TB', 'rsp_tit': '파트너사 협력으로 해상 운송 효율성 증대 및 Bkg 유입 확대 추진 중', 'rsp_data': {'head': '파트너사||추진 사항||’24년 진행 현황', 'body': '[신규] 포스코플로우||연근해 지역 우선순위 전략적 파트너 선사로 협업 각 파트너사로부터 월간 약 30 Teu ↑ Bkg 유입 목표 (특히, 북중국향 및 싱/말 등 우리사 필요지역) 스케쥴 및 해상운임 제공 온라인마케팅 채널 활용 (NS 브랜드 노출/홍보)||[2/7, 수] 간담회 참석 (포워더 및 선사) [2/23, 금] 컨테이너섹션 과 ‘플로우멤버스’ 협업안 논의 개시 - 포스코플로우 멤버사用 S/C 제공 및 선복 운영안, 필요 구간 등 - 예일GLS ‘코일포터’ (기존 ‘목재’ 쇼링 대체재) 활용 검토키로 → 3/8일 후속 미팅^[진행 중] 판토스NOW||||[1/8, 월] 판토스NOW 플랫폼 정식 런칭 → 오픈 이후 오류/이슈사항 개선 중 으로 확인 [2월 현재] 서비스 프로모션/마케팅 진행 中 → 우리사로 유입 기대 - 1분기 적용 S/C 및 선복운영안 유효 하나 실 Bkg 유입은 가시적으로 ‘없음’ - 2분기 예상 Bkg 수준 재확인 및 운임, 선복운영안 전달 예정^[진행 중] 쉽다||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 (KCC 등) - 중국발 위주 월간 약 20~30 Teu ‘수입’ Bkg 유입 중 → 우리사 필요지역인 싱/말/인니발 유치 확대 Try (수입영업팀 공조)^[진행 중] 서프컴퍼니||||[2/20, 화] 북중국향 포워더 대상 이벤트성 프로모션 수행 검토 - 국제물류주선업 라이센스 미취득 → ‘중개자‘ 역할로써 마케팅 수행 - CY~Door 포함 남성해운 서비스를 플랫폼/채널 통한 홍보, 영업지원키로^[진행 중] 밸류링크유||||[정기] 스케쥴 및 월간 해상운임 안내 및 Spot 성 비딩 건 등 협업 - 평택발 하이퐁착 월간 약 10~30Teu ‘냉동화물’ 수출 지속 (‘23년 $71,000불)^[유지] 지비티에스||||[정기] 스케쥴 및 월간 해상운임 안내 Bkg 유입 미미 → ’24년 1월 부 자체 포워더팀 신설 및 영업 진행 중 ※ 모기업이 관세사(베스트관세사) 로 20년차 업력 → 19년 부 플랫폼사업 진출'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '‘21년 부\n‘21년 부\n‘22년 부\n‘22년 부\n‘24년 부\n‘23년 부\n‘22년\n‘23년\n‘24년\n‘21년 마켓 전환 → 대면영업 중요도↑\n우리사 역할 측면은 계속 지원하며 시도가능영역은 계속 Try (단, 팀의 Workforce/효율성 등 감안)\n디지털전환(DT) 요구 및 마켓 수요 증가 → 파트너사 확대/협업\n운영프로세스 구축(선복/SC) 및 API 기반 스케쥴 연동, Bkg 유입'}], 'chunk_id': 2057}, {'rsp_tit': '2번째 검색데이터: 우수 선화주기업 인증제도 현장평가 > 7. 차별화 서비스 제공현황 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '남성해운의 차별화 서비스는 이렇습니다!\n차별화 서비스 요약\n해운물류서비스\n디지털 연계\n- 물류 패러다임의 변화에 대응하여 다양한 디지털 기술의 융합/연계로 연결성을 강화하고,\n디지털기반 확장된 물류 생태계 구성원을 대상으로 기존의 logistic Provider와 차별화 되는 경험을 제공 중'}, {'rsp_type': 'TB', 'rsp_tit': '해운물류 디지털화, 운임 경쟁력 강화, 아세안 내륙 운송 확대', 'rsp_data': {'head': '구분||차별화 서비스||세부 전략', 'body': '1||해운물류서비스 디지털 연계||DT로드맵 추진과제 수행^2||경쟁력 있는 운임 제공||거점/운송인프라 연결한 패키지딜^3||복합운송연계 서비스 계획||아세안지역 (캄보디아 등) 내륙개발^4||해외거점 터미널 확보||해외지역 운송, 창고 등 J/V 추진^5||피더 네트워크 확보||일본, 중국, 인니 등 소규모 항구개발^6||친환경, 고효율 선박 확충||해양진흥공사 등 정책지원사업 참여'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '상세 내용\nDT 추진과제 및 로드맵을 통해서\nDT 가치체계로 인한 변화의 모습은 이와 같으며\n지속적인 투자, 조직대응수준 강화로\n차별적 서비스 제공\n전면 재편된 e-Service 및 플랫폼 파트너사,\n디지털 포워더사와 협업 진행 중\n확장된 물류 생태계 내\n디지털 가치 전파와 저변 확대를 위한 선도적 역할\n디지털 혁신 비전 선포 (Digitalized Logistics to Empower your Experience)\n로드맵을 통한 Enabler 도출 및 시행 중'}], 'chunk_id': 879}, {'rsp_tit': '3번째 검색데이터: Huangpu terminal 2023_page15 (출처:Huangpu terminal 2023)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '第 1 页 共 14 页 GCT-BDD-2023-A-5 (外贸) 外贸贸轮港口作业协议 [ GCT-X-23-90070 ] 甲方：南星海运林式会社 乙方：广州港股份有限公司 八方：广州集装箱码头有限公司 甲、乙、八三方依照中华人民共和国有关法律、法规，在平等互利的 基础上，经友好协商，就甲方在广州港新港港区经宣集装箱贸轮运输 的有关事项达成如下协议： 一、甲方在广州港集国码头作业的集装箱贸轮航线必须取得中华 人民共和国交通部的核准许可，其所属集装箱贸轮依协议约定著沿广 州港码头开展正常的普运活动。乙方经与甲方协商安排甲方集装箱贸 轮航线在八方著沿作业，八方受甲方委托进行集装箱船船的停著、装 细、维存以及其他作业。 甲方指定广州港中联国际船务代理有限公司为其船船代理，并书 面告知乙方、八方其他代理权限。在此权限内，乙方、八方在今后的操作中，可无需事先知照甲方，而遭照来自其指定代理的指引、要求、 通知等进行操作。甲方有权对代理及代理权限进行变更，但需提前一个月书面通知乙方、八方，并得到乙方、八方的确认。否则因此产生 的损失及费用，乙方、八方不予负责。甲方及其代理需提供运营许可证明的资料复印作，包括企业法人普业执照、组织机构代码证、税务 登记证等，一般纳税人资格证（加盖公章）以及船船代理资质证明等 。 乙方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、八方的质责，当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，应当与甲方、当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、八方的责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、八方的质责，当与甲方、当乏方的质责，当与甲方、当乏方的责，当与甲方、当方、当方的质责，当与甲方、当方的质责，当与甲方、当方、当方的质责，当与甲方、当方的责，当与甲方、当方的责，当与甲方、当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的责，当方的'}], 'chunk_id': 3005}, {'rsp_tit': '4번째 검색데이터: 20230731155302_GNE 계약서_page2 (출처:20230731155302_GNE 계약서)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': "CONTENTS Article Heading Page 1. APPOINTMENT .....................................................................................................................3 2. DUE CARE.............................................................................................................................3 3. AGENT'S ROLES AND FUNCTIONS....................................................................................3 (a). HUSBANDING..........................................................................................................3 (b). MARKETING, CARGO BOOKING AND OPERATION...........................................4 (c). EQUIPMENT CONTROL .........................................................................................5 (d). RISKSAND CLAIMS MANAGEMENT.....................................................................6 (e). DOCUMENTA TION AND CUSTOMER SERVICE...................................................6 (f). INFORMATION........................................................................................................6 (g). CLAIMS...................................................................................................................7 (h). STAFF AND RESOURCES. .......................................................................................7 4. BILL OF LADING ..................................................................................................7 5. RELEASING OF CARGOES ..................................................................................7 6. ACCOUNTING.......................................................................................................8 (a). COLLECTION OF FREIGHT..................................................................................8 (b). DISBURSEMENTS....................................................................................................8 (c). REMITTANCE OF FUNDS.........................................................................................9 (d). ACCOUNTING INSTRUCTIONS...............................................................................9 (e). FOREIGN EXCHANGE REGULA TION.....................................................................9 7. MONIES AND FUNDS RECEIVED BY THE AGENT...........................................................9 8. THIRD PARTY SERVICE PROVIDERS..................................................................................9 9. OFFICES AND SUB-AGENTS .............................................................................................10 10. REMUNERATION................................................................................................................10 11. DISBURESMENT..................................................................................................................10 12. COSTS AND EXPENSES........................................................................................................10 13. ASSIGNMENT.........................................................................................................................11 14. CHANGE OF THE AGENT'S STRUCTURE ........................................................................11 15. DEFAULT ...............................................................................................................................11 16. THE AGENT'S DUTIES AFTER TERMINATION.................................................................12 17. INDEMNITY...........................................................................................................................12 18. FORCE MAJEURE ................................................................................................................12 19. CONFIDENTIALITY..............................................................................................................12 20. COUNTERPARTS ..................................................................................................................13 21. GOVERNING LAW AND ARBITRATION..........................................................................13 22. EFFECTIVE DATE................................................................................................................13 Appendix I: COMPENSATIONS........................................................................................................................................14 2"}], 'chunk_id': 2434}, {'rsp_tit': '5번째 검색데이터: 우수 선화주기업 인증제도 현장평가 > 1. 회사 소개 (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '주요 연혁\n● 남성해운은 1953년 8월 대한민국 최초 민간 외항선사로, 약 70년간 해운업을 영위하였으며,\n 現, 18척의 국적 자사선과 용선 3척 총 29,739 TEU의 선복량을 보유하였으며,\n 한중일 외 베트남, 싱가포르, 인도네시아 등 총 64 개 기항지에 서비스를 제공\n대한민국 최초 한-일 부정기항로 개설로 외국항행 개시\n한-일 컨테이너 정기항로 취항/ 피더 컨테이너 서비스 개시\n남성해운㈜ 설립\n한-중 항로(부산 – 대련/청도/상해) 개설\n한-동남아 항로(홍콩/셔코우 직기항) 개설\n한-베트남 항로(인천 – 홍콩 - 하이퐁 – 셔코우) 개설\n홍콩 현지 법인 설립\n홍콩-베트남(호치민)-태국(방콕/람차방) 삼국간 항로 개설\n전사 Process Innovation (프로세스, IT 및 조직 혁신)\n중국 멀티모달(Sea+Rail) 본격 개시\n베트남 현지 법인 설립\n우수선화주인증 1등급 획득, 호치민 Depot 및 IGDC 물류거점 확보\n우수 선화주기업 상생협력 우수사례 최우수 수상\n태국 방콕 Depot/CFS 물류거점 확보\n인도네시아(자카르타) 서비스 개시\n국내 자영운송사 및 싱가포르/ 말레이시아 서비스 개시\n자사선 선대 현황'}, {'rsp_type': 'TB', 'rsp_tit': '컨테이너선 정보: 선박명, 용량, 인도일, 항로, 서비스명', 'rsp_data': {'head': '||선명||TEU||인도일||항로||서비스명', 'body': '1||STAR CLIPPER||962||2010.03||한중일||PD2^2||STAR SKIPPER||962||2010.06||한중일||BKH^3||STAR PIONEER||953||2010.08||한중일||PD2^4||STAR EXPRESS||953||2010.10||한중일||NTP^5||STARSHIP LEO||1,891||2013.02||동남아||KHP^6||STARSHIP URSA||1,891||2013.02||동남아||KVT^7||STARSHIP PEGASUS||1,891||2013.03||동남아||VTX^8||STAR CHALLENGER||1,003||2016.02||한중일||BJ1^9||STAR VOYAGER||1,003||2016.04||한중일||NSP^10||STARSHIP TAURUS||1,614||2017.07||동남아||NTX^11||STARSHIP AQUILA||1,614||2017.10||동남아||NKT^12||STAR EXPLORER||1,011||2020.06||동남아||BIH^13||STAR FRONTIER||1,011||2020.07||동남아||IHS^14||STAR CHASER||963||2021.12||한일||NTP^15||STAR RANGER||963||2022.02||한중일||PD1^16||STARSHIP DRACO||1,607||2022.11||동남아||KMV^17||STARSHIP JUPITER||2,548||2023.06||동남아||ANX^18||STARSHIP NEPTUNE||2,548||2023.10||동남아||KCI'}}, {'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '```\n23년 11월 2일 기준\n```'}], 'chunk_id': 866}]
(InferenceActor pid=591) 메시지 저장 직후 chunk_id 확인 :  chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='남성해운의 새로운 전략', additional_kwargs={'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={}), AIMessage(content='## 남성해운의 새로운 전략 상세 분석 보고서\n\n### 1. 서론\n\n본 보고서는 내부 자료를 바탕으로 남성해운의 새로운 전략에 대해 상세히 분석합니다. 남성해운은 급변하는 시장 환경에 적응하고 경쟁력을 강화하기 위해 디지털 전환(DT)을 중심으로 한 다양한 전략을 추진하고 있습니다. 본 보고서에서는 이러한 전략들을 심층적으로 검토하고, 각 전략의 목표와 핵심 내용을 분석합니다.\n\n### 2. 디지털 전환(DT) 및 비대면 영업 채널 확대 전략\n\n남성해운은 디지털 전환(DT) 요구와 마켓 수요 증가에 발맞춰 **비대면 영업 채널 확대를 핵심 전략으로 추진**하고 있습니다. 이는 디지털 기술을 활용하여 물류 패러다임을 변화시키고, 확장된 물류 생태계 구성원들에게 차별화된 경험을 제공하는 것을 목표로 합니다[^1].\n\n- **파트너사 협력 강화**: 포스코플로우, 판토스NOW, 쉽다, 서프컴퍼니, 밸류링크유, 지비티에스 등 다양한 파트너사와 협력하고 있으며, 특히 포스코플로우와는 연근해 지역을 중심으로 전략적 파트너십을 구축하고 있습니다. 파트너사별 협력 목표는 월간 약 30 TEU 이상의 Bkg 유입입니다[^2].\n- **플랫폼 활용**: 판토스NOW 플랫폼 런칭, 쉽다와의 중국발 수입 Bkg 유치, 서프컴퍼니를 통한 북중국향 포워더 대상 프로모션 등 **플랫폼을 적극 활용**하여 영업을 확대하고 있습니다.\n- **자체 포워더팀 신설**: Bkg 유입이 미미한 지비티에스의 경우, 자체 포워더팀을 신설하여 영업을 진행하는 등 **적극적인 자체 영업 역량 강화**를 추진하고 있습니다[^2].\n- **e-Service 및 디지털 포워더사 협업**: 남성해운은 e-Service 및 플랫폼 파트너사, 디지털 포워더사와 협업하며 디지털 기반의 물류 서비스를 강화하고 있습니다[^1].\n\n### 3. Extended Logistics를 통한 사업 영역 확장 전략\n\n남성해운은 기존의 컨테이너 운송업 중심에서 벗어나 **Extended Logistics를 추진**하며 사업 영역을 확장하고 있습니다. 이는 "Beyond Shipping, Engineering the future"라는 새로운 슬로건 아래, 해상운송에서 육상운송까지 서비스를 확대하는 것을 의미합니다[^5].\n\n- **Port to Port 서비스 확장**: 기존 Port to Port 서비스의 운영 구조 혁신을 통해 성장 동력을 확보하고, 이를 기반으로 Extended Logistics Service로 확장하고 있습니다.\n- **신규 사업 진출**: 컨테이너 운송업 외에도 제3자 물동량 처리, 배후부지/Depot/운송사 자영화 및 지분 투자 등 연관 타 업종으로의 확장을 추진하고 있습니다[^5].\n- **수익성 개선 및 신규 시장 진출**: 기존 노선 합리화를 통해 수익성을 개선하고, 신규 노선 개설을 통해 신규 지역 및 복합 운송 집중 지역으로 진출하고 있습니다[^5].\n\n### 4. 차별화된 서비스 제공 전략\n\n남성해운은 경쟁사와의 차별화를 위해 다음과 같은 전략들을 추진하고 있습니다[^1].\n\n- **경쟁력 있는 운임 제공**: 고객에게 경쟁력 있는 운임을 제공하여 가격 경쟁력을 확보합니다.\n- **아세안 지역 내륙 개발**: 아세안 지역 내륙 개발을 통해 복합 운송 연계 서비스를 제공하고 물류 네트워크를 확장합니다.\n- **해외 거점 터미널 확보**: 해외 거점 터미널을 확보하여 글로벌 물류 경쟁력을 강화합니다.\n- **소규모 항구 개발**: 일본, 중국, 인도 등 소규모 항구 개발을 통해 피더 네트워크를 확보하고 서비스 범위를 확대합니다.\n- **친환경 고효율 선박 확충**: 친환경 고효율 선박을 확충하여 지속 가능한 물류 시스템을 구축합니다.\n\n### 5. 운영 효율성 및 고객 경험 혁신 전략\n\n남성해운은 4차 산업혁명 기술을 활용하여 운영 효율성을 극대화하고 고객 경험을 혁신하고자 합니다[^5].\n\n- **기술 선도**: 4차 산업혁명 기술을 활용한 혁신을 통해 물류 프로세스를 자동화하고 효율성을 높입니다.\n- **조직 혁신**: 기술 선도와 함께 조직 혁신을 추진하여 변화에 빠르게 대응할 수 있는 유연한 조직 체계를 구축합니다.\n- **인력 역량 강화**: 기존 인력에게 New Trend/New Society에 맞는 역량 교육을 지원하여 고객 혁신 및 운영 효율성 극대화를 도모합니다.\n- **새로운 계약체계 구축**: Huangpu terminal과의 계약에서 보여지듯이, 남성해운은 새로운 항로 개설 시 20일 전 사전 통보, 월간 일정 제공, 세부 화물 정보 제공 등의 계약 내용을 통해 터미널 운영자와의 긴밀한 협력을 도모하고 있습니다[^3].\n\n### 6. 결론\n\n남성해운은 디지털 전환(DT), Extended Logistics, 차별화된 서비스 제공, 운영 효율성 및 고객 경험 혁신을 핵심 전략으로 삼아 급변하는 물류 시장에서 지속적인 성장 동력을 확보하고자 노력하고 있습니다. 이러한 전략들은 남성해운이 단순한 해운 기업을 넘어 고객에게 최적의 물류 솔루션을 제공하는 종합 물류 기업으로 도약하는 데 기여할 것으로 예상됩니다.\n\n---\n\n**출처:**\n\n*   남성해운_팀별 주간회의_W9_240227.pptx[^2]\n*   [남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx[^1, ^5]\n*   Huangpu terminal 2023[^3]\n*   20230731155302_GNE 계약서[^4]\n\n---\n**각주:**\n\n[^1]: 남성해운은 디지털 기술을 활용하여 물류 패러다임을 변화시키고, 디지털 기반 확장된 물류 생태계 구성원들에게 차별화된 경험을 제공하는 데 중점을 두고 있습니다. (출처: [남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)\n[^2]: 남성해운은 포스코플로우와 연근해 지역 우선순위 전략적 파트너로서 협업하고 있으며, 각 파트너사로부터 월간 약 30 TEU 이상의 Bkg 유입을 목표로 하고 있습니다. (출처: 남성해운_팀별 주간회의_W9_240227.pptx)\n[^3]: 남성해운은 Huangpu terminal에 새로운 항로를 20일 전에 통보해야 하며, 월간 일정 및 세부 화물 정보를 제공해야 합니다. (출처: Huangpu terminal 2023)\n[^4]: 남성해운은 계약을 통해 에이전트에게 선박의 접안, 통관, 입국 관리, 예인 등의 서비스를 부탁하고 있습니다. (출처: 20230731155302_GNE 계약서)\n[^5]: 남성해운은 20년 동안 “Beyond Shipping, Engineering the future”라는 새로운 슬로건을 내세우며 기존의 Port to Port 서비스 강점을 바탕으로 해상운송에서 육상운송까지 서비스를 확대하는 Extended Logistics를 추진하고 있습니다. (출처:[남성해운] 우수선화주기업 인증제도 현장평가 참조자료_20231103.pptx)', additional_kwargs={'chunk_ids': [2057, 879, 3005, 2434, 866], 'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={})]) return_messages=True
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 대답
(InferenceActor pid=591) [STREAM] error in partial streaming => 'str' object has no attribute 'get'
(InferenceActor pid=591) [STREAM] close_sse_queue => removing SSE queue for request_id=5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) === [In-Flight Batching] Waiting for first item in request_queue... ===
(InferenceActor pid=591) [In-Flight Batching] Got the first request. Attempting to fill a batch...
(InferenceActor pid=591) [STREAM] close_sse_queue => no SSE queue found for 5f6eae2d-a83f-4086-9caf-73f27bff73f8
(InferenceActor pid=591) [In-Flight Batching] Timeout reached => proceeding with the batch.
(InferenceActor pid=591) [DEBUG] _process_single_query 시작: 08:37:56, 요청 내용: {'request_id': '1742459818907-9433', 'http_query': {'qry_id': '1742459823644-1834', 'user_id': 'user123', 'page_id': '1742459818907-9433', 'auth_class': 'admin', 'qry_contents': '디지털 기획팀의 우선과제가 어떻게 돼?', 'qry_time': '2025-03-20T08:37:03.644Z'}}, 현재 스레드: AsyncIO Thread: default
(InferenceActor pid=591) [STREAM] _process_single_query: request_id=1742459818907-9433
(InferenceActor pid=591) [DEBUG] Creating new CustomConversationBufferMemory for session=1742459818907-9433
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, 사용자 입력 질문: 12, 총합: 12
(InferenceActor pid=591) Using cached data
(InferenceActor pid=591)    ... calling query_sort() ...
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:56 [async_llm.py:204] Added request 16502d35-2501-40fa-b754-ccda7284bf6b.
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO tracking.py:11: Entering process_format_to_response()
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO tracking.py:11: Entering error_format()
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO tracking.py:15: Exiting error_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO debug_tracking.py:12: 배치 처리 후 상태 - Process Memory: RSS=1838.85 MB, VMS=36637.11 MB
(InferenceActor pid=591) [2025-03-20 08:37:55] INFO debug_tracking.py:13: 배치 처리 후 상태 - GPU Memory: allocated=0.00 MB, reserved=0.00 MB
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO debug_tracking.py:26: [Batch Tracking] Batch size: 1, Token counts: [0]
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO debug_tracking.py:12: 배치 처리 전 상태 - Process Memory: RSS=1838.85 MB, VMS=36637.11 MB
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO debug_tracking.py:13: 배치 처리 전 상태 - GPU Memory: allocated=0.00 MB, reserved=0.00 MB
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:11: Entering load_data()
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:15: Exiting load_data() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:11: Entering query_sort()
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:15: Exiting query_sort() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:56] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>디지털 기획팀의 현재 우선 과제를 알려줘<query>
(InferenceActor pid=591) <keyword/>디지털 기획팀, 우선 과제<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 디지털 기획팀의 현재 우선 과제를 알려줘, 키워드 : 디지털 기획팀, 우선 과제, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591)    ... query_sort => QU=디지털 기획팀의 현재 우선 과제를 알려줘, KE=디지털 기획팀, 우선 과제, TA=no, TI=1900-01-01:2099-01-01
(InferenceActor pid=591) [SOOWAN] TA is No, before make a retrieval
(InferenceActor pid=591) ##### query_sort is starting, attempt: 1 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:57 [async_llm.py:204] Added request b1d8091e-029c-44bc-aa3e-e9d5ad23af82.
(InferenceActor pid=591) [2025-03-20 08:37:57] INFO tracking.py:11: Entering specific_question()
(InferenceActor pid=591) [2025-03-20 08:37:57] INFO tracking.py:15: Exiting specific_question() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:37:57] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:57] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>디지털 기획팀의 우선 과제는 무엇인가?<query>
(InferenceActor pid=591) <keyword/>디지털 기획팀, 우선 과제</keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) [ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.
(InferenceActor pid=591) ##### query_sort is starting, attempt: 2 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:58 [async_llm.py:204] Added request e6256af6-8df5-4bbd-944f-46532c563e4b.
(InferenceActor pid=591) [2025-03-20 08:37:58] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:58] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>디지털 기획팀의 현재 우선 과제는 무엇인가?<query>
(InferenceActor pid=591) <keyword/>디지털 기획팀, 우선 과제</keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) [ERROR query_sort] 필요한 태그들이 누락되었습니다. 재시도합니다.
(InferenceActor pid=591) ##### query_sort is starting, attempt: 3 #####
(InferenceActor pid=591) [SOOWAN] collect_vllm_text 진입 PROMPT:
(InferenceActor pid=591) INFO 03-20 08:37:59 [async_llm.py:204] Added request f9f04edb-d906-487f-bd86-6ebbdc5de672.
(InferenceActor pid=591) [2025-03-20 08:37:59] INFO tracking.py:11: Entering collect_vllm_text()
(InferenceActor pid=591) [2025-03-20 08:37:59] INFO tracking.py:15: Exiting collect_vllm_text() -- Elapsed: 0.00s
(InferenceActor pid=591) [DEBUG query_sort] Generated answer:
(InferenceActor pid=591) <query/>디지털 기획팀의 현재 우선 과제를 알려줘<query>
(InferenceActor pid=591) <keyword/>디지털 기획팀, 우선 과제<keyword>
(InferenceActor pid=591) <table/>no<table>
(InferenceActor pid=591) <time/>all<time>
(InferenceActor pid=591)
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) 구체화 질문: 디지털 기획팀의 현재 우선 과제를 알려줘, 키워드 : 디지털 기획팀, 우선 과제, 테이블 필요 유무: no, 시간: 1900-01-01:2099-01-01
(InferenceActor pid=591) -------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(InferenceActor pid=591) [SOOWAN]: execute_rag : 진입
(InferenceActor pid=591) [SOOWAN]: execute_rag : 테이블 필요없음
(InferenceActor pid=591) [시간 범위] 전체 기간 사용
(InferenceActor pid=591) [RETRIEVE] 검색에 사용되는 문서 수: 3511
(InferenceActor pid=591) [SOOWAN] retrieve : 진입
(InferenceActor pid=591) [SOOWAN] cal_sim_score : 진입 / query :  디지털 기획팀, 우선 과제
(InferenceActor pid=591) [SOOWAN] embed: 진입
(InferenceActor pid=591) [SOOWAN] embed: 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V 생산 완료
(InferenceActor pid=591) [SOOWAN] cal_sim_score : query_V.shape == 1
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering execute_rag()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:15: Exiting execute_rag() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering expand_time_range_if_needed()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:15: Exiting expand_time_range_if_needed() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering retrieve()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO RAG.py:440: Retrieval for query: '디지털 기획팀, 우선 과제'
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO RAG.py:441: Available documents: 3511
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering cal_sim_score()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering embed()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:15: Exiting embed() -- Elapsed: 0.01s
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:15: Exiting cal_sim_score() -- Elapsed: 0.12s
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO RAG.py:445: Similarity score shape: (3511, 1, 1)
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO tracking.py:11: Entering cal_bm25_score()
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO RAG.py:557: Starting BM25 calculation for query: 디지털 기획팀, 우선 과제
(InferenceActor pid=591) [2025-03-20 08:38:00] INFO RAG.py:558: Document count: 3511
[2025-03-20 08:38:02] INFO _internal.py:97: 14.39.16.61 - - [20/Mar/2025 08:38:02] "POST /query_stream HTTP/1.1" 200 -
(InferenceActor pid=591) -------------자료 검색 성공--------------
(InferenceActor pid=591) ------- [{'file_name': '남성해운_팀별 주간회의_W36_20230905.pptx', 'title': '[신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '인프라 운영 합리화 측면,\n효율성 대비 초기 인프라 셋업 비용 부담\n및 그후 운영유지보수 비용 증가 리스크로\n인해 5년後 코어부분의 퍼블릭 클라우드\n전환 재고려\n우리만의 최적 인프라 운영 환경 구성\nHybrid Cloud + AWS 멀티 클라우드\n인프라 운영 전략 유지\n2] STORAGE SERVER E.O.S(24년 2월)\n3] E.O.S기간內 KT-IDC 적접 설치\n1] IBM 서버 E.O.S(24년 12월)\n4] KT-IDC 적접 설치後 E.O.S기간內\n안정화/ 테스트 수행後 전환\n수행 배경\n. ORACLE VER 11G(E.O.S) > 12C로 전환\n(신규 구매)\n. DATA 마이그레이션\n. SAP 재구성 및 DATA마이그레이션\n. ORACLE DR 구성\n. SAP DATA\n. Oracle Server Node1 / RAC 이중화\n. ICON+ DATA\n. Oracle Server Node2 / RAC /이중화\n. SAP ( NED , NEQ , NEP )\n. ORACLE 12C 설치로 인한 ICON+및\nESVC+ 검증 및 테스트(쿼리)\n. SAP ABAP인터페이스 데이터 검증\n및 SAP 운영 테스트'}], 'chunk_id': 1673}, {'file_name': '남성해운_팀별 주간회의_W36_20230905.pptx', 'title': '[신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'KT CLOUD/KT IDC+AWS 관리자\n사용자\nBrowser\nBrowser 운영 개발자\nCross Browser\nREST / HTML5\nMulti Device\nDevOps\nGIT 소스 통합 운영 관리\nCI-CD 자동 배포 관리\nAPM통한 안정적 서비스제공 프레임워크\n클라우드 연계\nHP GIT CI-CD\nKT 클라우드 WAS1\nICON E-SVC APS 1 WS 1 SSL 인증보안\nMSP LBS Data Backup Storage RDS\nWAS2 APS 2 WS 2 ICON E-SVC\nMSP 장교빌딩 Fax System File Server\nSVN DATA전용선 LINE G/W B\nAWS CLOUD KT IDC 운영 인프라 아키텍쳐 (AS IS )\nDB ICON (RAC) BACKUP STORAGE EAPI EMAS IOT\nDB NODE1 DB NODE2 DB SAP OLD GW\nSCALE DOWN SCALE UP A'}], 'chunk_id': 1674}, {'file_name': '남성해운_팀별 주간회의_W21_240521.pptx', 'title': '[신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n.급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 남성그룹 오더/배차 API 연계 구축을 위한 설계서 검토 및 요구사항 확정 with 유로지텍\n- API 연계 설계 - 라인운송 요청/취소 API 개발\n- 라인운송 요청관리 - 라인운송 오더 수신\n- 배차 정보 송신 - 배차 운임 정보 송신\n- API 연계 처리 테스트 남성그룹 육상운송연계 자동화 시스템 구축을 위한 ‘틀’ 마련\nwith 신성장실현팀\n. DOOR/CY + Ocean Service + CY/DOOR 경험 시스템內 디지털화 必\n. 비즈니스 디지털 거점 적용 전환 대상\n국내: TW로지스틱스 , 베트남: NS로지스틱스 ,태국: KSP로지스틱스\n홍콩: NB로지스틱스 , 중국 : 충칭 물류법인\n. 디지털 비즈니스 로직 요구사항\n육상 운송 오더(BKG) ,\n운임 Autorating 자동화,\n육상 배차 정보 관리(조회,등록,수행) , JOB ORDER\n24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 통한\n‘業’ 전문성 강화 A 배경 적극적 커뮤니케이션 채널 활성화 통한 ‘業’ 전문성 강화 必\n.컨테이너 IOT 장착을 통한\n맵 서비스 적용 및 Big-Data IFC연계\n.고객 서비스 차별화를 위한\nIOT장착 Auto-rating 적용 및\ne-Svc 비즈니스 적용\n.인도네시아 대리점 업무 향상을 위한\n지원(세관신고, e-DO , 인보이스..)\n.러시아 e-DO 서비스 및 지속적 터미널\nCODECE연계 ….\n.남성그룹 육상운송연계 자동화 시스템 ‘틀’ 구축을 위한 출항 A 수행 추진사항'}], 'chunk_id': 1308}, {'file_name': '남성해운_팀별 주간회의_W5_240130 (1).pptx', 'title': '[운영혁신본부] 운항관리팀장 > 주요업무 (핵심 추진과제 Trim 최적화 진행 현황 – DT 핵심항목)', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '주요지표항목\n▷ Trim 달성율\n▷ Consumption 달성율\n√ 기준값 대비 증감율 (기준값 = 100%)\n√ 소모량 감소 (100% 대비▲)\n소모량 증가 (100% ▼)\nDT 전환 구성도 (계획)\nWeek 5 / 2024.1.30\n향후 계획\n▷ 디지털운영팀 전산화 개발 협업\n√ 레드마인 (Redmine) 공유 접수 完\n▷ 정량화 분석\n√ 정기적 수작업 분석 및 시스템 안정화 (오류 최소화 작업)\n√ 마젤란마린과 분석 결과 공유 (문제점 파악, 진행 방향 미세 조정 등 미세 조정)'}], 'chunk_id': 1966}, {'file_name': '남성해운_팀별 주간회의_W20_240514.pptx', 'title': '[신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항', 'contents': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 e-Svc上 , 남성그룹 對고객 서비스 MAP서비스 사용 현황\n. 남성 > 밸류링크유 맵서비스 무료 사용 타선사 대비 서비스 경쟁력\n. 동영 > 트래이드링스 맵서비스 유료 사용 (연간 2400만원 지급)\n\x0b남성그룹(남성 & 동영 ) 비용합리화 도모 必\n. 동영해운 (이정근 본부장) : 요구사항 및 배경 의견 적극 동의 및 동참 P.O.C : 부산 소재 / 에코마린\n(AIS 정보 1위 업체 글로벌 스파이어 맵 서비스)\n. 요구사항 수렴 리스트 전달 및 남성/동영 인베디드 커스텀 서비스 개발中\n. 범위 : 남성/동영 300척 內\n 씨벤티지(연간 3800만 견적) , 트래이드링스(동영/연간 2400만:Vessel Tracking) 대비\n 서비스 유지보수 운영 및 비용 경쟁력 우위\n. 적용 : e-Svc 上 / Cargo Tracking , Vessel Tracking\n. 견적 비용 : 최초 1년 첫해 1800만(개발비 3백포함) / 2년째 부터 1600만\nA 배경 INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁 강화통한 비용 합리화 必\n. 홈페이지 라우트 서비스 동적 맵\n 서비스 통한 Self Service 체제\n 전환\n.e-Svc 上 , 對고객 서비스 가시성확보/활용성 증대위한\nAIS정보 통한 실시간 Map 트래킹 서비스 통합 전환 검토 中 수행\nA 추진사항'}], 'chunk_id': 1292}] -------
(InferenceActor pid=591) ---------------------------------------
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 리트리버
(InferenceActor pid=591) [SOOWAN] TA is No, and make a retrieval is successed
(InferenceActor pid=591) [STREAM] Starting partial generation for request_id=1742459818907-9433
(InferenceActor pid=591) [STREAM] _stream_partial_answer => request_id=1742459818907-9433, chart=None
(InferenceActor pid=591) [DEBUG] Prepared reference data: {"type": "reference", "status_code": 200, "result": "OK", "detail": "Reference data", "evt_time": "2025-03-20T08:38:02.964330", "data_list": [{"rsp_type": "R", "rsp_tit": "남성 내부 데이터", "rsp_data": [{"rsp_tit": "1번째 검색데이터: [신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고 (출처:남성해운_팀별 주간회의_W36_20230905.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "인프라 운영 합리화 측면,\n효율성 대비 초기 인프라 셋업 비용 부담\n및 그후 운영유지보수 비용 증가 리스크로\n인해 5년後 코어부분의 퍼블릭 클라우드\n전환 재고려\n우리만의 최적 인프라 운영 환경 구성\nHybrid Cloud + AWS 멀티 클라우드\n인프라 운영 전략 유지\n2] STORAGE SERVER E.O.S(24년 2월)\n3] E.O.S기간內 KT-IDC 적접 설치\n1] IBM 서버 E.O.S(24년 12월)\n4] KT-IDC 적접 설치後 E.O.S기간內\n안정화/ 테스트 수행後 전환\n수행 배경\n. ORACLE VER 11G(E.O.S) > 12C로 전환\n(신규 구매)\n. DATA 마이그레이션\n. SAP 재구성 및 DATA마이그레이션\n. ORACLE DR 구성\n. SAP DATA\n. Oracle Server Node1 / RAC 이중화\n. ICON+ DATA\n. Oracle Server Node2 / RAC /이중화\n. SAP ( NED , NEQ , NEP )\n. ORACLE 12C 설치로 인한 ICON+및\nESVC+ 검증 및 테스트(쿼리)\n. SAP ABAP인터페이스 데이터 검증\n및 SAP 운영 테스트"}], "chunk_id": 1673}, {"rsp_tit": "2번째 검색데이터: [신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고 (출처:남성해운_팀별 주간회의_W36_20230905.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "KT CLOUD/KT IDC+AWS 관리자\n사용자\nBrowser\nBrowser 운영 개발자\nCross Browser\nREST / HTML5\nMulti Device\nDevOps\nGIT 소스 통합 운영 관리\nCI-CD 자동 배포 관리\nAPM통한 안정적 서비스제공 프레임워크\n클라우드 연계\nHP GIT CI-CD\nKT 클라우드 WAS1\nICON E-SVC APS 1 WS 1 SSL 인증보안\nMSP LBS Data Backup Storage RDS\nWAS2 APS 2 WS 2 ICON E-SVC\nMSP 장교빌딩 Fax System File Server\nSVN DATA전용선 LINE G/W B\nAWS CLOUD KT IDC 운영 인프라 아키텍쳐 (AS IS )\nDB ICON (RAC) BACKUP STORAGE EAPI EMAS IOT\nDB NODE1 DB NODE2 DB SAP OLD GW\nSCALE DOWN SCALE UP A"}], "chunk_id": 1674}, {"rsp_tit": "3번째 검색데이터: [신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항 (출처:남성해운_팀별 주간회의_W21_240521.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n.급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 남성그룹 오더/배차 API 연계 구축을 위한 설계서 검토 및 요구사항 확정 with 유로지텍\n- API 연계 설계 - 라인운송 요청/취소 API 개발\n- 라인운송 요청관리 - 라인운송 오더 수신\n- 배차 정보 송신 - 배차 운임 정보 송신\n- API 연계 처리 테스트 남성그룹 육상운송연계 자동화 시스템 구축을 위한 ‘틀’ 마련\nwith 신성장실현팀\n. DOOR/CY + Ocean Service + CY/DOOR 경험 시스템內 디지털화 必\n. 비즈니스 디지털 거점 적용 전환 대상\n국내: TW로지스틱스 , 베트남: NS로지스틱스 ,태국: KSP로지스틱스\n홍콩: NB로지스틱스 , 중국 : 충칭 물류법인\n. 디지털 비즈니스 로직 요구사항\n육상 운송 오더(BKG) ,\n운임 Autorating 자동화,\n육상 배차 정보 관리(조회,등록,수행) , JOB ORDER\n24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 통한\n‘業’ 전문성 강화 A 배경 적극적 커뮤니케이션 채널 활성화 통한 ‘業’ 전문성 강화 必\n.컨테이너 IOT 장착을 통한\n맵 서비스 적용 및 Big-Data IFC연계\n.고객 서비스 차별화를 위한\nIOT장착 Auto-rating 적용 및\ne-Svc 비즈니스 적용\n.인도네시아 대리점 업무 향상을 위한\n지원(세관신고, e-DO , 인보이스..)\n.러시아 e-DO 서비스 및 지속적 터미널\nCODECE연계 ….\n.남성그룹 육상운송연계 자동화 시스템 ‘틀’ 구축을 위한 출항 A 수행 추진사항"}], "chunk_id": 1308}, {"rsp_tit": "4번째 검색데이터: [운영혁신본부] 운항관리팀장 > 주요업무 (핵심 추진과제 Trim 최적화 진행 현황 – DT 핵심항목) (출처:남성해운_팀별 주간회의_W5_240130 (1).pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "주요지표항목\n▷ Trim 달성율\n▷ Consumption 달성율\n√ 기준값 대비 증감율 (기준값 = 100%)\n√ 소모량 감소 (100% 대비▲)\n소모량 증가 (100% ▼)\nDT 전환 구성도 (계획)\nWeek 5 / 2024.1.30\n향후 계획\n▷ 디지털운영팀 전산화 개발 협업\n√ 레드마인 (Redmine) 공유 접수 完\n▷ 정량화 분석\n√ 정기적 수작업 분석 및 시스템 안정화 (오류 최소화 작업)\n√ 마젤란마린과 분석 결과 공유 (문제점 파악, 진행 방향 미세 조정 등 미세 조정)"}], "chunk_id": 1966}, {"rsp_tit": "5번째 검색데이터: [신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항 (출처:남성해운_팀별 주간회의_W20_240514.pptx)", "rsp_data": [{"rsp_type": "TT", "rsp_tit": "", "rsp_data": "DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 e-Svc上 , 남성그룹 對고객 서비스 MAP서비스 사용 현황\n. 남성 > 밸류링크유 맵서비스 무료 사용 타선사 대비 서비스 경쟁력\n. 동영 > 트래이드링스 맵서비스 유료 사용 (연간 2400만원 지급)\n\u000b남성그룹(남성 & 동영 ) 비용합리화 도모 必\n. 동영해운 (이정근 본부장) : 요구사항 및 배경 의견 적극 동의 및 동참 P.O.C : 부산 소재 / 에코마린\n(AIS 정보 1위 업체 글로벌 스파이어 맵 서비스)\n. 요구사항 수렴 리스트 전달 및 남성/동영 인베디드 커스텀 서비스 개발中\n. 범위 : 남성/동영 300척 內\n 씨벤티지(연간 3800만 견적) , 트래이드링스(동영/연간 2400만:Vessel Tracking) 대비\n 서비스 유지보수 운영 및 비용 경쟁력 우위\n. 적용 : e-Svc 上 / Cargo Tracking , Vessel Tracking\n. 견적 비용 : 최초 1년 첫해 1800만(개발비 3백포함) / 2년째 부터 1600만\nA 배경 INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁 강화통한 비용 합리화 必\n. 홈페이지 라우트 서비스 동적 맵\n 서비스 통한 Self Service 체제\n 전환\n.e-Svc 上 , 對고객 서비스 가시성확보/활용성 증대위한\nAIS정보 통한 실시간 Map 트래킹 서비스 통합 전환 검토 中 수행\nA 추진사항"}], "chunk_id": 1292}]}]}
(InferenceActor pid=591) [STREAM] Sent reference data for request_id=1742459818907-9433
(InferenceActor pid=591) [STREAM] final_query =
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 디지털 기획팀의 현재 우선 과제를 알려줘
(InferenceActor pid=591) [DEBUG] Token counts - 이전 대화: 0, RAG 검색 자료: 2410, 사용자 구체화 질문: 12, 총합: 2429
(InferenceActor pid=591) [STREAM] SSE: calling generate_answer_stream for request_id=1742459818907-9433
(InferenceActor pid=591) 최종 LLM 추론용 prompt 생성 :
(InferenceActor pid=591) <bos><start_of_turn>user
(InferenceActor pid=591) 너는 남성해운의 도움을 주는 데이터 분석가야.
(InferenceActor pid=591)
(InferenceActor pid=591) 주어진 **내부 자료**를 바탕으로 **내 질문**에 **상세하고 논리정연한** 답변을 작성해줘.
(InferenceActor pid=591) **답변은 반드시 아래 규칙에 맞춰 Markdown 형식**으로 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 1. **문단/제목:** `#`, `##`, `###` 등의 헤더를 사용하고, 문단 사이에 **한 줄 이상의 공백**을 넣어줘.
(InferenceActor pid=591) 2. **강조**: 강조할 단어나 문구는 `**굵게**`(이중별표) 또는 `*기울임*`(단일별표)를 사용해줘.
(InferenceActor pid=591) 3. **목록**: 필요하다면 `-` 또는 `*` 기호를 사용해 **목록**을 만들어줘.
(InferenceActor pid=591) 4. **표**: SQL 표 결과가 답변에 포함될 경우, 반드시 표의 시작 부분에 "<<<TABLE>>>"와 끝 부분에 "<<<END_TABLE>>>"라는 구분자를 추가해서 출력해줘.
(InferenceActor pid=591) 5. **코드 블록**: 예시 코드나 특수한 데이터는 ``` ``` 언어명 ... ``` ``` 을 사용해 표시해줘.
(InferenceActor pid=591) 6. **출처**: 내부 자료를 참조했다면 **어디서 어떤 내용을 사용했는지**를 마지막에 간단히 표기해줘.
(InferenceActor pid=591) 7. **각주(footnotes)**: 답변에 각주가 필요한 경우, 본문 중에 `[^1]`, `[^2]`와 같은 형태로 표시하고, 마크다운 형식과 같게 답변 마지막에 해당 각주 내용을 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 만약 **주어진 자료**에 질문에 해당하는 내용이 **없다면**, `"내부 자료에 해당 자료 없음"`이라고만 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) **주의**:
(InferenceActor pid=591) - 너무 짧거나 단답형이 아닌, 충분히 **길고 자세한 보고서 형태**로 답변해줘.
(InferenceActor pid=591) - 가능하면 **논리적 근거**와 **예시**를 들어 설명해줘.
(InferenceActor pid=591) - **문단**을 명확히 구분하여 **읽기 편하게** 작성해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 아래는 **내부 자료**와 **질문**이 주어질 것이니, 꼭 이 지침을 따라 답변해줘.
(InferenceActor pid=591)
(InferenceActor pid=591) 내부 자료: 1번째 검색자료 (출처:남성해운_팀별 주간회의_W36_20230905.pptx) :
(InferenceActor pid=591) 남성해운 디지털운영팀은 인프라 영역 중점 추진 과제 수행 보고를 위해 팀별 주간회의를 진행했습니다. 발표 자료에는 인프라 운영 합리화 방안이 제시되었는데, 효율성 대비 초기 인프라 셋업 비용 부담 및 그 후 운영 유지보수 비용 증가 리스크로 인해 5년 후 코어 부분의 퍼블릭 클라우드 전환을 재고려할 계획입니다. 또한, 남성해운만의 최적 인프라 운영 환경 구성을 위해 하이브리드 클라우드와 AWS를 활용한 멀티 클라우드 인프라 운영 전략을 유지할 것입니다. 발표 자료에는 IBM 서버와 STORAGE SERVER의 E.O.S(End of Support) 일정과 KT-IDC 적접 설치 계획, ORACLE 버전 업그레이드, 데이터 마이그레이션, SAP 재구성 및 데이터 마이그레이션, ORACLE DR 구성 등 구체적인 실행 계획이 제시되었습니다., , Score: 0.5218
(InferenceActor pid=591) 2번째 검색자료 (출처:남성해운_팀별 주간회의_W36_20230905.pptx) :
(InferenceActor pid=591) 남성해운 디지털운영팀은 인프라 영역 중점 추진 과제 수행 보고를 위해 팀별 주간회의를 진행했습니다. 이 발표자료에서는 KT 클라우드와 KT IDC를 활용한 운영 인프라 아키텍처를 보여줍니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 현재 시스템은 KT 클라우드와 KT IDC를 기반으로 운영되며, WAS, APS, WS 등 다양한 서비스를 제공합니다. 또한, GIT, CI-CD, APM 등을 활용하여 안정적인 서비스 제공을 위한 DevOps 환경을 구축했습니다. 보안 측면에서는 SSL 인증, MSP, LBS 등을 통해 시스템을 보호하고 있습니다. 데이터 백업 및 저장은 Storage와 RDS를 통해 관리하며, 추가적으로 Data 전용선을 통해 안정적인 데이터 전송을 보장합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 발표자료에는 현재 시스템의 아키텍처를 보여주는 다이어그램이 포함되어 있습니다. 이 다이어그램은 DB ICON(RAC), BACKUP STORAGE, EAPI, EMAS, IOT, DB NODE1, DB NODE2, DB SAP, OLD GW 등의 구성 요소를 보여줍니다. 또한, 시스템의 확장 가능성을 나타내는 SCALE DOWN과 SCALE UP 기능도 표시되어 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 발표자료는 2023년 9월 5일 남성해운 신성장전략실 디지털운영팀에서 제작되었습니다., , Score: 0.5202
(InferenceActor pid=591) 3번째 검색자료 (출처:남성해운_팀별 주간회의_W21_240521.pptx) :
(InferenceActor pid=591) DT운영팀은 조직 DX 전략을 레벨업하기 위해 지속적인 강화를 추진하고 있으며, 이를 위해 5가지 Build UP 영역을 집중적으로 강화하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 첫째, DA를 통한 체계적이고 효율적인 업무 간소화 전환을 추진하고 있습니다. 둘째, INFRA 응용 프로그램 고객 서비스 영역의 경쟁력을 지속적으로 강화하고 있습니다. 셋째, DT운영팀 Gray 영역의 Self Service를 통해 Man Power 경쟁력을 강화하고 있습니다. 넷째, DX 신기술을 민첩하게 도입하고 실용성을 중시하여 비즈니스에 적용하고 있습니다. 다섯째, 현업과의 리듬을 유지하고 적극적인 커뮤니케이션 채널을 활성화하여 '업' 전문성을 강화하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 구체적으로 남성그룹 오더/배차 API 연계 구축을 위한 설계서 검토 및 요구사항 확정 작업을 유로지텍과 함께 진행하고 있습니다. 또한 남성그룹 육상운송연계 자동화 시스템 구축을 위한 '틀' 마련 작업을 신성장실현팀과 함께 진행하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 또한, 국내 TW로지스틱스, 베트남 NS로지스틱스, 태국 KSP로지스틱스, 홍콩 NB로지스틱스, 중국 충칭 물류법인 등 디지털 비즈니스 로직 적용 대상을 선정하고 있습니다. 디지털 비즈니스 로직은 육상 운송 오더(BKG), 운임 Autorating 자동화, 육상 배차 정보 관리(조회, 등록, 수행), JOB ORDER 등을 포함합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 추가적으로, 컨테이너 IOT 장착을 통한 맵 서비스 적용 및 Big-Data IFC 연계, 고객 서비스 차별화를 위한 IOT 장착 Auto-rating 적용 및 e-Svc 비즈니스 적용, 인도네시아 대리점 업무 향상을 위한 지원(세관신고, e-DO, 인보이스..), 러시아 e-DO 서비스 및 지속적 터미널 CODECE 연계 등을 추진하고 있습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 이러한 노력들을 통해 DT운영팀은 조직 DX 전략을 성공적으로 이행하고, 해운 산업의 변화에 선도적인 역할을 수행할 것입니다., , Score: 0.5144
(InferenceActor pid=591) 4번째 검색자료 (출처:남성해운_팀별 주간회의_W5_240130 (1).pptx) :
(InferenceActor pid=591) 이번 주간 회의에서는 남성해운 운영혁신본부 운항관리팀장이 주요 업무로 Trim 최적화 진행 현황을 발표했습니다. 발표 내용은 DT 핵심 항목에 초점을 맞췄습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) Trim 달성율과 Consumption 달성율을 주요 지표로 제시했습니다. Consumption 달성율은 기준값(100%) 대비 증감율을 통해 파악하며, 소모량 감소는 100% 대비 ▲, 소모량 증가는 100% ▼로 표기했습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 또한, DT 전환 구성도(계획)를 Week 5 기준으로 제시했습니다. 향후 계획으로는 디지털운영팀과의 전산화 개발 협업을 통해 레드마인(Redmine) 공유 접수를 완료하고, 정량화 분석을 통해 정기적 수작업 분석 및 시스템 안정화(오류 최소화 작업)를 진행할 예정입니다. 마젤란마린과 분석 결과를 공유하여 문제점 파악 및 진행 방향 미세 조정 등을 진행할 계획입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 이 발표 자료는 남성해운 팀별 주간회의 자료로, 2024년 1월 30일에 제작되었습니다., , Score: 0.5033
(InferenceActor pid=591) 5번째 검색자료 (출처:남성해운_팀별 주간회의_W20_240514.pptx) :
(InferenceActor pid=591) 급변하는 해운 시장 환경 속에서 디지털 전환을 통해 경쟁력을 강화하기 위해 DT운영팀은 조직 DX 전략을 레벨업하기 위한 지속적인 강화를 추진하고 있습니다. 이를 위해 5가지 Build Up 영역을 집중적으로 강화할 계획입니다. 첫째, DA를 통한 체계적이고 효율적인 업무 간소화를 추진합니다. 둘째, INFRA 응용 프로그램 고객 서비스 영역에서 지속적인 경쟁력 강화를 위해 노력합니다. 셋째, DT운영팀의 Gray 영역에서 Self Service를 통해 인력 경쟁력을 강화합니다. 넷째, DX 신기술을 민첩하게 도입하여 실용성을 중시하는 방식으로 비즈니스에 적용합니다. 다섯째, 현업과의 리듬을 유지하고 적극적인 커뮤니케이션 채널을 활성화하여 협업을 강화합니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 특히, 남성그룹의 고객 서비스 MAP 서비스 사용 현황을 분석하여 비용 합리화를 도모하고 있습니다. 남성해운은 밸류링크유 맵 서비스를 무료로 사용하고 있으며, 동영해운은 트래이드링스 맵 서비스를 연간 2400만원을 지불하고 사용하고 있습니다. 이에 따라 남성그룹(남성 & 동영)의 비용 합리화를 위해 에코마린(AIS 정보 1위 업체, 글로벌 스파이어 맵 서비스)과 협력하여 남성/동영 300척 이내 대상으로 인베디드 커스텀 서비스를 개발 중입니다. 이 서비스는 씨벤티지(연간 3800만원 견적)와 트래이드링스(동영/연간 2400만원:Vessel Tracking) 대비 서비스 유지보수 운영 및 비용 경쟁력 우위를 확보할 수 있도록 설계되었습니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 또한, INFRA 응용 프로그램 고객 서비스 영역에서 지속적인 경쟁력 강화를 위해 홈페이지 라우트 서비스 동적 맵 서비스를 통한 Self Service 체제 전환을 검토하고 있습니다. e-Svc 상에서 고객 서비스 가시성을 확보하고 활용성을 증대하기 위해 AIS 정보를 통한 실시간 Map 트래킹 서비스 통합 전환도 검토 중입니다.
(InferenceActor pid=591)
(InferenceActor pid=591) 이러한 노력들을 통해 DT운영팀은 조직 DX 전략을 레벨업하고, 해운 시장의 변화에 유연하게 대응하며 지속적인 성장을 도모할 것입니다., , Score: 0.4988
(InferenceActor pid=591)
(InferenceActor pid=591)
(InferenceActor pid=591) 질문:
(InferenceActor pid=591)
(InferenceActor pid=591) [사용자 질문]
(InferenceActor pid=591) 디지털 기획팀의 현재 우선 과제를 알려줘<end_of_turn>
(InferenceActor pid=591) <start_of_turn>model
(InferenceActor pid=591) 답변:
(InferenceActor pid=591)
(InferenceActor pid=591) INFO 03-20 08:38:02 [async_llm.py:204] Added request 74401270-3c7f-4cc2-826e-a4850c3cb0a8.
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO RAG.py:591: BM25 scores: min=0.7793, max=24.1504, mean=6.7011
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting cal_bm25_score() -- Elapsed: 1.94s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO RAG.py:448: BM25 score shape: (3511,)
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:11: Entering min_max_scaling()
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting min_max_scaling() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO RAG.py:457: Top 5 document indices: [1672 1673 1307 1965 1291]
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO RAG.py:458: Top 5 document scores: [0.5217542474030481, 0.5202098612545953, 0.5143576686142908, 0.5033134643792139, 0.4988371853589044]
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO RAG.py:459: Top document titles: ['[신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고', '[신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고', '[신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항', '[운영혁신본부] 운항관리팀장 > 주요업무 (핵심 추진과제 Trim 최적화 진행 현황 – DT 핵심항목)', '[신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항']
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting retrieve() -- Elapsed: 2.10s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:11: Entering generate_answer_stream()
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting generate_answer_stream() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:11: Entering collect_vllm_text_stream()
(InferenceActor pid=591) [2025-03-20 08:38:02] INFO tracking.py:15: Exiting collect_vllm_text_stream() -- Elapsed: 0.00s
[DEBUG] SSE closed.
(ServeReplica:default:inference pid=586) INFO 2025-03-20 08:38:32,631 default_inference 1zebleoo a59810d8-d268-42e2-be13-956ad5e0694d -- CALL close_sse_queue OK 2.4ms
(InferenceActor pid=591) ---------------- chunk_id 찾기 :  [{'rsp_tit': '1번째 검색데이터: [신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고 (출처:남성해운_팀별 주간회의_W36_20230905.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '인프라 운영 합리화 측면,\n효율성 대비 초기 인프라 셋업 비용 부담\n및 그후 운영유지보수 비용 증가 리스크로\n인해 5년後 코어부분의 퍼블릭 클라우드\n전환 재고려\n우리만의 최적 인프라 운영 환경 구성\nHybrid Cloud + AWS 멀티 클라우드\n인프라 운영 전략 유지\n2] STORAGE SERVER E.O.S(24년 2월)\n3] E.O.S기간內 KT-IDC 적접 설치\n1] IBM 서버 E.O.S(24년 12월)\n4] KT-IDC 적접 설치後 E.O.S기간內\n안정화/ 테스트 수행後 전환\n수행 배경\n. ORACLE VER 11G(E.O.S) > 12C로 전환\n(신규 구매)\n. DATA 마이그레이션\n. SAP 재구성 및 DATA마이그레이션\n. ORACLE DR 구성\n. SAP DATA\n. Oracle Server Node1 / RAC 이중화\n. ICON+ DATA\n. Oracle Server Node2 / RAC /이중화\n. SAP ( NED , NEQ , NEP )\n. ORACLE 12C 설치로 인한 ICON+및\nESVC+ 검증 및 테스트(쿼리)\n. SAP ABAP인터페이스 데이터 검증\n및 SAP 운영 테스트'}], 'chunk_id': 1673}, {'rsp_tit': '2번째 검색데이터: [신성장전략실] 디지털운영팀 > 인프라 영역 중점 추진 과제 수행 보고 (출처:남성해운_팀별 주간회의_W36_20230905.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'KT CLOUD/KT IDC+AWS 관리자\n사용자\nBrowser\nBrowser 운영 개발자\nCross Browser\nREST / HTML5\nMulti Device\nDevOps\nGIT 소스 통합 운영 관리\nCI-CD 자동 배포 관리\nAPM통한 안정적 서비스제공 프레임워크\n클라우드 연계\nHP GIT CI-CD\nKT 클라우드 WAS1\nICON E-SVC APS 1 WS 1 SSL 인증보안\nMSP LBS Data Backup Storage RDS\nWAS2 APS 2 WS 2 ICON E-SVC\nMSP 장교빌딩 Fax System File Server\nSVN DATA전용선 LINE G/W B\nAWS CLOUD KT IDC 운영 인프라 아키텍쳐 (AS IS )\nDB ICON (RAC) BACKUP STORAGE EAPI EMAS IOT\nDB NODE1 DB NODE2 DB SAP OLD GW\nSCALE DOWN SCALE UP A'}], 'chunk_id': 1674}, {'rsp_tit': '3번째 검색데이터: [신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항 (출처:남성해운_팀별 주간회의_W21_240521.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n.급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 남성그룹 오더/배차 API 연계 구축을 위한 설계서 검토 및 요구사항 확정 with 유로지텍\n- API 연계 설계 - 라인운송 요청/취소 API 개발\n- 라인운송 요청관리 - 라인운송 오더 수신\n- 배차 정보 송신 - 배차 운임 정보 송신\n- API 연계 처리 테스트 남성그룹 육상운송연계 자동화 시스템 구축을 위한 ‘틀’ 마련\nwith 신성장실현팀\n. DOOR/CY + Ocean Service + CY/DOOR 경험 시스템內 디지털화 必\n. 비즈니스 디지털 거점 적용 전환 대상\n국내: TW로지스틱스 , 베트남: NS로지스틱스 ,태국: KSP로지스틱스\n홍콩: NB로지스틱스 , 중국 : 충칭 물류법인\n. 디지털 비즈니스 로직 요구사항\n육상 운송 오더(BKG) ,\n운임 Autorating 자동화,\n육상 배차 정보 관리(조회,등록,수행) , JOB ORDER\n24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 통한\n‘業’ 전문성 강화 A 배경 적극적 커뮤니케이션 채널 활성화 통한 ‘業’ 전문성 강화 必\n.컨테이너 IOT 장착을 통한\n맵 서비스 적용 및 Big-Data IFC연계\n.고객 서비스 차별화를 위한\nIOT장착 Auto-rating 적용 및\ne-Svc 비즈니스 적용\n.인도네시아 대리점 업무 향상을 위한\n지원(세관신고, e-DO , 인보이스..)\n.러시아 e-DO 서비스 및 지속적 터미널\nCODECE연계 ….\n.남성그룹 육상운송연계 자동화 시스템 ‘틀’ 구축을 위한 출항 A 수행 추진사항'}], 'chunk_id': 1308}, {'rsp_tit': '4번째 검색데이터: [운영혁신본부] 운항관리팀장 > 주요업무 (핵심 추진과제 Trim 최적화 진행 현황 – DT 핵심항목) (출처:남성해운_팀별 주간회의_W5_240130 (1).pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': '주요지표항목\n▷ Trim 달성율\n▷ Consumption 달성율\n√ 기준값 대비 증감율 (기준값 = 100%)\n√ 소모량 감소 (100% 대비▲)\n소모량 증가 (100% ▼)\nDT 전환 구성도 (계획)\nWeek 5 / 2024.1.30\n향후 계획\n▷ 디지털운영팀 전산화 개발 협업\n√ 레드마인 (Redmine) 공유 접수 完\n▷ 정량화 분석\n√ 정기적 수작업 분석 및 시스템 안정화 (오류 최소화 작업)\n√ 마젤란마린과 분석 결과 공유 (문제점 파악, 진행 방향 미세 조정 등 미세 조정)'}], 'chunk_id': 1966}, {'rsp_tit': '5번째 검색데이터: [신성장전략실] 디지털운영팀장 > 운영 영역 수행 사항 (출처:남성해운_팀별 주간회의_W20_240514.pptx)', 'rsp_data': [{'rsp_type': 'TT', 'rsp_tit': '', 'rsp_data': 'DT운영팀 ‘조직 DX전략 레벨업 위한 지속적 강화 Top 5 Build UP영역’\n급박하게 변화하는 해운마켓플레이스上 자연스러운 디지털 전환 도달 목표 24’ DT운영팀 전사조직 레벨업 위한 지속적 강화 Build up 5가지 영역\n. DA 통한 체계적이며 효율적인 업무 간소화 전환\n. INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁력 강화\n. DT운영팀 Gray 영역 Self Service통한 Man Power경쟁력 강화\n. DX신기술 민첩하게 액션하고 실용성위주 現)비즈니스 上 도입\n. 현업과 리듬을 유지, 적극적 커뮤니케이션 채널 활성화 e-Svc上 , 남성그룹 對고객 서비스 MAP서비스 사용 현황\n. 남성 > 밸류링크유 맵서비스 무료 사용 타선사 대비 서비스 경쟁력\n. 동영 > 트래이드링스 맵서비스 유료 사용 (연간 2400만원 지급)\n\x0b남성그룹(남성 & 동영 ) 비용합리화 도모 必\n. 동영해운 (이정근 본부장) : 요구사항 및 배경 의견 적극 동의 및 동참 P.O.C : 부산 소재 / 에코마린\n(AIS 정보 1위 업체 글로벌 스파이어 맵 서비스)\n. 요구사항 수렴 리스트 전달 및 남성/동영 인베디드 커스텀 서비스 개발中\n. 범위 : 남성/동영 300척 內\n 씨벤티지(연간 3800만 견적) , 트래이드링스(동영/연간 2400만:Vessel Tracking) 대비\n 서비스 유지보수 운영 및 비용 경쟁력 우위\n. 적용 : e-Svc 上 / Cargo Tracking , Vessel Tracking\n. 견적 비용 : 최초 1년 첫해 1800만(개발비 3백포함) / 2년째 부터 1600만\nA 배경 INFRA 응용 프로그램 고객 서비스 영역 지속적 경쟁 강화통한 비용 합리화 必\n. 홈페이지 라우트 서비스 동적 맵\n 서비스 통한 Self Service 체제\n 전환\n.e-Svc 上 , 對고객 서비스 가시성확보/활용성 증대위한\nAIS정보 통한 실시간 Map 트래킹 서비스 통합 전환 검토 中 수행\nA 추진사항'}], 'chunk_id': 1292}]
(InferenceActor pid=591) 메시지 저장 직후 chunk_id 확인 :  chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='디지털 기획팀의 우선과제가 어떻게 돼?', additional_kwargs={'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={}), AIMessage(content='# 남성해운 디지털 기획팀 우선 과제 보고서\n\n## 1. 핵심 요약\n\n남성해운 디지털 기획팀은 조직의 DX 전략을 레벨업하기 위해 5가지 핵심 영역을 집중적으로 강화하고 있습니다. 이는 업무 효율화, 인프라 경쟁력 강화, 인력 경쟁력 강화, 신기술 도입, 그리고 내부 협업 강화에 초점을 맞추고 있습니다. 특히 남성그룹 전체적인 비용 합리화를 위한 MAP 서비스 관련 프로젝트와 고객 서비스 개선을 위한 다양한 시스템 도입 및 전환이 중요한 과제로 부각되고 있습니다.\n\n## 2. 우선 과제 상세 분석\n\n현재 디지털운영팀의 주요 우선 과제는 다음과 같습니다.\n\n### 2.1. DA 기반 업무 간소화 및 효율 증대\n데이터 분석(DA)을 활용하여 업무 프로세스를 체계적으로 간소화하고 효율을 증대시키는 노력을 진행하고 있습니다. 이는 전반적인 운영 비용 절감과 생산성 향상에 기여할 것으로 예상됩니다.\n  \n### 2.2. INFRA 및 고객 서비스 경쟁력 강화\n인프라 응용 프로그램 및 고객 서비스 영역의 경쟁력을 지속적으로 강화하는 데 집중하고 있습니다.  KT 클라우드 및 KT IDC를 활용한 운영 인프라 아키텍처를 기반으로 안정적인 서비스 제공을 위한 DevOps 환경을 구축하고 있습니다.\n\n### 2.3. 자체 서비스(Self Service) 구축을 통한 인력 경쟁력 강화\nDT운영팀 내부의 Gray 영역에서 자체 서비스(Self Service)를 구축하여 인력 경쟁력을 강화하고 있습니다. 이를 통해 팀원들이 보다 핵심적인 업무에 집중할 수 있도록 지원합니다.\n\n### 2.4. DX 신기술 도입 및 비즈니스 적용\nDX 관련 신기술을 빠르게 도입하고 실용성을 중시하여 실제 비즈니스에 적용하는 데 앞장서고 있습니다. 이를 통해 남성해운은 해운 산업의 변화에 선도적으로 대응할 수 있을 것으로 기대됩니다.\n\n### 2.5. 내부 협업 및 커뮤니케이션 강화\n현업 부서와 긴밀하게 소통하고 협업 채널을 활성화하여 전문성을 강화하고 있습니다. 이를 통해 실제 현장의 요구사항을 반영한 효과적인 DX 전략을 수립하고 실행할 수 있습니다.\n\n### 2.6. MAP 서비스 비용 합리화 및 고객 서비스 개선\n남성그룹(남성해운, 동영해운)의 MAP 서비스 사용 현황을 분석하여 비용 합리화를 위한 프로젝트를 진행하고 있습니다. 밸류링크유, 트래이드링스 등 기존 서비스 대비 비용 경쟁력을 확보할 수 있는 에코마린(글로벌 스파이어 맵 서비스)과의 협력을 통해 인베디드 커스텀 서비스를 개발하고 있습니다.  또한, 홈페이지 라우트 서비스 동적 맵 서비스 전환 및 AIS 정보를 활용한 실시간 Map 트래킹 서비스 통합 전환을 검토하여 고객 서비스 가시성과 활용성을 증대시키려는 노력을 기울이고 있습니다.\n\n## 3. 추가적인 추진 과제\n\n*   **남성그룹 오더/배차 API 연계 구축**: 유로지텍과의 협력을 통해 설계서 검토 및 요구사항 확정 작업 진행 중입니다.\n*   **남성그룹 육상운송연계 자동화 시스템 구축**: 신성장실현팀과의 협력을 통해 시스템 구축을 위한 기반 작업 진행 중입니다.\n*   **디지털 비즈니스 로직 적용 대상 선정**: 국내외 주요 로지스틱스 기업 (TW로지스틱스, NS로지스틱스, KSP로지스틱스, NB로지스틱스, 충칭 물류법인)을 대상으로 디지털 비즈니스 로직 적용 가능성을 검토하고 있습니다. ([^1])\n*   **IOT 장착을 통한 맵 서비스 및 빅데이터 IFC 연계**: 컨테이너 IOT 장착을 통해 맵 서비스 적용 및 Big-Data IFC 연계를 추진하고 있습니다. 고객 서비스 차별화를 위한 IOT 장착 Auto-rating 적용 및 e-Svc 비즈니스 적용도 검토 중입니다.\n*   **해외 대리점 업무 지원**: 인도네시아 대리점 업무 향상을 위한 지원 (세관신고, e-DO, 인보이스 등) 및 러시아 e-DO 서비스 연계를 추진하고 있습니다.\n\n## 4. 결론\n\n디지털운영팀은 다양한 과제를 통해 남성해운의 DX 전환을 가속화하고 경쟁력을 강화하는 데 주력하고 있습니다. 특히, 비용 절감과 고객 서비스 향상을 위한 MAP 서비스 관련 프로젝트와 더불어 디지털 비즈니스 로직 적용 확대를 위한 노력이 핵심적인 추진 과제로 부각되고 있습니다. 이러한 노력들이 지속적으로 추진될 경우, 남성해운은 해운 시장에서 선도적인 역할을 수행할 수 있을 것으로 기대됩니다.\n\n---\n\n[^1]: 디지털 비즈니스 로직에는 육상 운송 오더(BKG), 운임 Autorating 자동화, 육상 배차 정보 관리(조회, 등록, 수행), JOB ORDER 등이 포함됩니다.\n\n**출처:**\n*   남성해운\\_팀별 주간회의\\_W36\\_20230905.pptx\n*   남성해운\\_팀별 주간회의\\_W21\\_240521.pptx\n*   남성해운\\_팀별 주간회의\\_W5\\_240130 (1).pptx\n*   남성해운\\_팀별 주간회의\\_W20\\_240514.pptx', additional_kwargs={'chunk_ids': [1673, 1674, 1308, 1966, 1292], 'qry_id': '', 'user_id': None, 'auth_class': None, 'qry_time': None}, response_metadata={})]) return_messages=True
(InferenceActor pid=591) [SOOWAN] process_to_format 진입
(InferenceActor pid=591) [SOOWAN] 타입 : 대답
(InferenceActor pid=591) [STREAM] error in partial streaming => 'str' object has no attribute 'get'
(InferenceActor pid=591) [STREAM] close_sse_queue => removing SSE queue for request_id=1742459818907-9433
(InferenceActor pid=591) === [In-Flight Batching] Waiting for first item in request_queue... ===
(InferenceActor pid=591) [STREAM] close_sse_queue => no SSE queue found for 1742459818907-9433
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO tracking.py:11: Entering process_to_format()
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO tracking.py:15: Exiting process_to_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO tracking.py:11: Entering process_format_to_response()
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO tracking.py:11: Entering error_format()
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO tracking.py:15: Exiting error_format() -- Elapsed: 0.00s
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO debug_tracking.py:12: 배치 처리 후 상태 - Process Memory: RSS=1838.71 MB, VMS=36637.11 MB
(InferenceActor pid=591) [2025-03-20 08:38:32] INFO debug_tracking.py:13: 배치 처리 후 상태 - GPU Memory: allocated=0.00 MB, reserved=0.00 MB


```

-----------------

# Base-Knowledge
 - 위 파일들은 LLM 모델을 활용한 사내 RAG 서비스의 소스 코드입니다.
 - 파일 트리와 각 파일의 내용이 코드 블록 내에 포함되어, 프로젝트의 현재 구조와 상태를 한눈에 파악할 수 있습니다.
 - vLLM과 ray를 활용하여 사용성 및 추론 성능을 개선하였습니다.
 - Langchain을 활용하여 reqeust_id별로 대화를 저장하고 활용할 수 있습니다.
 - 에러 발생 시 로깅을 통해 문제를 추적할 수 있도록 설계되었습니다.


# Answer-Rule
 1. 추후 소스 코드 개선, 구조 변경, 에러 로그 추가 등 다양한 요구사항을 반영할 수 있는 확장성을 고려합니다.
 2. 전체 코드는 한국어로 주석 및 설명이 포함되어, 이해와 유지보수가 용이하도록 작성됩니다.


# My-Requirements
 1. 우리의 목표는 현재 batch가 5개라면, 유기적으로 5개의 요청을 처리할 수 있도록 하는 것이야. 
 2. 하지만 로그에서 보다시피, 이미 3개의 요청이 들어간 상황에서 새로운 요청이 들어가도 함께 처리되지 않고 있어. 해당 원인에 대해서 상세히 분석하고 이유를 알려줘.
 3. 위 원인에 대한 분석을 기반으로 5개로 제한을 둔 배치에 자리가 비워져 있으면 배치가 끝나지 않아도 새로운 요청을 계속해서 배치에 채워서 LLM이 이를 처리할 수 있도록 해줘.
