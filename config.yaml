# config.yaml

### Model
model_id : 'google/gemma-2-27b-it'

ray:
  actor_count: 1          # 총 Actor 개수
  actor_num_gpus: 2       # Ray-Actor(Node)가 점유하고 있는 GPU

use_vllm: True # vLLM 사용 여부
vllm:
  enable_prefix_caching: True
  scheduler_delay_factor: 0.1
  enable_chunked_prefill: True
  tensor_parallel_size: 2 # vLLM의 GPU 사용 갯수 (!!!! actor_num_gpus 보다 작아야 함 !!!!)
  max_num_seqs: 128
  max_num_batched_tokens: 16384
  block_size: 128 # 미적용
  gpu_memory_utilization: 0.95
  disable_custom_all_reduce: true

model:
  quantization_4bit : False # Quantize 4-bit
  quantization_8bit : False # Quantize 8-bit
  max_new_tokens : 2048      # 생성할 최대 토큰 수

  do_sample : True # True 일때만 아래가 적용
  temperature : 1.0          # 텍스트 다양성 조정: 높을수록 창의력 향상 (1.0)
  top_k : 30                 # top-k 샘플링: 상위 k개의 후보 토큰 중 하나를 선택 (50)
  top_p : 1.0                # top-p 샘플링: 누적 확률을 기준으로 후보 토큰을 선택 (1.0 보다 낮을수록 창의력 증가)
  repetition_penalty : 1.0   # 같은 단어를 반복해서 출력하지 않도록 패널티를 부여 (1.0 보다 클수록 페널티 증가)
embed_model_id : 'BM-K/KoSimCSE-roberta-multitask'
# cache_dir : "D:/huggingface" # Windows Local
# cache_dir : "/media/user/7340afbb-e4ce-4a38-8210-c6362e85eae7/RAG/RAG_application/huggingface" # Local
cache_dir : "/workspace/huggingface"  # Docker

### Data
data_path : 'data/1104_NS_DB_old.json' # VectorDB Path
metadata_path : 'data/Metadata.json' # Metadata.json Path
sql_data_path : 'data/poc.db'        # SQLite 데이터베이스 Path

### Retrieve
N : 5 # Retrieve top N chunks

### Others
beep : '-------------------------------------------------------------------------------------------------------------------------------------------------------------------------'
seed : 4734                     # Radom Seed
k : 15                        # SQL Max Rows (None=MAX)
